# 资源需求与投资回报

---

## TL;DR（高管速读版）

> **用 4.5 人、40 周、约 200 万的总投入，换取年化 120-250 万的可量化回报，以及"周级问题检测变天级"的不可量化战略优势。更重要的是——每个阶段都可以选择停下来。**

- **人力**：核心团队 4.5 人（后端 x2 + 前端 x1 + AI 工程师 x1 + 产品经理 x0.5），辅以 DevOps x0.5 和设计师 x0.5，峰值不超过 5.5 人。
- **基础设施**：开发期近零成本（Docker Compose 本地运行），生产环境月度云资源开销约 5,000-12,000 元，LLM API 调用月度 2,000-15,000 元（随数据量弹性伸缩）。
- **时间**：6 个阶段合计 40-54 周（含 20% 缓冲）。Phase 1 已完成，Phase 2 进行中。从当前节点到核心功能可用（Phase 3 结束）约 14-20 周。
- **回本周期**：保守估算 12-18 个月。Phase 3 交付后即开始产生可量化回报。
- **安全阀**：每个阶段结束设 Go/No-Go 评审点。最大单次风险敞口不超过 30 万（单阶段投入），而非一次性押注 200 万。

---

## 1. 团队配置建议

### 1.1 核心团队角色与职责

团队设计遵循一个原则：**每个角色都必须在至少两个阶段中是关键路径上的瓶颈资源。** 如果一个角色只在某个阶段短暂需要，应该用外包或兼职覆盖，而非全职招聘——招人的隐性成本（招聘周期、onboarding、文化融合）远高于薪资本身。

| 角色 | 人数 | 核心职责 | 技能要求 | 参与阶段 |
|------|------|---------|---------|---------|
| **后端工程师** | 2 | 微服务开发、数据管线、API 设计、Agent 运行时 | FastAPI + SQLAlchemy + async Python；分布式系统基础 | Phase 1-6（全程） |
| **前端工程师** | 1 | Web UI、Agent 对话界面、数据可视化 | React + TypeScript + Vite；实时交互（SSE）经验 | Phase 1-6（全程） |
| **AI 工程师** | 1 | Prompt 工程、AI 管线、向量检索调优、模型评估 | LLM 应用开发；Embedding/Rerank 实践；评估体系设计 | Phase 2-6（Phase 1 不需要） |
| **产品经理** | 0.5 | 需求定义、验收标准、用户调研、竞品跟踪 | VOC/CX 领域经验；能与技术团队深度对话 | Phase 2.5-6（早期技术驱动） |
| **DevOps** | 0.5 | CI/CD、容器编排、监控告警、环境管理 | Docker + 云平台（阿里云/AWS）；基础 SRE 能力 | Phase 1, 4-6（按需介入） |
| **设计师** | 0.5 | 交互设计、组件规范、治理工作台 UX | 中后台设计经验；能理解复杂信息架构 | Phase 3-6（按需介入） |

### 1.2 各阶段人力需求变化

人力配置不是一条直线，而是一条阶梯——早期"精兵模式"，中期"满编运转"，后期根据产品方向可能需要扩编或调整。

| 阶段 | 后端 | 前端 | AI | PM | DevOps | 设计 | **合计** | 月人力成本（估） |
|------|------|------|----|----|--------|------|---------|----------------|
| Phase 1（已完成） | 1 | 1 | — | — | 0.5 | — | **2.5** | ~8.8 万 |
| Phase 2（进行中） | 2 | 0.5 | — | — | — | — | **2.5** | ~8.8 万 |
| Phase 2.5 | 2 | 0.5 | 0.5 | — | — | — | **3** | ~10.5 万 |
| Phase 3 | 2 | 1 | 1 | 0.5 | — | 0.5 | **5** | ~17.5 万 |
| Phase 4 | 2 | 1 | 1 | 0.5 | — | 0.5 | **5** | ~17.5 万 |
| Phase 5 | 2 | 1.5 | 1 | 0.5 | 0.5 | — | **5.5** | ~19.3 万 |
| Phase 6 | 2 | 1 | 1 | 0.5 | 1 | — | **5.5** | ~19.3 万 |

> **人力成本估算基准**：工程师月均全成本（含社保、福利、办公）约 3.5 万/人，PM/设计约 3 万/人。这是一线城市中等偏上水平的保守估算。

### 1.3 技能需求矩阵

一个被频繁忽视的问题：不是"有人"就够了，还要"有对的技能"。以下矩阵标注了每个阶段的关键技能需求——标记为"关键"的技能如果缺失，该阶段大概率延期。

| 技能域 | Phase 1 | Phase 2 | Phase 2.5 | Phase 3 | Phase 4 | Phase 5 | Phase 6 |
|--------|---------|---------|-----------|---------|---------|---------|---------|
| FastAPI + async | 关键 | 关键 | 关键 | 关键 | 需要 | 需要 | 需要 |
| SQLAlchemy 2.0 | 关键 | 需要 | 需要 | 关键 | 关键 | 需要 | 需要 |
| LLM 应用开发 | — | 关键 | 需要 | 关键 | 关键 | 关键 | 关键 |
| Prompt 工程 | — | — | — | 关键 | 需要 | 需要 | 需要 |
| 向量检索（pgvector） | — | — | — | 关键 | 关键 | 需要 | 需要 |
| Agent 架构设计 | — | — | 关键 | 需要 | 需要 | 关键 | 关键 |
| React + SSE | 需要 | 需要 | — | 需要 | 需要 | 关键 | 需要 |
| DevOps / 可观测性 | 需要 | — | — | — | — | 需要 | 关键 |

> **关键**：该阶段成败取决于此技能；**需要**：需具备但不是瓶颈；**—**：该阶段不涉及。

---

## 2. 基础设施成本

基础设施成本是管理层最容易"看懂"的数字，也是最容易被高估或低估的数字。高估来自"按最终形态规划 Day 1 预算"，低估来自"忘记 LLM API 是按调用量收费的"。我们的原则是：**按当前阶段的真实需求估算，不为未来可能需要的能力提前付费。**

### 2.1 开发环境（Phase 1-3：近零成本）

| 资源 | 方案 | 月度成本 |
|------|------|---------|
| PostgreSQL 17 + pgvector | Docker Compose 本地运行 | 0 元 |
| Redis 7 | Docker Compose 本地运行 | 0 元 |
| 计算资源 | 开发者本地机器 | 0 元（已有设备） |
| LLM API（开发调试） | 各 Provider 免费额度 + 低量调用 | ~500 元/月 |
| **合计** | | **~500 元/月** |

Prism 的基础设施选型（PostgreSQL + Redis + Docker Compose）决定了开发阶段几乎没有额外的基础设施支出。这不是偶然——第六章（技术蓝图）中"基础设施从简"的原则，在成本维度上的体现就是：**不在 Day 1 为 Kubernetes、Kafka、Elasticsearch 付费。**

### 2.2 生产环境（Phase 3+ 上线后）

以下估算基于阿里云/AWS 中等规格，满足初期 10-50 用户、日处理 1,000-10,000 条反馈的场景。

| 资源 | 规格 | 月度成本 |
|------|------|---------|
| 云服务器（应用） | 2 台 2C4G（llm-service + user-service） | ~800 元 |
| PostgreSQL（托管） | 2C4G，100GB SSD | ~1,200 元 |
| Redis（托管） | 1GB 内存 | ~300 元 |
| 对象存储 | 100GB（冷数据归档、日志） | ~50 元 |
| 域名 + SSL + CDN | 基础配置 | ~200 元 |
| 监控告警 | 基础 Prometheus + Grafana（自建或轻量云服务） | ~400 元 |
| **基础设施小计** | | **~3,000 元/月** |

| 弹性成本项 | 低负载场景 | 中等负载场景 | 高负载场景 |
|-----------|----------|------------|----------|
| 数据量 | ~1,000 条/月 | ~10,000 条/月 | ~100,000 条/月 |
| LLM API 调用（标注 + Embedding） | ~2,000 元/月 | ~6,000 元/月 | ~15,000 元/月 |
| 额外计算资源 | — | +1,000 元/月 | +3,000 元/月 |
| **弹性成本小计** | **~2,000 元/月** | **~7,000 元/月** | **~18,000 元/月** |
| **月度总成本** | **~5,000 元/月** | **~10,000 元/月** | **~21,000 元/月** |

### 2.3 LLM API 成本详解

LLM API 是 Prism 运营成本中最大的变量项。以下按单条 Voice 反馈的处理全链路拆解：

| 环节 | 模型类型 | 预估 token 消耗 | 单条成本（按 GPT-4o 级别定价） |
|------|---------|----------------|---------------------------|
| 语义拆解（Stage 1） | Chat 模型 | ~800 token（输入+输出） | ~0.012 元 |
| 标签涌现（Stage 2） | Chat 模型 | ~600 token | ~0.009 元 |
| 向量化（Stage 3） | Embedding 模型 | ~300 token | ~0.001 元 |
| 关系构建（Stage 4） | Chat 模型 | ~400 token | ~0.006 元 |
| **单条 Voice 合计** | | **~2,100 token** | **~0.028 元** |

> **成本趋势利好**：LLM 单位价格持续下降——GPT-4o 较 GPT-4 降价约 80%，国产模型（DeepSeek、Qwen）在同等任务上的成本可低至 GPT-4o 的 1/5-1/10。Prism 的别名系统支持透明切换 Provider，可以持续追随成本最优选择。

---

## 3. 时间线估算

### 3.1 各阶段时间线

所有时间估算已包含 20% 缓冲。这个缓冲不是"乐观估计再加个保险"，而是 Hofstadter 定律的工程实践——事情总是比你预期的更久，即使你已经考虑了这一点。

| 阶段 | 内容 | 工期（含 20% 缓冲） | 累计周数 | 状态 |
|------|------|---------------------|---------|------|
| **Phase 1** | 基础设施 + 模型配置 | 4 周 | 4 | 已完成 |
| **Phase 2** | LLM 调用能力 | 4-6 周 | 8-10 | **进行中** |
| **Phase 2.5** | Agent 基础运行时 | 4-6 周 | 12-16 | 待启动 |
| **Phase 3** | VOC 数据摄入 + 语义底座 | 6-8 周 | 18-24 | 待启动 |
| **Phase 4** | 语义检索 + 概念治理 | 6-8 周 | 24-32 | 待启动 |
| **Phase 5** | Agent 高级交互 + 编排 | 8-10 周 | 32-42 | 待启动 |
| **Phase 6** | 洞察引擎 + 平台化 | 8-12 周 | 40-54 | 待启动 |

以甘特图视角呈现（每格代表 2 周）：

```
         W1  W3  W5  W7  W9  W11 W13 W15 W17 W19 W21 W23 W25 W27 ...
Phase 1  ████                                                          ✓ 已完成
Phase 2      ████████                                                  ⟵ 进行中
Phase 2.5            ████████
Phase 3                      ████████████
Phase 4                                  ████████████
Phase 5                                              ████████████████
Phase 6                                                          ████████████████
         ─────────── ─────────────────── ───────────── ────────────────────────────
         地基层       核心能力层            知识管理层     高级能力 + 平台化
```

### 3.2 关键路径分析

关键路径是决定项目最终交付时间的"最长链"——链上任何一个环节延迟，都会导致整体延迟。

**关键路径**：Phase 2 → Phase 2.5 → Phase 3 → Phase 4 → Phase 5 → Phase 6

这是一条严格的串行依赖链（详见第七章的阶段依赖关系图），意味着：

1. **Phase 2 是当前的关键节点。** 它的按时交付直接决定后续所有阶段的启动时间。
2. **Phase 3 是价值释放的拐点。** Phase 1-2.5 是纯投入期（建基础设施），Phase 3 是投入开始转化为可感知业务价值的第一个阶段。
3. **Phase 4 之后存在并行空间。** Phase 5 的前端（Agent 对话 UI）和后端（多 Agent 框架）可以部分并行推进，有约 2-3 周的压缩空间。

### 3.3 当前进展

| 阶段 | 完成度 | 核心交付物状态 |
|------|--------|--------------|
| Phase 1 | 100% | shared 共享库、user-service、llm-service 管理功能、Web UI、Docker Compose 基础设施——全部交付并通过验收 |
| Phase 2 | 进行中 | LiteLLM 集成、Chat/Embedding API、故障转移引擎开发中 |

**Phase 1 已完成的事实意味着**：微服务骨架已经就位、数据库 Schema 隔离已验证、前后端技术栈已跑通、团队的协作节奏已建立。这些"看不见的基础设施"是后续每个阶段能够按预期推进的前提。

---

## 4. 投资回报分析

### 4.1 总投入估算

先把账算清楚——管理层有权知道"总共要花多少钱"。

| 成本项 | Phase 1-2（已投入/进行中） | Phase 2.5-3（核心价值交付） | Phase 4-6（高级能力） | **合计** |
|--------|--------------------------|---------------------------|---------------------|---------|
| 人力成本 | ~18 万（2.5 人 x 2 月） | ~56 万（4 人均 x 4 月） | ~109 万（5.25 人均 x 6 月） | **~183 万** |
| 基础设施（开发期） | ~0.1 万 | ~0.3 万 | ~0.5 万 | **~0.9 万** |
| 基础设施（生产期） | — | ~2 万（Phase 3 后上线） | ~6 万 | **~8 万** |
| LLM API | ~0.3 万 | ~2 万 | ~5 万 | **~7.3 万** |
| 工具/许可证 | ~0.5 万 | ~0.5 万 | ~1 万 | **~2 万** |
| **阶段小计** | **~19 万** | **~61 万** | **~122 万** | **~201 万** |

> **关键数字**：总投入约 200 万，其中人力成本占 91%。这符合软件项目的一般规律——人才是最大的投资，也是最大的变量。

### 4.2 定量 ROI：人工 VOC 分析成本 vs. Prism 自动化

以一个拥有 10 万+月活用户、日产 500-2,000 条客户反馈的中型互联网公司为参照：

| 对比维度 | 传统人工方式 | Prism 自动化 | 差异 |
|---------|------------|-------------|------|
| **VOC 分析师** | 2 名全职（年薪 30-50 万/人） | 0.5 名（聚焦治理和决策，重复性工作由 AI 承接） | 节省 45-75 万/年 |
| **问题检测时间** | 1-4 周（依赖人工巡检周报） | 1-24 小时（AI 自动巡检） | 缩短 85%-95% |
| **标签覆盖率** | ~30%（预设标签无法穷举） | 85%+（涌现式标签） | 提升 ~55 个百分点 |
| **月度分析报告** | 5-8 工作日（数据收集+分析+撰写） | 1-2 工作日（AI 初稿+人工审核） | 节省 3-6 工作日/月 |
| **外部 VOC 工具年费** | 50-200 万（Qualtrics/Medallia） | 0（自建，运维成本已含在上述估算中） | 节省 50-200 万/年 |
| **Prism 年度运营成本** | — | ~15-25 万（生产环境 + LLM API） | — |
| **年化净节省** | — | — | **~80-250 万** |

需要强调的是，上表中"外部 VOC 工具年费"一项需要区分两种情况：如果组织当前使用 Qualtrics/Medallia 等商业方案，自建替代可直接节省该费用；如果当前尚未使用此类工具，则该项不计入节省，而应视为"以更低成本获得相当甚至更优的能力"。

### 4.3 定性 ROI：难以量化但战略性的回报

定量 ROI 只是冰山一角。以下三项回报难以精确定价，但对组织的长期竞争力有深远影响：

**决策速度提升。** 当产品负责人能在问题爆发的第一天（而非第四周）看到 Signal 告警，决策窗口从"被动应对"变为"主动预防"。一个被及时发现的 P0 级体验问题，可能挽回数千名即将流失的用户——每个用户的生命周期价值（LTV）乘以流失概率，就是一笔可观但难以精确计算的回报。

**产品迭代加速。** 传统流程中，从"用户反馈"到"产品改进"的信息链条是：VOC 分析师 → 周报 → 产品经理 → 需求文档 → 开发排期。每个节点都有信息损耗和时间延迟。Prism 将这条链缩短为：AI 实时分析 → Signal 直达产品经理 → 产品经理在治理工作台直接关联到相关反馈原文。信息损耗从 60%+ 降至 10% 以下。

**组织学习加速。** Prism 的 Concept Layer 是组织知识的"活档案"——每确认一个 Concept，组织对客户需求的理解就深一层；每合并一组相似标签，分析精度就提升一分。这种"越用越聪明"的知识复利结构，是传统工具（哪怕是 Qualtrics XM Discover）无法提供的。

### 4.4 与竞品的成本对比

公平的竞品对比必须包含自建方案的隐性成本——否则就是自欺欺人。

| 对比维度 | Qualtrics XM | Medallia | Prism（自建） |
|---------|-------------|----------|-------------|
| **年度许可费** | 80-200 万 | 50-150 万 | 0 |
| **实施费用** | 20-50 万（首年） | 15-40 万（首年） | 0（自有团队） |
| **年度运维/SaaS 费** | 含在许可费中 | 含在许可费中 | ~15-25 万 |
| **团队建设成本** | 0（SaaS 服务） | 0（SaaS 服务） | ~183 万（一次性，分阶段投入） |
| **团队维护成本** | 1-2 人运营 | 1-2 人运营 | 2-3 人持续迭代 |
| **定制化能力** | 低（受限于平台能力） | 中（有 API，但深度有限） | 高（完全自主） |
| **数据主权** | 数据存于第三方 | 数据存于第三方 | 完全自有 |
| **AI 能力深度** | 中（近期在追赶） | 中 | 高（AI Native 设计） |
| **Agent 能力** | 无 | 无 | 核心特性 |
| **退出成本** | 低（停止续费即可） | 低 | 中（需维护或迁移） |
| **3 年总成本** | 260-650 万 | 165-430 万 | **~230 万**（含建设 + 运维） |

> **关键洞察**：自建方案的 3 年总成本与购买 Medallia 基础版相当，但获得了完全的定制化能力、数据主权和 AI 深度——这些是在 AI 快速演进时代的战略性资产，而非可有可无的"加分项"。

但也要诚实面对自建的隐性成本：

- **团队学习曲线**：Phase 2-3 存在 2-4 周的 LLM 应用开发学习期。这已计入各阶段的时间缓冲中。
- **运维负担**：生产环境需要持续的运维投入。Phase 6 引入全栈可观测性后可以大幅降低人工运维频率，但不能降到零。
- **迭代成本**：自建意味着所有新功能都需要自己开发。好处是完全按需定制；代价是没有免费的"产品更新"。
- **机会成本**：4.5 人投入 Prism，意味着这些人不能同时做其他项目。这是管理层需要权衡的。

### 4.5 回本周期估算

采用保守场景（仅计算人力替代 + 外部工具替代，不计入难以量化的战略回报）：

| 场景 | 年化可量化回报 | 总投入 | 回本周期 |
|------|-------------|--------|---------|
| **保守**（替代 1 名分析师，无外部工具替代） | ~40 万/年 | ~201 万 | ~60 个月 |
| **中性**（替代 1.5 名分析师 + 避免购买中端工具） | ~120 万/年 | ~201 万 | **~20 个月** |
| **乐观**（替代 2 名分析师 + 替代高端工具） | ~250 万/年 | ~201 万 | **~10 个月** |

> **保守场景的补充说明**：如果仅替代 1 名分析师的重复性工作，纯财务回本需要约 5 年。但这个场景忽略了两个事实：第一，被解放的分析师可以转向更高价值的工作（策略分析、客户深访），产出价值远超其薪资；第二，Prism 的知识复利结构意味着回报是递增的——第二年的回报高于第一年，第三年高于第二年。

---

## 5. 里程碑与决策点

### 5.1 Go/No-Go 评审框架

第八章（风险分析）中识别的 R8（团队资源瓶颈）是红色风险。Go/No-Go 评审机制是这个风险的核心缓解策略——它确保管理层在每个阶段结束时都有一个"理性的退出窗口"。

每个阶段的 Go/No-Go 评审回答三个问题：

1. **交付物是否达标？** 对照验收标准，逐项核实。可以有"Nice to Have"的遗留，但"Must Have"必须完成。
2. **团队状态是否健康？** 连续加班超过 3 周是危险信号，意味着工作量估算有偏差或者效率有问题。
3. **下一阶段的前置条件是否就绪？** 技术债是否可控？架构假设是否得到验证？关键人员是否到位？

三个问题全部"是"，Go。任何一个"否"，暂停评估——可以是"修复后继续"，也可以是"调整方向"或"止损退出"。

### 5.2 各阶段决策点详情

| 阶段结束 | 评审时间点 | 关键验证问题 | Go 条件 | No-Go 后的选项 |
|---------|----------|-------------|--------|---------------|
| **Phase 1** ✓ | 第 4 周 | 微服务骨架是否健壮？技术栈是否验证通过？ | 已通过 | — |
| **Phase 2** | 第 8-10 周 | LLM 调用链是否可靠？故障转移是否生效？ | Chat/Embed API 可用 + 降级演示通过 | 已有 LLM 管理工具可独立使用；评估是否继续 |
| **Phase 2.5** | 第 12-16 周 | Agent 运行时是否稳定？Skill 契约是否合理？ | Agent 完成一次完整 ReAct 循环 | 已有 LLM 网关可独立使用；Agent 方向需重新评估 |
| **Phase 3** | 第 18-24 周 | AI 管线质量是否达标？涌现标签是否有效？ | 导入数据 + 语义检索 + Agent 分析均通过 | **核心功能可用**——已具备基础 VOC 分析能力 |
| **Phase 4** | 第 24-32 周 | Concept 治理是否被用户接受？Signal 质量如何？ | 产品经理完成至少 10 次治理操作并认为有价值 | 已有完整 VOC 分析平台；治理功能降级为"辅助建议" |
| **Phase 5** | 第 32-42 周 | 多 Agent 协作是否稳定？策略模式是否有效？ | Orchestrator 成功编排多 Specialist 完成复合任务 | 已有单 Agent + 人机共治平台；高级编排延后 |
| **Phase 6** | 第 40-54 周 | 自动化洞察是否准确？平台 API 是否安全？ | Agent 自动发现有价值 Signal + 外部调用成功 | 已有完整 VOC 平台；平台化作为独立规划 |

### 5.3 退出策略：每个阶段的"已获得 vs. 已投入"

这是管理层最关心的问题：**如果我在某个阶段选择停下来，我已经花的钱换到了什么？**

| 停止点 | 累计投入 | 已获得的可用资产 | 资产价值评估 |
|--------|---------|----------------|------------|
| Phase 1 后 | ~10 万 | 微服务骨架 + 用户认证 + LLM Provider 管理 UI | 技术原型，无直接业务价值；但 shared 库和认证模块可复用于其他项目 |
| Phase 2 后 | ~29 万 | 上述 + 统一 LLM 网关（Chat/Embed/Rerank + 故障转移） | **可独立使用的 LLM 网关**——团队内部任何 AI 项目都可以复用，替代自建或购买 LLM 中间层 |
| Phase 2.5 后 | ~51 万 | 上述 + Agent 运行时（Skill 注册表 + Agent Loop + 双身份认证） | LLM 网关 + Agent 基础设施——可以支撑各类 LLM 应用的开发，不限于 VOC 场景 |
| **Phase 3 后** | **~112 万** | **上述 + VOC 数据管线 + 语义底座 + 8 个原子 Skill** | **核心产品已形成**——可以开始试用、收集反馈、产生业务价值 |
| Phase 4 后 | ~155 万 | 上述 + Concept 治理 + Signal 自动发现 + 高级检索 | 完整的 VOC 分析平台——可对外交付或内部部署 |
| Phase 5 后 | ~193 万 | 上述 + 多 Agent 协作 + 工作流编排 + 自定义 Skill | 高级 AI 分析平台——具备显著的竞争差异化 |
| Phase 6 后 | ~201 万 | 上述 + 自动化洞察 + 开放平台 + 全栈可观测性 | 完整的 AI Native VOC 平台——Prism 愿景的完整实现 |

> **Phase 3 是"价值拐点"**——从这个阶段开始，Prism 不再是"一堆基础设施"，而是"一个可以解决真实业务问题的产品"。如果管理层需要一个"最小承诺点"，Phase 3 是合理的目标：累计投入约 112 万，获得可工作的 VOC 分析核心能力。

### 5.4 关键技术验证节点

除了业务层面的 Go/No-Go，以下技术假设需要在特定阶段得到验证。如果验证失败，需要调整方案而非硬推：

| 验证节点 | 所在阶段 | 待验证假设 | 验证方式 | 失败时的 Plan B |
|---------|---------|----------|---------|---------------|
| LiteLLM 集成 | Phase 2 | LiteLLM 能稳定覆盖目标 Provider | 集成测试 + 压力测试 | 自建轻量适配层（仅覆盖 3-5 个核心 Provider） |
| Agent ReAct 循环 | Phase 2.5 | 自建 Agent Loop 的推理质量足够 | 预定义测试场景的通过率 >80% | 引入轻量 Agent 框架（如 Instructor） |
| 涌现式标签质量 | Phase 3 | LLM 能生成有意义的涌现标签 | 人工评审覆盖率 + 一致性指标 | 回退双轨模式（预设标签为主） |
| pgvector 性能 | Phase 3-4 | 10 万向量内 P95 延迟 <100ms | 基准测试 | 提前规划向量库迁移或加分区 |
| Signal 自动产生 | Phase 4 | 分析器能发现有价值的 Signal | 产品经理评审 Signal 质量 | 降级为"辅助统计"，人工驱动发现 |

---

## 6. Key Takeaways

1. **这是一笔分期付款，不是一次性赌注。** 六阶段路线图将 ~200 万的总投入切分为 6 笔 10-50 万的分期投入，每笔投入后都有评审窗口。管理层的最大单次风险敞口不超过单阶段投入（~30 万），而非总投入的 200 万。这不是"降低了项目的预算"，而是"降低了每次决策的赌注"。

2. **人力是最大的投资，也是最大的资产。** 基础设施和 LLM API 合计只占总成本的不到 10%——决定项目成败的是"对的人做对的事"。好消息是，这些人力投入积累的不仅是代码资产，还有 LLM 应用开发、AI 管线设计、Agent 架构等前沿技能——即使项目调整方向，团队能力不会归零。

3. **Phase 3 是价值拐点。** 投入 ~112 万（总预算的 56%），获得核心 VOC 分析能力。这是向管理层建议的"最小承诺线"——承诺做到 Phase 3，在 Phase 3 验收后再决定是否继续。如果 Phase 3 效果不达预期，~112 万换到的 LLM 网关 + Agent 运行时仍然是有价值的技术资产。

4. **自建 vs. 购买不是非此即彼。** 3 年视角下，自建方案的总成本（~230 万）与 Medallia 基础版相当，但多出了完全的定制化能力、数据主权和 AI 深度。更重要的是，自建方案获得的是"能力"（团队知道如何构建 AI Native 应用），而购买方案获得的是"服务"（离开供应商就什么都没有）。在 AI 能力快速演进的今天，"能力"的价值远高于"服务"。

5. **每个数字都偏保守，每个估算都有缓冲。** 时间线含 20% 缓冲，成本按一线城市中等偏上水平估算，ROI 仅计算可直接量化的部分。如果实际表现优于保守估算——例如 LLM 成本继续下降、团队效率超出预期——回本周期可能大幅缩短。但我们宁可让管理层在审批时有"保守的预期"，也不愿制造"乐观的失望"。

6. **不投资的成本也是成本。** 如果组织选择不建 Prism，选择继续用人工+传统工具处理 VOC，需要接受的隐性代价是：问题继续以"周级"速度被检测、30% 的反馈继续落入"其他"黑洞、分析师继续把 60% 的时间花在数据收集而非洞察产出上。这些"不变的代价"不会出现在财务报表中，但会持续消耗组织的感知能力和响应速度。

---

*本章从人力、成本、时间、回报四个维度回答了管理层最关心的投资决策问题。回到全书的核心主张——Prism 不是一个"建完就交付的项目"，而是一个"越用越聪明的平台"。资源投入的终极回报不是省下了几名分析师的薪资，而是让组织获得了一种前所未有的"实时感知客户心声、快速将感知转化为行动"的系统性能力。这种能力一旦建立，就是竞争对手无法用钱买到的护城河。*
