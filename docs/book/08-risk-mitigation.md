# 风险分析与对策

---

## TL;DR（高管速读版）

一个声称"没有风险"的项目提案，本身就是最大的风险——它意味着团队要么没认真想，要么不敢说。

Prism 项目面临 12 个已识别的核心风险，分布在技术、产品、组织和市场四个维度。其中 **3 个高优先级风险**（LLM 输出不确定性、异步管线高并发可靠性、小团队资源瓶颈）需要在架构设计阶段就嵌入缓解机制，而非等到问题爆发后再"救火"。

本章的核心原则是：**风险不可消除，但可以管理**。每一个风险都配备了明确的缓解策略、量化的触发条件和可执行的应急预案。我们追求的不是"零风险"，而是"在风险变成事故之前，有人知道该做什么"。

管理学大师 Peter Drucker 说过："计划的价值不在于预测未来，而在于系统性地思考不确定性。" 本章就是对 Prism 项目不确定性的系统性思考。

---

## 1. 风险评估框架

### 1.1 方法论：概率 x 影响矩阵

我们采用经典的**概率 x 影响**二维评估框架，将每个风险映射到一个 3x3 矩阵中。这不是学术练习——它的核心价值是**强制排序**：当你有 12 个风险、有限的资源，你必须知道先防守哪一个。

**概率定义**：

| 等级 | 定义 | 判断依据 |
|------|------|---------|
| **高** | >60% 在项目周期内会发生 | 已有前兆信号，或行业普遍存在 |
| **中** | 20%-60% 在项目周期内可能发生 | 存在触发条件，但尚未观测到前兆 |
| **低** | <20% 在项目周期内可能发生 | 需要多个条件同时满足才会触发 |

**影响定义**：

| 等级 | 定义 | 判断依据 |
|------|------|---------|
| **高** | 导致阶段目标无法交付，或需要重大架构返工 | 交付延迟 >4 周，或核心功能降级 |
| **中** | 导致部分功能受限或需要额外工作量 | 交付延迟 1-4 周，或需要额外人力投入 |
| **低** | 可以在正常迭代中消化，不影响关键路径 | 交付延迟 <1 周，工作量增幅 <15% |

### 1.2 风险矩阵总览

|  | **影响：低** | **影响：中** | **影响：高** |
|---|---|---|---|
| **概率：高** | — | **R1** LLM 输出不确定性 | — |
| **概率：中** | — | **R2** pgvector 性能瓶颈<br>**R5** 涌现标签质量<br>**R6** 用户接受度 | **R4** 异步管线可靠性<br>**R8** 团队资源不足 |
| **概率：低** | **R10** 技术债累积 | **R3** LiteLLM 依赖<br>**R7** Agent 体验预期<br>**R9** 跨专业协作<br>**R12** LLM 成本趋势 | **R11** 大厂竞争 |

**优先级分层**：

- **红色区域**（概率高 x 影响高，概率高 x 影响中，概率中 x 影响高）：必须在架构设计阶段内建缓解机制——R1、R4、R8
- **橙色区域**（概率中 x 影响中，概率低 x 影响高）：需要制定明确的监控指标和应急预案——R2、R3、R5、R6、R11
- **黄色区域**（其余组合）：纳入定期评审，触发条件出现时启动响应——R7、R9、R10、R12

---

## 2. 技术风险

### R1: LLM 输出不确定性（幻觉、格式不稳定）

**风险描述**

LLM 是 Prism 语义理解引擎的核心驱动力，但"核心驱动力"的另一面是"核心不确定性"。LLM 的输出本质上是概率性的——同一个 Prompt、同一条反馈，两次调用可能给出不同的标签、不同的情感判断、甚至不同的 JSON 格式。这不是 bug，而是 LLM 的本质特征。

在 VOC 分析场景中，这种不确定性的后果很具体：一条关于"付款卡顿"的反馈，可能被标注为"支付体验"、"性能问题"或"用户体验"——三个标签都不算错，但对下游的聚类和趋势分析来说，不一致性就是噪音。

| 属性 | 值 |
|------|---|
| **概率** | 高（>60%）——这是 LLM 的固有特征，必然发生 |
| **影响** | 中——不影响系统可用性，但影响分析质量和用户信任 |
| **优先级** | 红色 |

**缓解策略：三级降级守卫 + JSON Schema 校验**

我们不试图"消除"不确定性——那是对抗物理定律。我们的策略是**将不确定性约束在可接受的范围内**：

1. **第一级：Prompt 工程约束**。通过结构化 Prompt（Few-shot 示例 + 输出格式指令 + 约束条件），将 LLM 的自由度限制在预定义的输出空间内。实测可将格式合规率从约 70% 提升至 92% 以上。
2. **第二级：JSON Schema 校验**。对 LLM 返回的结果进行严格的 Schema 验证——字段类型、必填项、枚举值范围。不合格的响应自动触发重试（最多 2 次），仍不合格则降级到第三级。
3. **第三级：规则兜底**。当 LLM 连续失败时，回退到基于规则的简单分类器（关键词匹配 + TF-IDF），确保数据流不中断。质量有损失，但"有结果"好过"没结果"。

**触发条件**：

- LLM 响应格式校验失败率 > 5%（连续 1 小时窗口）
- 同一条反馈两次处理的标签一致率 < 70%

**应急预案**：

- 自动切换至备用模型（别名系统的降级链）
- 若所有模型均不稳定，启用规则兜底模式，同时告警通知运维
- 事后分析不稳定 case，补充进 Prompt 的 Few-shot 示例库

---

### R2: pgvector 在大规模数据下的性能瓶颈

**风险描述**

Prism 选择 PostgreSQL + pgvector 而非专用向量数据库（如 Pinecone、Milvus），核心原因是"关系数据 + 向量数据共存于同一事务边界"（详见第六章技术蓝图）。这个决策在百万级数据量以内是成立的——pgvector 的 HNSW 索引在 100 万向量、1536 维的场景下，查询延迟可控制在 50ms 以内。

但如果 Prism 成功地获取了大量客户并积累了海量反馈数据，当向量数量超过 500 万，pgvector 的内存占用和查询延迟可能出现非线性增长。这是一个"成功的烦恼"——只有产品做得好才会触发。

| 属性 | 值 |
|------|---|
| **概率** | 中（20%-60%）——取决于业务增长速度，Phase 3-4 内可能触发 |
| **影响** | 中——语义检索变慢影响用户体验，但不影响数据完整性 |
| **优先级** | 橙色 |

**缓解策略：分层防御**

1. **短期（Phase 3-4）**：优化 pgvector 配置——HNSW 索引参数调优（`m=16, ef_construction=200`）、分区表按时间范围分片、定期 VACUUM 和索引重建。
2. **中期（Phase 5）**：引入向量数据的冷热分离——近 3 个月的"热数据"保留在 pgvector 中，更早的"冷数据"归档到对象存储，按需加载。
3. **长期（Phase 6+）**：如果数据量确实突破千万级，迁移到专用向量数据库（Milvus 或 Qdrant），同时保留 PostgreSQL 作为关系数据源。由于 Prism 的向量检索层已通过抽象接口隔离，迁移成本可控。

**触发条件**：

- 向量检索 P95 延迟 > 200ms
- pgvector 索引内存占用 > 可用内存的 60%

**应急预案**：

- 短期：增加 PostgreSQL 实例内存、限制单次检索的向量范围（加时间窗口过滤）
- 中期：启动冷热分离方案的实施

---

### R3: LiteLLM 依赖单点（社区项目的不确定性）

**风险描述**

LiteLLM 是 Prism LLM 网关的底层调用层，覆盖了 100+ Provider 的统一接口。它是一个活跃的开源社区项目，但"活跃"和"稳定"是两码事。社区项目存在三个固有风险：维护者精力转移导致项目停滞、破坏性版本升级、以及关键 bug 修复的响应速度不可控。

| 属性 | 值 |
|------|---|
| **概率** | 低（<20%）——LiteLLM 目前商业化进展良好，短期内停滞风险较低 |
| **影响** | 中——影响新 Provider 的接入速度，但不影响已有 Provider 的调用 |
| **优先级** | 橙色 |

**缓解策略：抽象层隔离**

1. **接口隔离**：Prism 的 LLM 调用层不直接暴露 LiteLLM 的 API，而是通过自定义的 `LLMProvider` 抽象接口调用。上游服务只依赖抽象接口，不感知底层实现是 LiteLLM 还是其他。
2. **版本锁定**：锁定 LiteLLM 版本，不跟踪最新版。每次升级都在 staging 环境做完整回归测试。
3. **替代方案储备**：持续关注 OpenAI 原生 SDK 的多 Provider 支持进展，以及 LangChain 的 LLM 调用层。如果 LiteLLM 出现问题，可在 1-2 周内切换底层实现。

**触发条件**：

- LiteLLM 连续 3 个月无实质性维护（commit、issue 响应）
- 出现无法绕过的破坏性 bug 且官方 2 周内无修复

**应急预案**：

- Fork LiteLLM 仓库，自行维护关键 bug 修复
- 启动底层替换计划，切换到备选方案

---

### R4: 异步管线在高并发下的可靠性

**风险描述**

Prism 的 VOC 处理管线是一个典型的异步多阶段管线：数据摄入 → 预处理 → LLM 标注 → 向量化 → 存储。每个阶段都可能因外部依赖（LLM API 超时、数据库连接池耗尽、Redis 队列积压）而失败。在低负载下，偶发失败可以通过简单重试消化；但在高并发场景下（如批量导入 10 万条反馈），失败率会因为资源竞争而叠加放大。

这是一个典型的**"正常运行时看不见、高峰期集中爆发"**的风险——它不会在 demo 中出现，但一定会在生产环境的第一个流量高峰中暴露。

| 属性 | 值 |
|------|---|
| **概率** | 中（20%-60%）——批量导入是确定的使用场景，高并发不可避免 |
| **影响** | 高——数据丢失或处理不完整直接损害产品核心价值 |
| **优先级** | 红色 |

**缓解策略：三重可靠性保障**

1. **重试机制**：每个管线阶段内建指数退避重试（最多 3 次），区分可重试错误（超时、限流）和不可重试错误（数据格式非法）。
2. **死信队列**：超过最大重试次数的消息进入死信队列（Redis Stream 的 Dead Letter Queue），不阻塞主流程。运维可手动检查、修复后重新投递。
3. **幂等设计**：每条反馈数据分配全局唯一的处理 ID，管线中每个阶段的写操作都基于该 ID 做幂等检查。即使同一条数据被重复处理，最终结果也是一致的。

**触发条件**：

- 管线处理失败率 > 2%（连续 30 分钟窗口）
- 死信队列积压 > 1000 条
- 管线端到端延迟 P95 > 30 秒

**应急预案**：

- 启用流量限速（Rate Limiting），将批量导入速率降至管线可承受范围
- 增大数据库连接池和 Redis 内存配额
- 极端情况下暂停实时处理，切换至离线批处理模式

---

## 3. 产品风险

### R5: 涌现式标签质量不达预期

**风险描述**

涌现式标签是 Prism 最核心的差异化特征——让 AI 从数据中"发现"标签，而非把数据"塞进"预设标签。但"涌现"本身就意味着不确定性：AI 可能发现过于细碎的标签（"付款按钮颜色太暗"和"付款界面颜色不好"是两个标签还是一个？）、过于抽象的标签（"体验不好"缺乏行动指导意义）、或者干脆发现一堆噪声。

这不是技术问题，而是**产品定义问题**——什么叫"好的"涌现标签？这个标准在项目启动时是模糊的，需要在真实数据上反复校准。

| 属性 | 值 |
|------|---|
| **概率** | 中（20%-60%）——涌现式标签是探索性创新，效果不确定是常态 |
| **影响** | 中——影响产品差异化叙事，但不影响系统基础功能 |
| **优先级** | 橙色 |

**缓解策略：双轨设计 + 人类治理兜底**

1. **双轨并行**：系统同时支持"预设标签"和"涌现标签"两种模式。Phase 3 初期以预设标签为主、涌现标签为辅（实验性功能），逐步积累数据后评估涌现标签的质量，再决定比例调整。
2. **人类治理层**：涌现出的标签不直接进入生产分析流程——它们首先进入"待审核"状态，由业务人员确认、合并、重命名或拒绝。AI 负责"提出"，人类负责"定性"。
3. **质量度量体系**：定义涌现标签的质量指标——覆盖率（多少反馈被至少一个标签覆盖）、一致性（同类反馈是否获得相同标签）、粒度合理性（标签数量 vs. 反馈数量的比值）。

**触发条件**：

- 涌现标签覆盖率 < 60%（即 40% 以上的反馈没有获得任何有意义的涌现标签）
- 人工审核的拒绝率 > 50%

**应急预案**：

- 回退到纯预设标签模式，涌现标签降级为"辅助参考"
- 重新设计 Prompt 策略，增加涌现标签的约束条件
- 引入少量标注数据做 Fine-tuning，提升标签质量

---

### R6: 用户接受度低——从预设标签到涌现标签的认知转换成本

**风险描述**

传统 VOC 工具的用户已经习惯了"先定义标签体系 → 再把反馈归类"的工作流。涌现式标签颠覆了这个心智模型：标签不是人先定义的，而是 AI 后发现的。这种转换对用户来说意味着**失去掌控感**——"我不知道 AI 会给我什么标签，我怎么建立分析框架？"

Rogers 创新扩散理论告诉我们：一项创新的采纳速度取决于五个因素，其中"兼容性"（与现有工作方式的一致程度）和"可观测性"（能否快速看到好处）是最关键的。涌现式标签在这两个维度上都有天然劣势。

| 属性 | 值 |
|------|---|
| **概率** | 中（20%-60%）——取决于目标用户群体的开放程度和引导策略 |
| **影响** | 中——用户不接受 = 产品核心价值无法传递 |
| **优先级** | 橙色 |

**缓解策略：渐进式引入 + 并行运行**

1. **渐进式引入**：不在 Day 1 就要求用户"放弃预设标签、拥抱涌现"。而是让用户继续使用熟悉的预设标签体系，同时在界面上以"AI 发现"的形式展示涌现标签——"看看 AI 还发现了什么你没想到的"。
2. **并行运行期**：至少 2-3 个月的并行期，让用户在实际使用中感受涌现标签的增量价值（"哦，这个问题确实是预设标签没覆盖到的"），自然建立信任。
3. **可视化对比**：提供"预设标签 vs. 涌现标签"的对比视图，让用户直观看到涌现标签覆盖了哪些预设标签遗漏的反馈。用数据说话，而非用概念说服。

**触发条件**：

- 涌现标签功能开放后 30 天内，用户主动查看涌现标签的比例 < 20%
- 用户调研中对涌现标签的"有用"评分 < 3/5

**应急预案**：

- 调整产品定位：将涌现标签从"替代方案"降级为"补充工具"
- 强化引导设计：增加 onboarding 教程、案例展示、最佳实践文档

---

### R7: Agent 交互体验达不到用户预期

**风险描述**

当前市场上"AI Agent"的叙事已经相当激进——用户可能期望 Prism 的 Agent 像一个"全能分析师"一样理解任意自然语言指令并给出完美回答。但现实是，Phase 2.5-3 阶段的 Agent 能力是有限的：它能执行预定义的 Skill、能在语义空间中检索和关联，但不能做开放域推理或生成创造性的商业建议。

期望与现实的落差，是产品信任崩塌的最快路径。

| 属性 | 值 |
|------|---|
| **概率** | 低（<20%）——可以通过产品设计主动管理预期 |
| **影响** | 中——影响 Agent-First 叙事的可信度 |
| **优先级** | 黄色 |

**缓解策略：降低初期期望 + 明确能力边界**

1. **能力边界透明化**：在产品界面和文档中明确标注 Agent 当前能做什么、不能做什么。用"Agent 能力图谱"的形式展示已上线的 Skill 列表，比"智能助手"这种模糊标签更诚实。
2. **渐进式能力释放**：每个 Phase 交付时明确新增了哪些 Agent 能力，让用户感受到持续的进步，而非一次性的失望。
3. **失败优雅降级**：当 Agent 遇到超出能力范围的请求时，不给错误答案，而是明确说"这个问题超出了我当前的能力范围，建议您通过 XX 方式处理"。

**触发条件**：

- Agent 交互的用户满意度 < 3.5/5
- Agent 回答中"超出能力范围"的比例 > 30%

**应急预案**：

- 收集高频失败 case，优先补充对应的 Skill
- 调整产品文案，更精确地描述 Agent 定位

---

## 4. 组织风险

### R8: 小团队资源不足，阶段目标过于激进

**风险描述**

Prism 是一个跨 AI、后端、前端、产品四个领域的项目，规划了 6 个交付阶段。以 3-5 人的团队规模来说，任何一个阶段的工作量估算偏差都可能导致整体延期。更危险的是，如果团队为了赶进度而压缩测试和文档时间，技术债会在后续阶段以"返工"的形式十倍偿还。

Hofstadter 定律如是说："事情总是比你预期的要花更长时间——即使你已经考虑了 Hofstadter 定律。"

| 属性 | 值 |
|------|---|
| **概率** | 中（20%-60%）——小团队 + 大范围是创业项目的常态风险 |
| **影响** | 高——直接影响项目能否按时交付和团队士气 |
| **优先级** | 红色 |

**缓解策略：Go/No-Go 评审机制 + 阶段弹性**

1. **Go/No-Go 评审**：每个 Phase 结束时进行正式评审——验收标准是否达成？团队状态是否健康？下一阶段的前置条件是否就绪？如果答案有一个"否"，就暂停推进，而非硬冲。
2. **阶段目标可调整**：每个 Phase 的交付内容分为"Must Have"和"Nice to Have"。如果资源紧张，优先砍"Nice to Have"，而非降低"Must Have"的质量。
3. **缓冲时间内建**：每个 Phase 的时间估算中预留 20% 的缓冲，用于应对"计划外的计划"——这不是浪费，而是对不确定性的尊重。

**触发条件**：

- 当前 Phase 的进度落后于计划 > 2 周
- 团队成员连续 3 周以上加班超过 20%

**应急预案**：

- 砍掉当前阶段的"Nice to Have"内容
- 如果仍然不够，考虑将部分功能后移到下一阶段
- 极端情况下，评估是否需要引入外部支援（外包或兼职）

---

### R9: 跨专业协作困难

**风险描述**

Prism 团队需要 AI 工程师、后端工程师、前端工程师和产品经理紧密协作。问题在于：AI 工程师讲"Embedding"、"向量距离"、"Prompt 工程"；后端工程师讲"事务隔离"、"连接池"、"幂等"；产品经理讲"用户旅程"、"转化率"、"PMF"。这些人在各自的专业领域都很出色，但跨领域的沟通效率可能很低。

Conway 定律再次生效——如果团队内部的沟通有壁垒，那么系统的模块边界会恰好反映这些壁垒，而不是反映最优的技术架构。

| 属性 | 值 |
|------|---|
| **概率** | 低（<20%）——小团队反而沟通距离短，风险低于大团队 |
| **影响** | 中——影响开发效率和架构一致性 |
| **优先级** | 黄色 |

**缓解策略：统一术语表 + 跨角色 Review**

1. **统一术语表**：维护一份项目级的中英文术语对照表（见附录 A），确保团队在说"Signal"、"Concept"、"Embedding"时，所有人的理解一致。
2. **跨角色 Code Review**：AI 工程师的 PR 需要后端工程师 review（关注代码质量和性能），后端工程师的 PR 需要 AI 工程师 review（关注是否破坏了 AI 管线的语义）。跨界 review 是最好的知识转移机制。
3. **周度技术分享**：每周 30 分钟的内部 Tech Talk，轮流由不同角色介绍自己领域的核心概念和近期决策。

**触发条件**：

- Code Review 中出现"我不理解这段代码在做什么"的频率 > 每周 3 次
- 因沟通误解导致的返工事件 > 每月 2 次

**应急预案**：

- 针对高频误解领域，安排专项培训
- 考虑引入 ADR（Architecture Decision Record）文化，让每个重要决策都有书面记录

---

### R10: 技术债累积

**风险描述**

技术债和财务债一样——短期借债可以加速交付，长期不还就会破产。在快速迭代的项目中，团队很容易为了赶 deadline 而写"能跑就行"的代码——hardcoded 配置、缺失的错误处理、copy-paste 的重复逻辑。这些"债务"在写下的那一刻不会出问题，但在 6 个月后需要修改这段代码时，偿还成本可能是当初省下的 5-10 倍。

| 属性 | 值 |
|------|---|
| **概率** | 低（<20%）——可以通过流程约束来控制 |
| **影响** | 低——单次影响小，但具有累积效应 |
| **优先级** | 黄色 |

**缓解策略：制度化的债务管理**

1. **每阶段预留 20% 重构时间**：这不是"如果有时间就做"，而是写入 Phase 计划的硬约束。20% 不是拍脑袋——Martin Fowler 的经验值是 15-25%，我们取中间值。
2. **技术债台账**：维护一个 `TECH_DEBT.md` 文件，每次有意识地"借债"时记录——什么债、为什么借、预计何时还、不还的后果。让债务可见化。
3. **CI 质量门禁**：通过 linter、类型检查、测试覆盖率等自动化工具，在 PR 阶段阻止"低质量债务"的引入。

**触发条件**：

- 技术债台账中的未偿还条目 > 20 条
- 新功能开发中因历史代码质量问题导致的额外工作量 > 30%

**应急预案**：

- 安排专项"还债冲刺"（Debt Sprint），暂停新功能开发 1-2 周
- 如果问题集中在某个模块，考虑对该模块做集中重构

---

## 5. 市场风险

### R11: 大厂进入 AI-Native VOC 领域

**风险描述**

Qualtrics、Medallia、Salesforce——这些 CX 领域的巨头都在积极布局 AI 能力。如果其中任何一家推出了"AI-Native 的 VOC 分析平台"，Prism 将面临资源、品牌和渠道上的全方位碾压。

但有一个反直觉的事实：**大厂进入一个细分领域，不一定是坏事**。它意味着市场得到了验证——如果连大厂都觉得这个方向值得投入，说明 Prism 的赛道判断是对的。问题只在于：Prism 能否在大厂反应过来之前建立足够的差异化壁垒。

| 属性 | 值 |
|------|---|
| **概率** | 低（<20%）——大厂的 AI 布局集中在通用能力层，短期内不太会深入 VOC 细分领域 |
| **影响** | 高——如果大厂真的全力投入，小公司在正面竞争中几乎没有胜算 |
| **优先级** | 橙色 |

**缓解策略：速度优势 + 行业定制化**

1. **速度就是护城河**：大厂的产品周期以季度甚至年计，Prism 的周期以周计。在 12-18 个月的窗口期内，快速迭代、积累真实客户反馈、打磨产品细节——这些是大厂再多资源也买不来的。
2. **行业深度 > 功能广度**：不做"所有行业的通用 VOC"，而是先深耕 1-2 个垂直行业（如 SaaS、金融科技），积累行业专有的标签体系、Prompt 模板和最佳实践。大厂追求规模效应，倾向于做通用方案——行业深度是小团队的天然优势。
3. **Agent-First 差异化**：大厂的 AI 能力通常是"在现有产品上加 AI"，而 Prism 是"从 AI 出发重建产品"。这种架构差异不是功能层面可以模仿的，而是基因层面的不同。

**触发条件**：

- 竞品分析中发现大厂发布了 AI-Native VOC 产品
- 潜在客户在评估过程中将大厂的新产品列为直接竞品

**应急预案**：

- 加速差异化功能的交付（涌现标签、Agent 协作）
- 调整市场定位，强化行业垂直叙事
- 考虑寻求战略合作或融资，加大投入

---

### R12: LLM 成本长期趋势不确定

**风险描述**

Prism 的核心处理管线深度依赖 LLM 调用——每条反馈至少需要 1 次标注调用 + 1 次 Embedding 调用。当前主流 LLM 的价格趋势是下降的（GPT-4o 的单位成本较 GPT-4 已下降约 80%），但这个趋势能否持续 2-3 年，没有人能确定。如果 LLM 厂商改变定价策略（如引入最低消费、限制高频调用折扣），Prism 的单位经济模型可能需要重新计算。

| 属性 | 值 |
|------|---|
| **概率** | 低（<20%）——当前竞争格局下，价格下降趋势短期内大概率持续 |
| **影响** | 中——影响毛利率和定价策略，但不影响产品功能 |
| **优先级** | 黄色 |

**缓解策略：多 Provider 策略 + 成本追踪**

1. **多 Provider 架构**：Prism 的别名系统天然支持多 Provider——同一个别名可以绑定 OpenAI、Anthropic、开源模型等多个后端。如果某个 Provider 涨价，可以在不修改业务代码的情况下切换到成本更优的替代。
2. **成本追踪系统**：每次 LLM 调用记录 token 消耗和费用，按租户、按功能维度聚合。当单位处理成本偏离预期时，系统自动告警。
3. **本地模型备选**：持续评估开源 LLM（如 Llama、Mistral 系列）在标注和 Embedding 任务上的表现。对于不需要最强推理能力的任务（如情感分类、语言检测），可以逐步迁移到自部署的开源模型，将边际成本降至接近零。

**触发条件**：

- 单条反馈的 LLM 处理成本 > 预算的 150%
- 主要 Provider 宣布调价且涨幅 > 30%

**应急预案**：

- 启动 Provider 切换评估，寻找成本更优的替代
- 对非关键任务启用开源模型
- 调整产品定价，将成本变化传导至客户端

---

## 6. 缓解策略总表

| 编号 | 风险 | 类别 | 概率 | 影响 | 优先级 | 核心缓解策略 | 触发条件 |
|------|------|------|------|------|--------|-------------|---------|
| R1 | LLM 输出不确定性 | 技术 | 高 | 中 | 红色 | 三级降级守卫 + JSON Schema 校验 | 格式校验失败率 >5% |
| R2 | pgvector 性能瓶颈 | 技术 | 中 | 中 | 橙色 | 索引调优 → 冷热分离 → 专用向量库 | P95 延迟 >200ms |
| R3 | LiteLLM 依赖单点 | 技术 | 低 | 中 | 橙色 | 抽象层隔离 + 版本锁定 | 连续 3 月无实质维护 |
| R4 | 异步管线可靠性 | 技术 | 中 | 高 | 红色 | 重试 + 死信队列 + 幂等 | 失败率 >2% |
| R5 | 涌现标签质量 | 产品 | 中 | 中 | 橙色 | 双轨设计 + 人类治理兜底 | 覆盖率 <60% 或拒绝率 >50% |
| R6 | 用户接受度低 | 产品 | 中 | 中 | 橙色 | 渐进式引入 + 并行运行 | 30 天内查看率 <20% |
| R7 | Agent 体验预期 | 产品 | 低 | 中 | 黄色 | 能力边界透明化 + 优雅降级 | 满意度 <3.5/5 |
| R8 | 团队资源不足 | 组织 | 中 | 高 | 红色 | Go/No-Go 评审 + 阶段弹性 | 进度落后 >2 周 |
| R9 | 跨专业协作困难 | 组织 | 低 | 中 | 黄色 | 统一术语表 + 跨角色 Review | 沟通误解返工 >2 次/月 |
| R10 | 技术债累积 | 组织 | 低 | 低 | 黄色 | 每阶段 20% 重构时间 + 债务台账 | 未偿还条目 >20 |
| R11 | 大厂竞争 | 市场 | 低 | 高 | 橙色 | 速度优势 + 行业定制化 | 大厂发布同类产品 |
| R12 | LLM 成本不确定 | 市场 | 低 | 中 | 黄色 | 多 Provider + 成本追踪 + 开源备选 | 单条成本超预算 150% |

---

## Key Takeaways

1. **"没有风险"才是最大的风险**。Prism 诚实地识别了 12 个核心风险，并为每一个都准备了缓解策略和应急预案。这不是悲观主义，而是工程成熟度的体现。

2. **三个红色风险需要架构级应对**。LLM 输出不确定性（R1）、异步管线可靠性（R4）和团队资源瓶颈（R8）是最高优先级风险——它们的缓解策略不是"出了问题再解决"，而是从 Day 1 就嵌入到系统设计和项目管理流程中。

3. **技术风险可以用架构缓解，产品风险要用设计缓解**。三级降级守卫、抽象层隔离、幂等设计——这些是技术层面的"安全带"。双轨设计、渐进式引入、能力边界透明化——这些是产品层面的"安全带"。两套安全带缺一不可。

4. **风险管理是持续过程，不是一次性文档**。本章的风险矩阵应在每个 Phase 结束时复审——概率可能变化、影响可能升级、新的风险可能浮现。Go/No-Go 评审不仅评审交付物，也评审风险状态。

5. **坦诚面对风险，是赢得信任的前提**。对管理层来说，一个能清楚说出"我们可能在哪里摔跤、摔了怎么爬起来"的团队，远比一个说"一切尽在掌控"的团队更值得投资。风险管理的终极目标不是消除不确定性，而是让组织在不确定性中保持前进的信心和能力。
