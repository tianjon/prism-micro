# Agent-First 设计哲学

---

## TL;DR（高管速读版）

AI Agent 正在从"帮你打字的助手"进化为"独立完成任务的协作者"。这不是五年后的远景，而是 2025-2026 年正在发生的产业拐点。Anthropic MCP、OpenAI Function Calling、LangChain Agent 已经将 Agent 从实验室推向了工业化量产。

Prism 的核心赌注是：**Agent 不是系统的附加功能，而是系统的基础设施**。就像互联网不是给邮局加了个网站，而是重新定义了"通信"——Agent-First 不是给传统 VOC 加了个聊天框，而是重新定义了"谁在使用系统、如何使用系统"。

本章回答三个问题：
- **为什么**：Agent-First 不是可选的——不做的代价远高于做的成本
- **是什么**：Prism 的 Agent 哲学——身份化用户、契约化能力、可组合架构
- **怎么做**：从 Skill 注册表到 Agent Loop 到多 Agent 协作的完整技术路径

关键结论：在 Agent 时代，**系统的价值不取决于它有多少功能，而取决于它能被多少 Agent 编排**。

---

## 1. 为什么 Agent-First 不是可选的

### 1.1 AI Agent 的能力拐点：从"工具"到"协作者"

过去十年，AI 在企业中的角色一直是"工具"——你给它一个输入，它给你一个输出。翻译工具把英文变成中文，推荐系统把用户变成点击，分类模型把工单丢进预设的桶里。每一个环节都需要人类告诉 AI"现在该做什么"。

2024-2025 年，一个质变正在发生。

以 Anthropic 的 Claude 为例：它不再只是"回答问题"，而是能**理解任务目标、制定执行计划、选择合适的工具、根据中间结果调整策略、最终交付完整成果**。这不是"更聪明的搜索框"，这是一个能独立工作的协作者。

用一个管理者更熟悉的类比：**过去的 AI 像计算器——你按哪个键它算什么；现在的 AI 像实习生——你告诉它目标，它自己规划怎么做，中间遇到问题会问你，最后交付一份可用的成果。**

这个拐点的技术根源是三件事的同时成熟：

| 能力 | 过去 | 现在 | 影响 |
|------|------|------|------|
| **推理能力** | 模式匹配 | 链式推理（Chain-of-Thought） | Agent 能把复杂任务分解为多个步骤 |
| **工具使用** | 固定管线 | 动态工具选择（Function Calling） | Agent 能根据情况选择最合适的工具 |
| **上下文管理** | 短记忆 | 长上下文 + 外部记忆 | Agent 能在多轮交互中保持连贯性 |

当这三种能力同时跨过可用阈值，AI 就不再是"工具"，而是"协作者"。就像蒸汽机不只是"更快的马"——它重新定义了"动力"的含义；AI Agent 不只是"更快的分析师"——它重新定义了"谁在分析"的含义。

### 1.2 Agentic AI 趋势：从实验室到工业化

Agent 不再是论文里的概念。2024-2025 年，三个标志性事件宣告了 Agent 的工业化时代：

**Anthropic MCP（Model Context Protocol）**：Anthropic 在 2024 年底发布了 MCP 协议，定义了 Agent 与外部工具之间的标准通信协议。这就像 USB 接口统一了外设连接——有了 MCP，任何系统只要实现标准接口，就能被任何 Agent 调用。这不是某一家公司的产品特性，而是一个行业基础设施级的标准。

**OpenAI Function Calling → Assistants API**：OpenAI 从 Function Calling 到 Assistants API，再到 GPT Actions，一步步把"Agent 能力"从 API 级别提升到了平台级别。全球数百万开发者已经在用这套协议构建 Agent 应用。

**LangChain / LangGraph 生态**：LangChain 从一个工具库发展成了 Agent 开发的事实标准框架。LangGraph 引入了状态机模型，让复杂的多步骤 Agent 工作流变得可管理、可调试。GitHub 上超过 10 万星的生态规模意味着——Agent 开发不再依赖少数专家，而是有了成熟的工具链和社区支持。

这三件事传递的信号是一致的：**Agent 不是"未来的可能性"，而是"现在的基础设施"。** 不围绕 Agent 设计系统的企业，就像 2010 年不围绕移动端设计产品的企业——不是"落后"，而是"在一个正在消失的赛道上加速"。

### 1.3 不做 Agent-First 的代价：后期改造成本的指数级增长

让我们诚实地看一下"先不管 Agent，以后再加"这条路的真实成本。

一个不考虑 Agent 的 VOC 系统，会做出以下"自然而然"的设计决策：

- 认证系统只考虑人类登录（JWT），没有 API Key 体系
- API 设计围绕前端页面需求，而非原子能力组合
- 权限模型是粗粒度的角色（admin/viewer），没有细粒度的能力声明
- 审计日志只记录"谁登录了"，不记录"谁调用了什么工具"
- 数据接口返回"渲染好的结果"，而非"可组合的原始数据"

每一个决策单独看都是"合理的简化"。但当你在 v3 试图加入 Agent 能力时，你需要：

1. **重写认证系统**：从只支持 JWT 扩展到同时支持 API Key，并统一两条认证路径的下游处理。影响面：全部 API 端点。
2. **重写 API 层**：从"面向页面"重构为"面向能力"，原有的聚合接口需要拆成原子接口。影响面：全部前端代码 + 全部后端路由。
3. **重写权限模型**：从粗粒度角色扩展为角色 + 能力 + 约束的三层模型。影响面：数据库 schema + 全部中间件。
4. **重写审计日志**：从"谁登录了"扩展为"谁调用了什么、传了什么参数、花了多少成本"。影响面：全部服务层代码。
5. **重建数据接口**：从"返回渲染结果"改为"返回可组合数据"。影响面：全部查询逻辑 + 全部前端适配。

这五项改造不是并行的——它们相互依赖。改认证必须同时改权限，改权限必须同时改审计，改 API 必须同时改前端。这不是"重构"，这是**在飞行中更换发动机**。

根据行业经验，**架构级改造的成本是初始设计成本的 5-10 倍，而且在改造期间系统处于高风险状态——新旧系统并存、边界模糊、回归测试不可靠。** Martin Fowler 称之为"Strangler Fig Pattern"的理想场景，但现实中很少有团队能干净地执行。

这就是为什么 Agent-First 不是"锦上添花"，而是"地基选择"。地基选错了，不是加固能解决的——你需要推倒重来。

---

## 2. Prism 的 Agent 哲学

### 2.1 Agent 是"有身份的用户"，不是"后台脚本"

大多数系统在加入 AI 能力时，会把 Agent 当作一个"内部服务"——它运行在后台，用系统内部的 admin 账号调用 API，没有独立身份，没有独立权限，操作不可追溯。

这就像给公司请了一个实习生，但不给他发工牌、不给他分工位、不给他独立的门禁卡。他干了什么没人知道，出了问题没法定责，干得好也没法度量。

Prism 的做法完全不同：**Agent 在系统中拥有与人类用户完全对等的身份地位。**

| 维度 | 人类用户 | AI Agent |
|------|---------|---------|
| 身份 | 用户名 + 密码 → JWT | API Key → Principal |
| 权限 | 角色 + 能力 | 角色 + 能力（通常更窄） |
| 配额 | 请求频率限制 | 请求频率 + token 消耗 + 成本上限 |
| 审计 | 操作日志 | 操作日志 + 完整调用链 |
| 生命周期 | 注册 → 使用 → 注销 | 签发 → 使用 → 轮换/撤销 |

这个设计的核心价值不在于技术精巧，而在于**组织治理**。当 CEO 问"上周的分析报告是谁做的"，系统能清晰地回答："分析由 Agent-Alpha 执行，触发者是产品经理张三，使用了 vector_search 和 get_tags 两个工具，消耗了 12,000 tokens，成本 0.08 美元，完整调用链见审计日志。"

**可追溯性是信任的基础。没有身份的 Agent，就像没有署名的审计报告——技术上能跑，组织上没法用。**

### 2.2 Skill 是"有契约的能力"，不是"裸 API 调用"

在 Prism 的设计中，Agent 不直接调用 API。它通过 **Skill**（技能）来获取能力。

Skill 和裸 API 的区别，就像"合同"和"口头承诺"的区别：

| 维度 | 裸 API 调用 | Skill |
|------|-----------|-------|
| 接口定义 | 可能有文档，可能没有 | JSON Schema 声明式定义，强类型 |
| 输入输出 | 取决于调用者是否传对参数 | 契约化——输入 schema 不对就拒绝，输出 schema 有保证 |
| 权限 | 调用者自己管 | Skill 声明需要什么权限，运行时自动校验 |
| 成本 | 调用后才知道花了多少 | Skill 声明预估成本，运行时实时追踪 |
| 版本 | URL 里的 v1/v2 | 语义化版本 + 兼容性声明 |
| 可发现性 | 读文档 | Agent 运行时查询注册表，自动发现可用工具 |

为什么这很重要？因为 **Agent 的工具选择是 LLM 在运行时做出的决策**。如果工具的描述模糊、输入输出不清晰、权限边界不明确，LLM 就会做出错误的选择——调用错误的工具、传入错误的参数、超出权限范围。

Skill 的契约化设计，确保了 Agent 在"做选择"时有充足的、结构化的信息。这就像给实习生发了一本详细的《工作手册》——不是限制他的创造力，而是确保他在正确的边界内发挥。

### 2.3 类比：从 CGI 脚本到 RESTful API 的范式转换

如果你在 2000 年做过 Web 开发，你一定还记得 CGI 脚本的时代：每个页面请求触发一个独立的脚本，脚本直接操作数据库、直接输出 HTML，没有统一的接口规范、没有状态管理、没有错误处理约定。它能跑，但它不能"被组合"。

后来 REST 出现了。它说：**资源是名词，操作是动词（GET/POST/PUT/DELETE），接口有统一的规范，输入输出有标准的格式**。同样是 HTTP 调用，但因为有了"契约"，系统从"只能被人类通过浏览器访问"变成了"可以被任何客户端编排"。

Prism 的 Agent-First 设计，正在进行一次类似的范式转换：

```
CGI 时代   → "能跑，但只有写脚本的人知道怎么用"
REST 时代  → "标准化接口，任何客户端都能调用"
Agent 时代 → "声明式能力，任何 Agent 都能组合编排"
```

从 CGI 到 REST，关键变化不是技术多么复杂，而是**建立了一套契约**。从 REST 到 Agent-First，关键变化同样不是技术飞跃，而是**建立了一套让 AI 能理解、能选择、能组合的契约体系**。

Prism 的 Skill 体系就是这套契约。

---

## 3. Agent 运行时架构

### 3.1 Skill 注册表设计

Skill 注册表是 Agent 运行时的"工具目录"——Agent 在执行任务前，先查阅这本目录，了解自己有哪些工具可用、每个工具能做什么、需要什么输入、会给出什么输出。

**What：声明式的工具定义**

每个 Skill 通过 JSON Schema 进行声明式定义，包含六个核心维度：

| 维度 | 说明 | 对 Agent 的意义 |
|------|------|----------------|
| **名称与描述** | 自然语言描述工具的功能 | LLM 据此判断"这个工具能不能解决当前问题" |
| **输入契约** | JSON Schema 定义的参数结构 | LLM 据此构造正确的调用参数 |
| **输出契约** | JSON Schema 定义的返回结构 | LLM 据此理解工具返回的结果 |
| **权限声明** | 调用此工具需要的能力列表 | 运行时据此判断当前 Agent 是否有权调用 |
| **成本元数据** | 预估的 token 消耗和金钱成本 | 运行时据此追踪和控制成本 |
| **版本信息** | 语义化版本号和兼容性声明 | 确保 Agent 调用的是正确版本的工具 |

**Why：为什么必须是声明式的**

声明式定义有三个不可替代的优势：

第一，**可发现性**。Agent 不需要硬编码"我有哪些工具"，它在运行时查询注册表，自动获得最新的工具列表。这意味着新增一个 Skill 不需要修改 Agent 代码——注册即可用。

第二，**可验证性**。输入输出都有 schema，参数错了在调用前就能拦截，不会把错误传递到下游系统。

第三，**可治理性**。管理者可以通过注册表看到系统有哪些能力、每个能力的成本是多少、哪些 Agent 在使用哪些能力——这是组织级的能力清单。

**How：注册表的运行机制**

注册表持久化在 PostgreSQL 的 `agent` schema 中，通过 Redis 做热缓存。Agent 启动时加载可用 Skill 列表，运行时按需查询详细定义。新增或更新 Skill 通过管理 API 操作，变更实时生效。

### 3.2 Agent Loop 设计

Agent Loop 是 Agent 运行时的"心脏"——一个不断循环的推理-行动回路。

**What：ReAct 循环**

每个 Agent 任务的执行都遵循 ReAct（Reasoning + Acting）范式：

```
任务输入 → [ 推理 → 工具选择 → 执行 → 结果评估 → 继续/终止 ] → 任务输出
               ↑___________________________________|
                         （循环，直到终止条件满足）
```

每一轮循环包含五个步骤：

1. **推理（Reasoning）**：LLM 分析当前上下文——任务目标是什么、已经知道了什么、还需要知道什么、下一步应该做什么。这是 Agent 的"大脑"在工作。

2. **工具选择（Tool Selection）**：LLM 从可用的 Skill 列表中选择最合适的工具，并构造调用参数。选择依据是 Skill 的自然语言描述——这就是声明式定义的价值所在。

3. **执行（Execution）**：系统调用选中的 Skill，传入参数，获取结果。执行过程受权限和配额约束——如果 Agent 没有权限调用某个 Skill，或者已经超出成本上限，调用会被拒绝。

4. **结果评估（Evaluation）**：LLM 分析工具返回的结果——结果是否回答了当前的问题、是否发现了新的线索、是否需要调整策略。

5. **继续/终止（Decision）**：基于评估结果，决定是继续下一轮循环还是终止任务。终止条件有三类：任务完成、达到迭代上限、成本达到上限。

**Why：为什么是循环而不是流水线**

传统的数据处理是流水线——输入 → 处理1 → 处理2 → 处理3 → 输出。每一步固定，不会回头。

Agent Loop 是循环——因为**分析任务的路径不是预先可知的**。当你让 Agent 分析"用户为什么流失"，它可能先搜索一批反馈，发现"支付问题"是高频关键词，然后深入搜索支付相关的反馈，发现"iOS 17.2 特有"是一个关键线索，再进一步搜索版本相关的数据......每一步都依赖上一步的结果来决定方向。

这就像一个好的侦探不是按照检查清单办案，而是**根据每一条线索决定下一步去哪里挖**。Agent Loop 赋予了 AI 这种"跟着线索走"的能力。

**Risk：循环失控的风险与控制**

无约束的循环是危险的。Agent 可能陷入死循环、做出重复的无效调用、或者不断消耗 token 却没有产出。Prism 通过三层防护来控制这个风险：

| 防护层 | 机制 | 典型阈值 |
|--------|------|---------|
| **迭代上限** | 单次任务最大循环次数 | 20 轮 |
| **成本上限** | 单次任务最大 token 消耗 / 金钱成本 | 50,000 tokens / 0.50 USD |
| **时间上限** | 单次任务最大执行时间 | 5 分钟 |

任何一个上限被触发，Agent 会优雅终止——返回已经收集到的部分结果和"因达到资源上限而终止"的说明。这确保了系统资源的可控性。

### 3.3 多 Agent 协作模型（远景）

单个 Agent 能处理"找到和支付相关的用户反馈"这类明确任务。但当任务变成"生成本周的产品洞察周报"时，涉及的子任务太多、太杂——趋势分析、问题诊断、竞品对比、建议生成——一个 Agent 的上下文窗口和注意力难以承载。

Prism 的远景架构采用 **Orchestrator → Specialist** 模式：

**Orchestrator Agent（编排者）**：接收高层任务，将其分解为子任务，分配给合适的 Specialist Agent，收集结果，综合输出。它是"项目经理"。

**Specialist Agent（专家）**：专注于某一类子任务，拥有该领域最合适的 Skill 组合和提示词策略。它是"专业分析师"。

```
              ┌─────────────────────────┐
              │   Orchestrator Agent    │
              │   "生成本周洞察周报"      │
              └──────┬──────┬──────┬────┘
                     │      │      │
            ┌────────┘      │      └────────┐
            ▼               ▼               ▼
    ┌───────────────┐ ┌──────────────┐ ┌──────────────┐
    │ 趋势分析专家   │ │ 问题诊断专家  │ │ 竞品对比专家  │
    │ Specialist    │ │ Specialist   │ │ Specialist   │
    └───────────────┘ └──────────────┘ └──────────────┘
```

这个模型目前是远景设计（Phase 5-6），但它对 Phase 2.5 的架构设计有重要的约束意义：**Skill 注册表和 Agent Loop 必须从一开始就支持多 Agent 场景下的上下文隔离、权限继承和成本聚合**。这就是为什么我们要在 Phase 2.5 就把架构设计清楚，而不是等到 Phase 5 再"升级"。

---

## 4. Skill 体系设计

### 4.1 内置 Skill：原子查询工具的 Skill 化

Prism 的 Voice Service 设计了 8 个原子查询工具（vector_search、get_neighbors、random_sample、get_tags、get_units_by_tag、get_related_units、get_original_voice、get_tag_statistics），每一个都遵循"只提供原子能力，不预设策略"的设计原则。

这些原子工具在 Skill 体系中被包装为**内置 Skill**——系统自带、开箱可用、不可删除、由平台团队维护。

**What：原子 Skill 的设计哲学**

原子 Skill 是最小不可分割的能力单元。每个 Skill 做且只做一件事：`vector_search` 只做语义搜索、`random_sample` 只做随机采样、`get_tags` 只查标签列表。

**Why：为什么坚持原子化**

原子化的核心价值在于**组合的涌现性**。8 个原子 Skill 的自由组合可以产生数十种分析策略：

| 分析需求 | Skill 组合 |
|---------|-----------|
| "最近用户主要在抱怨什么" | `get_tags(sort_by="recent")` → `get_units_by_tag` |
| "A 功能和 B 功能哪个用户更满意" | `vector_search(A)` + `vector_search(B)` → 情感对比 |
| "这个问题有多少人遇到" | `vector_search` → `get_neighbors`（迭代扩展） |
| "有没有被忽视的长尾问题" | `random_sample` → 聚类分析 |
| "某个问题的反馈趋势如何" | `get_units_by_tag` + 时间序列分析 |

重要的是，这些组合策略**不是我们预设的**——它们是 Agent 在运行时根据任务目标自主决定的。新的分析需求不需要新的 API，Agent 用已有的积木就能搭出新的建筑。

**How：原子 Skill 的质量保证**

每个内置 Skill 必须满足四个标准：

1. **幂等性**：相同的输入在相同的数据状态下产生相同的输出
2. **可组合性**：输出格式可以直接作为其他 Skill 的输入
3. **可预测成本**：执行时间和资源消耗有明确的上界
4. **失败安全**：失败时返回结构化的错误信息，不会产生副作用

### 4.2 复合 Skill：策略级能力的封装

当某些 Skill 组合模式被反复使用时，将其封装为**复合 Skill** 可以提高效率和一致性。

**What：复合 Skill 是"策略模板"**

复合 Skill 是多个原子 Skill 的编排模板。它不包含新的逻辑，只定义了"按什么顺序调用哪些原子 Skill、中间结果如何传递"。

Prism 设计了五种核心策略模板：

| 复合 Skill | 组合的原子 Skill | 适用场景 |
|-----------|-----------------|---------|
| **探索式分析** | get_tags → random_sample → get_units_by_tag → get_tag_statistics | 了解整体面貌 |
| **深度追踪** | vector_search → get_neighbors → get_related_units → get_original_voice | 追踪特定线索 |
| **对比分析** | vector_search(A) + vector_search(B) → 情感/标签对比 | 比较两个主题 |
| **趋势分析** | vector_search(时间窗口) → 标签演化分析 | 时间维度变化 |
| **问题诊断** | 多角度 vector_search → 维度分析 → 时间线回溯 | 根因定位 |

**Why：为什么需要复合 Skill**

原子 Skill 给了 Agent 最大的灵活性，但灵活性的代价是效率。如果每次做"探索式分析"都让 Agent 从零开始规划步骤，就像每次做饭都要从"先确认厨房在哪里"开始。复合 Skill 是"菜谱"——经过验证的最佳实践，Agent 可以直接采用或在此基础上微调。

**Risk：策略僵化**

复合 Skill 的风险是策略僵化——如果 Agent 总是依赖固定的模板，就失去了"根据具体情况灵活应变"的能力。Prism 的应对策略是：**复合 Skill 是"建议"而非"强制"**。Agent 可以选择使用复合 Skill，也可以选择直接组合原子 Skill。系统不会强制 Agent 走预设路径。

### 4.3 自定义 Skill：用户可注册的扩展能力

**What：平台的开放性**

除了内置 Skill 和复合 Skill，Prism 支持用户注册自定义 Skill。自定义 Skill 可以封装企业内部的特有能力——比如对接内部 CRM 系统、调用内部知识库、触发 Jira 工单创建等。

**How：注册流程**

自定义 Skill 的注册需要通过审核：

1. **定义阶段**：提供 JSON Schema 的完整声明（名称、描述、输入输出契约、权限需求、成本预估）
2. **验证阶段**：系统自动验证 Schema 的合法性、端点的可达性、输入输出的一致性
3. **审核阶段**：管理员审核 Skill 的权限需求是否合理、成本预估是否准确
4. **发布阶段**：通过审核后进入注册表，对有权限的 Agent 可见

**Benefit：生态效应**

自定义 Skill 的价值在于**让 Prism 从一个封闭系统变成一个开放平台**。每注册一个新 Skill，系统的能力就扩展一分，所有 Agent 都能受益。这是一个正向飞轮——Skill 越多 → Agent 能力越强 → 用户越愿意注册新 Skill。

### 4.4 Skill 的版本化与生命周期

Skill 像任何软件组件一样，需要版本管理和生命周期管理。

| 阶段 | 状态 | Agent 行为 |
|------|------|-----------|
| **Alpha** | 实验中，接口可能变化 | 仅限指定的测试 Agent 使用 |
| **Stable** | 接口稳定，可生产使用 | 所有有权限的 Agent 可用 |
| **Deprecated** | 即将下线，有替代方案 | Agent 被警告使用替代 Skill |
| **Retired** | 已下线 | 调用返回错误，指引到替代 Skill |

版本号遵循语义化版本（SemVer）：主版本号变更意味着不兼容的接口变化，次版本号变更意味着向后兼容的功能新增，修订号变更意味着向后兼容的问题修复。

---

## 5. Agent 安全与治理

这是管理层最关心的部分。AI Agent 拥有自主行动能力，如果不加约束，它就是一把双刃剑——效率和风险同时放大。Prism 的安全治理设计遵循一个核心原则：**让 Agent 在严格的围栏内自由奔跑。**

### 5.1 权限沙箱：Agent 只能调用被授权的 Skill

**What：最小权限原则的工程化实现**

每个 Agent 在创建时被分配一组 **Capabilities**（能力许可），只有当 Agent 拥有某个 Skill 声明的所有 required capabilities 时，才能调用该 Skill。

```
Agent "insight-bot"
├── Capabilities: [voc:search, voc:read, llm:chat]
├── 可调用: vector_search ✓ (需要 voc:search)
├── 可调用: get_tags ✓ (需要 voc:read)
├── 不可调用: delete_voice ✗ (需要 voc:delete，未授权)
└── 不可调用: create_user ✗ (需要 auth:admin，未授权)
```

**Why：为什么不用简单的角色控制**

角色（Role）是粗粒度的——一个"analyst"角色可能包含几十种能力。如果 Agent 只需要"搜索"和"读取"两种能力，但因为"analyst"角色还包含"导出"和"批量操作"，Agent 就获得了不必要的权限。

能力（Capability）是细粒度的——精确到每一种操作。这遵循安全工程的黄金法则：**给予实体完成其任务所需的最小权限，不多一丝一毫。**

**Risk：权限管理的运维负担**

细粒度权限的代价是管理复杂度。每新增一个 Agent、每新增一个 Skill，都需要维护权限映射关系。Prism 通过"角色预设 + 能力微调"来缓解这个问题：预定义几个常用的角色模板（explorer、analyst、reporter），每个模板包含一组能力；创建 Agent 时选择角色模板，再根据需要增减个别能力。

### 5.2 成本预算：会话级 token 消耗上限

**What：每次任务执行有明确的成本天花板**

Agent 的每次任务执行都绑定一个**成本预算（Cost Budget）**。预算包含三个维度：

| 维度 | 说明 | 超出后行为 |
|------|------|-----------|
| **Token 上限** | 本次任务最大 LLM token 消耗 | 优雅终止，返回部分结果 |
| **金钱上限** | 本次任务最大金钱成本（含 LLM + 工具调用） | 优雅终止，返回部分结果 |
| **时间上限** | 本次任务最大执行时间 | 强制终止，返回超时提示 |

**Why：为什么成本控制是架构级问题**

Agent 的成本结构与传统系统完全不同。传统系统的成本主要是基础设施（服务器、带宽），用户操作本身几乎零成本。但 Agent 每一次"思考"都消耗 LLM token，每一次 token 消耗都是真金白银。

一个失控的 Agent Loop——比如陷入了"搜索 → 发现新线索 → 继续搜索"的无限循环——可以在几分钟内消耗掉数十美元的 token。如果系统同时运行 100 个这样的 Agent 任务，成本将是灾难性的。

**How：实时成本追踪**

成本追踪嵌入在 Agent Loop 的每一轮循环中。每次 LLM 推理和工具调用完成后，系统立即更新已消耗成本，并与预算比较。当消耗达到预算的 80% 时，系统向 Agent 注入"成本警告"信号，提示 Agent 开始收尾；达到 100% 时，强制终止。

这个机制确保了**成本的可预测性**——管理层可以基于"每个 Agent 任务不超过 X 元"来做预算规划，而不是事后收到"本月 LLM 消费 10 万元"的账单。

### 5.3 可审计性：完整的调用链日志

**What：每一步操作都有迹可循**

Prism 为每次 Agent 任务执行生成完整的调用链日志，包含：

- **触发者**：谁（人类或系统调度）触发了这次 Agent 任务
- **任务描述**：Agent 被要求做什么
- **每轮循环的详情**：推理过程（LLM 的输入输出）、工具选择（选了什么、为什么选）、执行结果、评估判断
- **成本明细**：每一步消耗了多少 token、多少钱
- **最终输出**：Agent 交付了什么结果
- **trace_id**：全链路追踪 ID，可以串联所有相关的系统日志

**Why：可审计性是合规和信任的基础**

在企业环境中，"AI 说的"不够——管理层需要知道"AI 是怎么得出这个结论的"。如果 Agent 报告"用户对支付功能的满意度下降了 30%"，管理层需要能追溯：Agent 搜索了哪些数据、采用了什么分析策略、样本量有多大、置信度如何。

这不仅是管理需求，也是监管需求。随着 AI 治理法规在全球范围内收紧（如欧盟 AI Act），AI 决策的可解释性和可审计性正在从"最佳实践"变成"合规要求"。

**How：分层日志存储**

调用链日志采用分层存储策略：

- **热数据**（最近 7 天）：存在 Redis 中，支持实时查询和监控面板展示
- **温数据**（7-90 天）：存在 PostgreSQL 中，支持结构化查询和审计分析
- **冷数据**（90 天以上）：归档到对象存储，支持合规要求的长期保留

### 5.4 人类否决权：关键操作需人类确认

**What：Human-in-the-Loop 机制**

并非所有操作都适合 Agent 自主完成。Prism 将操作分为三个信任级别：

| 信任级别 | 操作类型 | Agent 行为 |
|---------|---------|-----------|
| **自主执行** | 查询、搜索、分析、报告生成 | Agent 直接执行，事后记录 |
| **通知执行** | 批量导出、外部系统调用 | Agent 执行后通知人类 |
| **需人类确认** | 数据删除、权限变更、高成本操作 | Agent 发起请求，等待人类审批后执行 |

**Why：信任是渐进建立的**

刚部署 Agent 时，组织对 AI 的信任度低，应该把更多操作放在"需人类确认"级别。随着 Agent 表现稳定、审计记录积累，组织可以逐步将操作"降级"到"通知执行"甚至"自主执行"。

这就像一个新员工的转正过程：**试用期凡事请示 → 表现好了只需报告 → 完全信任后独立负责**。Prism 的信任级别机制让组织可以按自己的节奏来建立对 AI 的信任，而不是在"完全不信任"和"完全放手"之间做二选一。

**Risk：审批瓶颈**

如果太多操作需要人类确认，Agent 的效率优势就会被审批流程抵消。Prism 通过两种方式缓解这个问题：

1. **批量审批**：同类操作可以一次性审批（"允许 insight-bot 在本周内不限次数地执行探索式分析"）
2. **自动升级**：如果某类操作连续 N 次被人类无修改通过，系统建议将其降级为"通知执行"

### 5.5 安全治理的全景图

将以上四个维度组合，形成 Prism 的 Agent 安全治理全景：

```
┌─────────────────────────────────────────────────────────┐
│                  Agent 安全治理体系                       │
│                                                         │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐    │
│  │  权限沙箱    │  │  成本预算    │  │ 人类否决权   │    │
│  │             │  │             │  │             │    │
│  │ Capability  │  │ Token 上限   │  │ 三级信任     │    │
│  │ 白名单      │  │ 金钱上限     │  │ 渐进授权     │    │
│  │ 最小权限    │  │ 时间上限     │  │ 批量/自动    │    │
│  └──────┬──────┘  └──────┬──────┘  └──────┬──────┘    │
│         │                │                │            │
│         └────────────────┼────────────────┘            │
│                          ▼                             │
│              ┌───────────────────┐                     │
│              │   完整审计日志     │                     │
│              │                   │                     │
│              │  谁、做了什么、     │                     │
│              │  花了多少、结果     │                     │
│              │  如何               │                     │
│              └───────────────────┘                     │
│                                                         │
│  设计原则：在严格的围栏内自由奔跑                          │
└─────────────────────────────────────────────────────────┘
```

这套治理体系的设计目标是：**让管理层有信心把 Agent 投入生产——不是因为"AI 不会出错"，而是因为"出了错能发现、能止损、能追溯、能改进"。**

---

## 6. 从 Thin Agent 到 Orchestrator Agent 的演进路径

Agent 能力不是一步到位的。Prism 的演进路径遵循"先搭骨架、再长肌肉、最后练武功"的节奏，每个阶段独立可交付、可验证。

### Phase 2.5：Skill 注册表 + 基础 Agent Loop

**交付物**：
- Skill 注册表（声明式定义、CRUD 管理 API、权限校验）
- 基础 Agent Loop（单 Agent、固定迭代上限、成本追踪）
- 执行上下文管理（权限边界、资源配额、审计日志）
- 双身份认证（Human JWT + Agent API Key → 统一 Principal）

**可用 Skill**：仅 llm-service 提供的 Skill（chat、embedding）——Agent 能力有限，但"骨架"完整。

**验证标准**：Agent 能通过 API Key 认证、查询可用 Skill、执行一次简单的 LLM 对话、生成完整的审计日志。

**战略意义**：这个阶段的价值不在于"Agent 能做多少事"，而在于"Agent 基础设施是否可靠"。就像建大楼时先搭好钢结构——里面还没装修，但结构经得住考验。

### Phase 3：Thin Agent（管线内嵌 LLM 调用）

**交付物**：
- 8 个原子查询 Skill（vector_search、get_neighbors 等）
- VOC 数据摄入管线（AI 四阶段处理：拆分 → 丰富 → 向量化 → 关联）
- Thin Agent 能力——Agent 能组合原子 Skill 完成基础分析任务

**可用 Skill**：llm-service Skill + 8 个 VOC 查询 Skill——Agent 开始具备实际的分析能力。

**验证标准**：Agent 能接收一个分析任务（如"找到与支付功能相关的用户反馈"），自主规划步骤、调用工具、返回结构化结果。

**战略意义**：这是 Agent 能力的"从 0 到 1"——从"能跑"到"能干活"。Thin Agent 的"Thin"意味着它只做数据检索和初步分析，不做复杂推理，但已经能替代人类的大量重复性搜索工作。

### Phase 5：完整 Agent 引擎（策略模式 + 多 Agent）

**交付物**：
- 5 种策略模式的复合 Skill（探索式、深度追踪、对比、趋势、诊断）
- 自定义 Skill 注册机制
- 多 Agent 协作框架（Orchestrator → Specialist）
- 工作流编排（DAG 定义、条件分支、并行执行）

**可用 Skill**：内置 Skill + 复合 Skill + 自定义 Skill——Agent 从"工具使用者"变成"策略执行者"。

**验证标准**：Orchestrator Agent 能接收"生成本周产品洞察周报"任务，分解为多个子任务，分配给 Specialist Agent，汇总结果，输出结构化报告。

**战略意义**：这是 Agent 能力的"从 1 到 10"——从"执行明确任务"到"自主规划复杂工作流"。

### Phase 6：Orchestrator + 自动化洞察

**交付物**：
- 主动洞察发现（Agent 定期巡检，发现异常信号主动报告）
- 概念治理协助（Agent 提出概念候选，人类在 UI 中确认/合并/静音）
- 开放平台 API（外部 Agent 可以通过标准协议接入 Prism 的 Skill 体系）

**验证标准**：Agent 能在无人触发的情况下，自动发现"新涌现的高增长问题"，提出概念候选，通知相关人员。

**战略意义**：这是 Agent 能力的"从 10 到 100"——从"被动执行"到"主动发现"。系统从"人驱动 AI"变成"AI 驱动人"——AI 发现信号，人类做决策。这是 Prism 愿景的终极形态。

### 演进路径总览

```
Phase 2.5  骨架就位 ──────▶ "Agent 能跑，但还不能干活"
                              ↓ VOC 数据层上线
Phase 3    Thin Agent ────▶ "Agent 能搜索、能分析基础问题"
                              ↓ 策略能力 + 多 Agent
Phase 5    完整引擎 ──────▶ "Agent 能自主规划复杂分析工作流"
                              ↓ 主动发现 + 开放平台
Phase 6    自动化洞察 ────▶ "Agent 主动发现问题、人类做决策"
```

每一步的演进都是**能力的自然扩展，而非架构的痛苦重写**——因为骨架在 Phase 2.5 就设计对了。

---

## Key Takeaways

1. **Agent-First 是地基选择，不是装修风格。** AI Agent 从"工具"进化为"协作者"的拐点已经到来。不在 Day 1 把 Agent 设计进架构，Day 100 的改造成本是初始设计的 5-10 倍。这是一个典型的 Type 1（不可逆）决策。

2. **Agent 必须是"有身份的用户"。** 没有独立身份、权限、审计的 Agent，就像没有工牌的员工——技术上能干活，组织上没法管。Prism 的双用户模型让人类和 Agent 在同一个治理框架下工作。

3. **Skill 是契约，不是 API。** 声明式的工具定义让 Agent 能自主发现、选择、组合工具。这就像从 CGI 时代到 REST 时代的范式跃迁——关键变化不是技术复杂度，而是"契约"的建立。

4. **原子能力的组合远胜于预设策略。** 8 个原子 Skill 的自由组合产生数十种分析策略，而且新策略不需要新代码。"只提供原子能力，不预设策略"是 Agent 时代的 API 设计第一原则。

5. **安全治理是 Agent 上生产的前提。** 权限沙箱、成本预算、完整审计、人类否决权——四根支柱缺一不可。管理层不需要"相信 AI 不会犯错"，只需要确信"犯了错能发现、能止损、能追溯"。

6. **信任是渐进建立的。** 从"凡事请示"到"独立负责"，Prism 的三级信任机制让组织按自己的节奏适应 AI，而不是在"全面拒绝"和"盲目信任"之间做极端选择。

7. **演进路径必须是"骨架先于肌肉"。** Phase 2.5 的 Agent 运行时先于 Phase 3 的 VOC 数据层交付——这确保后续的每一个新能力上线后，Agent 都能立即编排使用，而不是"功能做好了，Agent 还没准备好"。

---

*Agent-First 不是技术信仰，而是工程经济学的理性选择。在一个 Agent 能力每 6 个月翻一倍的时代，系统最大的风险不是"Agent 做得太多"，而是"系统根本不支持 Agent 做事"。Prism 选择在 Day 1 就为这个时代做好准备。*
