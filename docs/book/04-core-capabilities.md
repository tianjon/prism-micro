# 核心能力深度剖析

---

## TL;DR（高管速读版）

Prism 不是一堆功能的拼盘，而是五个能力群相互咬合的有机体。就像人体需要消化系统、循环系统、神经系统协同工作才能维持生命，Prism 的五个能力群各司其职又彼此依赖，共同完成"从原始客户声音到可行动商业洞察"的价值转化。

| 能力群 | 类比 | 核心价值 |
|--------|------|---------|
| 语义理解引擎 | 消化系统——把"食物"分解为可吸收的"营养" | 把非结构化文本转化为可被机器理解的语义单元 |
| 数据接入框架 | 感觉器官——从多个渠道接收外部信号 | 零代码对接新数据源，确保"什么都听得到" |
| 知识资产体系 | 长期记忆——把短期信息沉淀为可复用的知识 | 让组织越用越聪明，形成不可复制的知识壁垒 |
| LLM 统一网关 | 心脏——为全身供血、保障持续运转 | 屏蔽多 Provider 差异，提供永不宕机的 AI 能力 |
| 用户体验层 | 眼睛和手——让人看到真相并采取行动 | 渐进式信息架构，从概览到深钻一气呵成 |

关键洞察：**能力之间的协同效应远大于单项能力之和**。语义理解引擎拆解出的标签，被知识资产体系沉淀为组织概念；LLM 网关的三级降级保障了语义引擎的处理永不中断；用户体验层的可溯源设计让每个 AI 洞察都经得起追问。拆开来看是五个独立能力，合起来是一个自增强的飞轮。

---

## 1. 能力地图总览

### 1.1 能力分类与阶段依赖

下表展示了 Prism 的五个核心能力群、其交付阶段，以及它们之间的依赖关系。

| 能力群 | 交付阶段 | 上游依赖 | 下游受益方 | 成熟度 |
|--------|---------|---------|-----------|--------|
| LLM 统一网关 | Phase 2 | 基础设施（PostgreSQL, Redis） | 语义理解引擎、知识资产体系、用户体验层 | 已实现 |
| 数据接入框架 | Phase 3 | LLM 网关（数据预处理） | 语义理解引擎 | 设计中 |
| 语义理解引擎 | Phase 3 | LLM 网关、数据接入框架 | 知识资产体系 | 设计中 |
| 知识资产体系 | Phase 3-4 | 语义理解引擎 | 用户体验层、AI Agent | 设计中 |
| 用户体验层 | Phase 4-5 | 知识资产体系、LLM 网关 | 终端用户（人类 + Agent） | 规划中 |

### 1.2 能力间的信息流

```
数据接入框架 ──→ 语义理解引擎 ──→ 知识资产体系 ──→ 用户体验层
     │                │                 │                │
     │                ▼                 ▼                │
     └──────→ LLM 统一网关（贯穿全链路，为所有环节提供 AI 能力）
```

这张图揭示了一个关键事实：**LLM 网关不是"某个阶段"的能力，而是贯穿整条价值链的基础设施**。这就是为什么它被安排在最早的交付阶段——地基必须先于楼层就位。

---

## 2. 能力群 1：语义理解引擎

> 类比：如果用户的原始反馈是一块矿石，语义理解引擎就是选矿厂——把矿石破碎、分选、提纯，最终产出可以直接送入冶炼炉的精矿。

### 2.1 SemanticUnit：最小语义单元

**What**：SemanticUnit 是 Prism 数据模型的原子粒子——一个独立的、自包含的、表达单一完整观点的语义片段。一条用户反馈（Voice）可以被拆解为一个或多个 SemanticUnit。

**Why**：一条用户评论往往同时包含多个独立观点。"你们的搜索功能很好用，但付款页面总是卡住，另外建议加个深色模式"——这条反馈里有一个正面评价、一个 Bug 报告和一个功能请求。如果作为整体处理，情感分析会被稀释为"中性"，标签会变成模糊的"综合反馈"，搜索时这条反馈既匹配"搜索好用"也匹配"付款卡住"，精确度大打折扣。

将其拆解为三个 SemanticUnit 后，每个片段都有精确的情感标注、专属的标签、独立的向量表示，可以被独立检索、独立关联、独立追踪。

**How**：每个 SemanticUnit 承载六层信息：

| 信息层 | 字段 | 作用 |
|--------|------|------|
| 内容层 | content, summary, normalized_content | 原文、摘要、标准化表述 |
| 语义分析层 | intent, sentiment, urgency, importance | 意图、情感、紧迫度、重要性 |
| 实体层 | entities | 功能模块、设备型号、版本号等结构化实体 |
| 上下文层 | position, context_before, context_after | 在原文中的位置和上下文 |
| 向量层 | embedding_id, embedding_model | 语义向量，支撑相似度检索 |
| 质量层 | content_quality, processing_confidence | 内容质量和处理置信度 |

**Risk**：拆解可能破坏原始语境。"虽然搜索很慢，但整体还不错"——如果只取后半句，就丢失了转折关系。缓解措施是保留 `context_before` 和 `context_after` 字段，以及 `is_standalone` 标记，让下游消费者知道该片段是否可以脱离上下文独立理解。

**Benefit**：细粒度语义单元带来三个量级的提升——检索精确度从"篇级"提升到"句级"，标签准确率从"粗放"提升到"精准"，关联分析从"文档间"深入到"观点间"。这是整个系统后续能力的基础。

### 2.2 语义拆解管线：四阶段异步处理

**What**：一条原始 Voice 进入系统后，经历四个串行阶段的 AI 处理，最终转化为结构化的语义知识。

**Why**：四阶段设计不是过度工程，而是关注点分离的必然要求。每个阶段有不同的计算特性、不同的错误模式、不同的重试策略。将它们解耦后，Stage 1 的 LLM 调用失败不会影响 Stage 3 已完成的向量化结果，任何阶段都可以独立优化和替换。

**How**：

| 阶段 | 名称 | 输入 | 输出 | AI 依赖 |
|------|------|------|------|---------|
| Stage 1 | 语义拆解 | 原始 Voice 文本 | SemanticUnit 草稿列表 | LLM Chat |
| Stage 2 | 标签涌现 | SemanticUnit 列表 | 带标签的 SemanticUnit | LLM Chat |
| Stage 3 | 向量化 | SemanticUnit 列表 | 带 embedding 的 SemanticUnit | Embedding API |
| Stage 4 | 关系构建 | 带向量的 SemanticUnit | UnitRelation 列表 | 向量相似度计算 |

Stage 1（语义拆解）是整条管线最关键的环节。LLM 接收原始文本，将其拆解为独立语义片段，同时为每个片段推断意图类型（反馈/投诉/建议/Bug 报告等）和情感倾向。质量控制规则包括：单条 Voice 最多拆解为 20 个片段、每个片段至少 10 个字符、置信度低于 0.6 的片段标记待人工审核。

Stage 2（标签涌现）为每个片段生成 3-7 个自由形式标签。LLM 不受预设词表约束，可以生成任意粒度的标签——从"搜索结果加载慢"到"iOS 17.2 指纹识别失败"。标签经过标准化处理（去停用词、同义词映射、编辑距离去重）后存入涌现标签库。

Stage 3（向量化）将每个片段的文本内容转换为 1536 维的语义向量（使用 OpenAI text-embedding-ada-002 或同等模型），存入向量数据库。这一步是后续所有语义检索能力的基础。

Stage 4（关系构建）基于三种来源建立片段间的显式关系：同源关系（来自同一条 Voice 的片段）、相似关系（向量相似度超过阈值的片段）、共现关系（共享相同标签的片段）。这些关系构成语义网络的"边"。

**Risk**：四阶段串行处理意味着端到端延迟是各阶段延迟之和。单条 Voice 的处理时间约 5-10 秒。缓解措施是异步任务队列（Celery）和批量并行处理。此外，LLM 输出的不确定性是固有风险，由下一节的守卫层专门应对。

**Benefit**：四阶段管线将一段自然语言文本转化为具有六层信息、可向量检索、可关联分析、可标签聚合的结构化语义知识。这个转化过程的成本约 $0.0035/条——千条 Voice 约 $3.5，万条约 $35——在商业分析的语境下几乎可以忽略不计。

### 2.3 涌现式标签机制：双轨设计

**What**：Prism 的标签体系采用"双轨并行"策略——一轨是涌现标签（EmergentTag），由 LLM 自由生成，不受预设词表约束；另一轨是预设维度（intent、sentiment 等），使用结构化枚举保证统计口径一致。

**Why**：纯涌现标签面临"标签爆炸"风险——"加载慢""响应慢""卡顿""很慢""太慢了"可能被 LLM 生成为五个不同的标签。纯预设分类又会落入封闭世界假设的陷阱。双轨制在两个极端之间找到平衡：涌现轨捕获新概念（你不知道你不知道的），预设轨保证可比性（你确定知道的）。

**How**：涌现标签经历三道标准化工序。第一道是文本清洗：去标点、去停用词、统一大小写。第二道是同义词映射：维护一张核心同义词表，"加载慢""卡顿""响应慢"自动收敛为同一标签。第三道是向量相似度合并：为每个标签生成 embedding，相似度超过 0.95 的标签自动建议合并。此外，每个标签携带丰富的统计元数据——使用次数、关联 Voice 数、7 天/30 天趋势、平均情感倾向、是否正在涌现。

**Risk**：标签质量依赖 LLM 的表现。不同模型、不同 temperature 可能为相同内容生成不同标签。缓解措施包括标准化流水线、相似度聚合、以及人工治理机制（Phase 4 的 Concept 治理）。

**Benefit**：双轨设计让系统同时具备"发现未知"和"统计已知"两种能力。新产品上线后出现的全新问题类型可以被即时捕获（涌现轨），同时情感趋势、意图分布等核心指标的统计口径保持稳定（预设轨）。

### 2.4 LLM 输出守卫层：三级降级策略

**What**：LLM 的输出本质上是概率性的——它可能返回格式错误的 JSON、遗漏必要字段、甚至产生幻觉。守卫层是一套三级防御机制，确保即使 LLM 表现不佳，系统仍能产出可用结果。

**Why**：在生产环境中，LLM 输出的可靠性直接决定了数据质量的下限。没有守卫层，一次 LLM 抽风就可能污染整个知识库。

**How**：

| 级别 | 触发条件 | 处理策略 | 数据质量影响 |
|------|---------|---------|-------------|
| L1 正常 | LLM 输出格式正确、字段完整、置信度高 | 直接入库 | 最优 |
| L2 修正 | 格式错误但可修复（如缺少字段、类型不匹配） | 自动修复 + 降低置信度标记 | 可接受 |
| L3 降级 | 无法修复或多次重试失败 | 将整条 Voice 作为单个 SemanticUnit 保存，标记待人工审核 | 保底 |

L3 降级策略的设计哲学是"宁可粗糙也不丢失"——即使 AI 处理完全失败，原始数据也会被保留在系统中，等待后续重处理或人工介入。

**Risk**：过度宽松的守卫层可能让低质量数据混入知识库。缓解措施是所有降级数据都携带置信度标记，下游查询工具可以按置信度过滤。

**Benefit**：三级降级策略将"LLM 输出不确定性"从架构风险降维为可管理的数据质量问题。系统的整体可用性不再受制于单次 LLM 调用的表现。

---

## 3. 能力群 2：数据接入框架

> 类比：如果说语义理解引擎是"选矿厂"，数据接入框架就是"矿石运输网络"——无论矿石来自哪个矿山（App 评论、客服对话、社交媒体），都能通过统一的运输通道送达选矿厂。

### 3.1 Source Adapter 声明式框架

**What**：Source Adapter 是 Prism 的数据源抽象层。每个数据源（App 评论、NPS 调查、客服工单等）通过声明式配置接入系统，无需编写定制化的 ETL 代码。

**Why**：企业的客户声音散落在无数渠道中——App Store 评论、Google Play 评论、Zendesk 工单、SurveyMonkey 问卷、微博评论、Discord 社区、用户访谈录音的转写文本……如果每接入一个新渠道就需要一次定制开发，系统的扩展速度将被工程瓶颈锁死。

**How**：每个 Source Adapter 声明三件事：

| 声明项 | 说明 | 示例 |
|--------|------|------|
| **数据获取方式** | 如何从外部系统拉取数据 | Webhook 推送 / API 轮询 / 文件导入 |
| **字段映射规则** | 如何将外部数据映射到 Voice 模型 | `review.body → content`, `review.rating → source_metadata.rating` |
| **内容策略** | 多字段如何组合为最终文本 | independent / concatenate / primary_with_context |

其中，内容策略是区别于传统 ETL 的关键设计。一条 NPS 回复包含评分（1-10）和开放式文本，一条 App 评论包含标题和正文，一封客服邮件包含主题行和邮件体。这些多字段数据有三种组合策略：

- **independent**：每个字段独立成为一条 Voice（适用于字段间语义独立的场景）
- **concatenate**：所有字段拼接为一条 Voice（适用于字段互相补充的场景）
- **primary_with_context**：一个字段作为主内容，其他字段作为上下文元数据（最常用）

**Risk**：声明式框架可能无法覆盖所有极端数据格式。缓解措施是保留自定义 Adapter 的扩展接口——声明式覆盖 80% 场景，剩下 20% 通过代码扩展。

**Benefit**：新数据源的接入从"周级开发"降低到"小时级配置"。更重要的是，所有数据源接入后都被标准化为统一的 Voice 模型，下游的语义理解引擎完全不需要关心数据来自哪里。

### 3.2 零代码接入的工程设计

**What**：理想状态下，一个新渠道的接入只需要填写一份配置文件，不需要写任何业务代码。

**Why**：在 VOC 场景中，数据源的数量和类型是持续增长的。今天你有 5 个数据源，半年后可能变成 15 个。如果每个数据源需要一周的开发时间，光是"接数据"就会耗尽工程团队的带宽。

**How**：Voice 模型的设计从一开始就考虑了泛化性。`source_type` 枚举覆盖了 8 种常见来源类型（feedback、review、interview、social、support、survey、nps、community），每种类型有对应的默认字段映射模板。`source_metadata` 是一个 JSONB 字段，用于存储任何来源特定的结构化信息——App 评论的星级、NPS 调查的分数、客服工单的优先级——无需修改数据库 schema。

**Benefit**：数据接入的边际成本趋近于零。这意味着组织可以快速拓宽"听觉"范围——从核心渠道到长尾渠道，从主动反馈到被动提及——而不会因为工程瓶颈错失关键信号。

---

## 4. 能力群 3：知识资产体系

> 类比：如果语义理解引擎是"选矿厂"产出精矿，知识资产体系就是"冶金工厂 + 金库"——它把精矿冶炼成可直接使用的金属（Signal → Concept），然后存入金库供组织反复取用。

### 4.1 Signal 自动产生机制

**What**：Signal 是系统自动检测到的"值得注意的变化"——一个新涌现的标签、一次情感的异常波动、一个快速增长的话题聚类。Signal 是原始的、未经确认的、由 AI 发现的"苗头"。

**Why**：在海量用户反馈中，绝大多数内容是"正常的噪声"。真正有价值的是"异常信号"——某个标签突然出现并快速增长、某个话题的情感急剧转负、某个用户群体开始集中抱怨某个功能。人类分析师不可能 7x24 小时盯着数据流，但洞察发现引擎可以。

**How**：Prism 的洞察发现引擎部署了五个并行分析器，持续监控数据变化：

| 分析器 | 检测目标 | 触发条件示例 |
|--------|---------|-------------|
| 趋势分析器 | 标签使用量、情感均值的时间趋势 | 某标签 4 周内增长超过 50% |
| 异常检测器 | 反馈数量、情感比例的统计异常 | 今日反馈量偏离均值 2 个标准差 |
| 聚类分析器 | 向量空间中的自然聚类 | 发现一个包含 50+ 条相似反馈的新聚类 |
| 情感分析器 | 整体和分标签的情感变化 | 某标签的平均情感从 0.2 降至 -0.3 |
| 涌现检测器 | 新标签、新表达方式、新用户需求 | 一个全新标签在 7 天内被使用 5 次以上 |

五个分析器按三个频率运行：每小时快速扫描（异常检测 + 涌现检测）、每天深度分析（趋势 + 聚类 + 情感）、每周全面复盘（所有分析器全量运行）。高优先级的发现（P0/P1）自动触发通知。

**Risk**：过于敏感的检测阈值会导致"狼来了"效应——太多 Signal 淹没团队。缓解措施是加权优先级评估器（综合考虑严重程度、影响范围、趋势方向、情感强度、置信度五个维度）和可调节的阈值配置。

**Benefit**：Signal 机制让组织从"被动看报表"转变为"主动被通知"。新问题的发现时间从"月报出来时"缩短到"问题涌现的第一天"。

### 4.2 Concept 人机共治流程

**What**：Concept 是经过人类确认的、稳定的知识资产。Signal 是 AI 发现的候选者，Concept 是组织认可的正式资产。从 Signal 到 Concept 的升级需要人类参与。

**Why**：Signal → Concept 的分离解决了一个根本性矛盾：AI 擅长发现但不擅长判断"是否值得组织投入资源"，人类擅长判断但没有精力逐条筛选。把探索交给 AI、把决策交给人类，各取所长。

**How**：Concept 的治理流程包括五个操作：

| 操作 | 说明 | 谁执行 |
|------|------|--------|
| **确认（Confirm）** | 将 Signal 升级为正式 Concept | 人类 |
| **命名（Rename）** | 修正 AI 的命名建议 | 人类 |
| **合并（Merge）** | 将多个相似的 Signal/Concept 合并 | 人类决策，系统执行 |
| **静音（Mute）** | 标记不值得关注的 Signal | 人类 |
| **追踪（Track）** | 将 Concept 纳入持续监控 | 人类设定规则，系统自动执行 |

每个操作都留有审计轨迹（谁、什么时候、为什么、影响了什么），确保组织的知识治理可追溯。

**Risk**：人类审核可能成为瓶颈——如果每天产生 100 个 Signal，谁来一个个看？缓解措施是优先级排序（只有 P0/P1 需要立即处理）和批量操作（一次合并多个相似 Signal）。

**Benefit**：Concept 不只是一个标签，而是一个活的知识资产——它有定义、有证据、有趋势、有负责人、有处置历史。当同类问题再次出现时，组织可以直接复用既有的处置模板，而不是每次从零开始。这就是"组织复利效应"的核心机制。

### 4.3 原子查询工具：8 个检索原语

**What**：Prism 为 AI Agent 提供 8 个精心设计的原子查询工具，而不是预设好的分析 API。

**Why**：传统系统会设计 `get_weekly_summary()`、`get_top_issues()` 这样的复合 API，预设了分析场景。问题在于：你无法预见所有使用场景，而预设策略往往是次优的。Prism 遵循 Unix 哲学——"做一件事，做好它"——提供最小能力原语，让 AI Agent 根据当前任务自主组合检索策略。

**How**：

| 工具 | 功能 | 典型用法 |
|------|------|---------|
| `vector_search` | 基于语义相似度检索片段 | "找到所有关于支付体验的反馈" |
| `get_neighbors` | 获取指定片段的向量空间近邻 | "这个片段附近还有什么相似的？" |
| `random_sample` | 随机采样片段 | "让我随机看看最近的反馈长什么样" |
| `get_tags` | 获取标签列表及统计信息 | "最近涌现了哪些新标签？" |
| `get_units_by_tag` | 按标签获取片段 | "所有标记为'搜索性能'的反馈" |
| `get_related_units` | 通过显式关系获取关联片段 | "和这个观点矛盾的反馈有哪些？" |
| `get_original_voice` | 从片段追溯到原始反馈 | "这个片段的原文是什么？" |
| `get_tag_statistics` | 获取标签使用统计 | "各标签的使用分布如何？" |

`random_sample` 值得特别关注。它看似简单，实则是对抗"信息茧房"的关键武器——向量搜索天然趋向于返回相似内容，而随机采样让 Agent 有机会"跳出去"发现意外洞察。就像好的研究者不会只看自己领域的论文，也会随机翻翻其他领域。

Agent 通过组合这些工具实现复杂分析。例如"最近用户主要在抱怨什么"这个需求，Agent 可能的策略是：先用 `get_tags(sort_by="recent")` 了解新涌现标签，再用 `get_units_by_tag` 深入每个标签，最后用 `random_sample` 检查是否有遗漏——这个策略不是系统预设的，而是 Agent 根据任务自主规划的。

**Risk**：原子工具对 Agent 的推理能力有较高要求——如果 Agent 的策略规划能力不足，可能无法有效组合工具。缓解措施是提供策略模板库（探索式、深度追踪式、对比式、趋势式、诊断式五种策略模式）作为参考。

**Benefit**：8 个原子工具可以覆盖无限多的分析场景，而不是 N 个复合 API 只能覆盖 N 个场景。更关键的是，当系统的数据和能力演化时，Agent 的分析策略可以随之演化——不需要修改 API，只需要让 Agent 学会新的组合方式。

### 4.4 组织复利效应的形成机制

**What**：复利效应指的是知识资产的价值随使用时间非线性增长——已确认的 Concept 加速新 Signal 的识别，已积累的标签网络让新数据的处理更准确，已验证的分析策略让后续分析更高效。

**Why**：这是 Prism 与传统 VOC 工具最本质的区别。传统工具的价值是线性的——处理一万条和处理十万条，洞察质量没有本质提升。Prism 的语义网络和标签体系会随着数据量增长而"变聪明"——标签标准化的同义词表越来越完善，向量空间中的语义拓扑越来越清晰，Signal 检测的准确率越来越高。

**How**：复利效应的三个飞轮：

1. **标签飞轮**：更多数据 → 更完善的标签标准化表 → 新数据的标签更准确 → 检索和聚合更精准
2. **向量飞轮**：更多向量 → 语义空间的拓扑更清晰 → 相似度检索和聚类分析更有效 → 关系网络更密集
3. **治理飞轮**：更多 Concept 被确认 → 同类问题的处置模板更丰富 → 新问题的响应更快 → 组织学习能力更强

**Benefit**：组织使用 Prism 的时间越长，知识资产越丰富，分析能力越强，响应速度越快。这种自增强效应构成了竞争壁垒——竞争对手可以复制软件功能，但无法复制你已经积累的知识资产。

---

## 5. 能力群 4：LLM 统一网关

> 类比：LLM 网关之于 Prism，就像发电厂之于整座城市——你不需要每栋楼自建发电机，只需要接入统一的电网。电网负责供电的稳定性、成本的优化、以及停电时的应急预案。

### 5.1 LiteLLM 统一集成

**What**：Prism 的 LLM 网关通过与 OpenAI API 兼容的统一接口，将多家 LLM Provider（硅基流动、OpenRouter、Kimi、MiniMax 等）封装在一个服务后面。所有上游服务（语义理解引擎、Agent 运行时、前端对话）只需要调用一个 API 端点。

**Why**：LLM 市场正处于"百花齐放"阶段。没有任何一家 Provider 在所有维度（价格、速度、质量、可用性）上都是最优的。绑定单一 Provider 既有供应商锁定风险，又无法利用不同 Provider 的各自优势。统一网关让"选择哪家 Provider"变成了一个配置问题而非架构问题。

**How**：LLM 网关实现了三层抽象：

| 抽象层 | 功能 | 示例 |
|--------|------|------|
| **Provider 层** | 封装不同厂商的 API 差异 | siliconflow(api_key, base_url), openrouter(api_key, base_url) |
| **模型层** | 定义具体模型及其参数 | qwen-plus@siliconflow, gpt-4o@openrouter |
| **别名层** | 为业务场景提供语义化名称 | `default-chat` → qwen-plus@siliconflow |

所有 Provider 都实现同一个抽象基类（`BaseLLMProvider`），提供 `chat`、`embedding`、`rerank` 三个标准方法。由于当前主流 Provider 均兼容 OpenAI API 格式，适配器的差异主要在 Base URL、额外 Header 和错误响应格式上——复杂度很低。

### 5.2 多模型策略引擎（别名系统）

**What**：别名系统是 Prism 的 LLM 调度核心。上游服务不直接指定 Provider 和模型，而是使用语义化别名（如 `default-chat`、`fast-chat`、`default-embedding`）。别名到实际模型的映射由管理员配置，运行时自动解析。

**Why**：别名系统解决了三个实际问题：

1. **团队沟通成本**：没有别名时，开发者需要记住"硅基流动的 Qwen/Qwen2.5-72B-Instruct"这样冗长的标识；有了别名，只需说"用 default-chat"
2. **切换零成本**：从 Qwen 切换到 GPT-4o，只需改别名映射，不需要改任何业务代码
3. **环境一致性**：开发环境用便宜的模型，生产环境用高质量模型，别名相同，代码不变

**How**：每个别名配置包含一个主模型和一个有序的降级模型列表。当主模型不可用时，系统自动切换到降级模型。这就引出了下一个关键设计。

### 5.3 三级降级服务韧性

**What**：Prism 的 LLM 调用具备三级降级能力，确保在 Provider 故障、模型不可用等情况下仍能提供服务。

**Why**：LLM 服务的可用性直接决定了 Prism 全链路的可用性。语义拆解、标签生成、Agent 推理、前端对话——几乎所有核心功能都依赖 LLM。如果 LLM 服务挂了，整个系统就停摆了。在 LLM Provider 服务稳定性参差不齐的当下，这不是理论风险。

**How**：

| 降级级别 | 触发条件 | 行为 | 用户感知 |
|---------|---------|------|---------|
| **Provider 级降级** | 某 Provider 连续调用失败 | 切换到同模型的其他 Provider | 几乎无感知，延迟微增 |
| **模型级降级** | 首选模型不可用 | 切换到别名的降级模型列表 | 可能感知到输出质量变化 |
| **功能级降级** | 所有模型均不可用 | 使用缓存/规则兜底，标记待重处理 | 功能降级但不中断 |

健康检查机制是降级策略的基础：被动检查（调用失败即标记不健康）+ 主动恢复（不健康的 Provider 每 60 秒尝试恢复探测）。健康状态缓存在 Redis 中，所有服务实例共享同一份健康视图。

**Risk**：降级链过长可能导致延迟累积。如果主模型、降级模型 1、降级模型 2 都需要超时后才失败，用户等待时间会很长。缓解措施是设置合理的超时时间和快速失败策略——如果一个 Provider 在 5 秒内没有响应第一个 token，立即切换到下一个。

**Benefit**：三级降级策略让 Prism 的"LLM 可用性"不再等于"任何单一 Provider 的可用性"，而是趋近于"所有 Provider 同时宕机的概率"——这个概率在配置了 3-4 个 Provider 后极低。对业务的含义是：**语义处理管线可以 7x24 小时不间断运行，洞察发现不会因为某家 LLM 厂商的抖动而中断**。

---

## 6. 能力群 5：用户体验层

> 类比：如果说前四个能力群是乐队的乐手，用户体验层就是指挥和音乐厅——再好的演奏如果没有好的指挥编排和音响效果，观众也无法获得完整的体验。

### 6.1 三层渐进式信息架构

**What**：Prism 的 UI 采用"概览 → 探索 → 深钻"三层渐进式信息架构，让用户从宏观到微观逐步深入。

**Why**：信息过载是数据产品的头号杀手。把所有数据一股脑堆在仪表板上，结果是用户什么都看到了但什么都没理解。渐进式架构遵循"先概览后细节"（Overview first, zoom and filter, then details-on-demand）的可视化设计原则，让不同角色按自己需要的深度获取信息。

**How**：

| 层级 | 受众 | 内容 | 交互 |
|------|------|------|------|
| **概览层** | CEO/VP | 关键指标卡片、情感趋势线、P0/P1 洞察摘要 | 一眼扫过，点击进入 |
| **探索层** | 产品经理/研发 Lead | 标签云、聚类可视化、时间热力图、Concept 治理工作台 | 筛选、排序、对比 |
| **深钻层** | 分析师/研究员 | 单个 SemanticUnit 详情、原始 Voice 全文、关系图谱、Agent 对话式分析 | 逐条查看、溯源、追踪 |

每一层都是下一层的入口。CEO 在概览层看到"本周支付相关负面反馈增长 200%"，点击进入探索层看到具体是哪些标签在增长，再点击进入深钻层看到用户的原始表述。

**Risk**：三层架构增加了前端开发的复杂度。缓解措施是利用 React 组件化和 shadcn/ui 组件库降低实现成本。

**Benefit**：不同角色各取所需。CEO 花 30 秒看完概览做决策，产品经理花 10 分钟在探索层做优先级排序，分析师花 1 小时在深钻层做根因分析——同一套数据，三种消费方式。

### 6.2 可解释的 AI 洞察呈现

**What**：Prism 的每一个 AI 洞察都附带完整的证据链——从聚合结论到代表性引用到原始 Voice，一路可追溯。

**Why**：AI 洞察如果不可解释，就不可信任；不可信任，就不会被采纳。"系统告诉我支付体验在恶化"——作为 VP，你的第一反应不是"好的我来修"，而是"证据呢？多少人说的？他们原话怎么说的？趋势是什么？"

Prism 的可解释设计原则是：**每个数字都能点击展开，每个结论都能追溯到原始证据**。

**How**：洞察呈现的四层可溯源结构：

```
洞察摘要：「支付页面卡顿问题本周爆发，影响约 500 位 iOS 用户」
  ├── 量化指标：反馈数 87 条，负面情感比例 92%，7日增长率 300%
  │     └── 点击展开：按天分布柱状图 + 按来源分布饼图
  ├── 代表性引用（3 条）
  │     ├── "付款的时候一直转圈，等了两分钟..." [情感: -0.8, 来源: App评论]
  │     ├── "支付页面又卡住了，这是这周第三次了" [情感: -0.9, 来源: 客服工单]
  │     └── "结账环节体验太差了，每次都要..." [情感: -0.7, 来源: NPS]
  │           └── 点击任一引用：跳转到完整原始 Voice
  └── AI 建议：建议紧急排查 iOS 17.2 + Stripe SDK 兼容性
        └── 置信度: 0.85，依据: 87 条反馈中 73 条来自 iOS 17.2 用户
```

**Benefit**：可解释设计将 AI 洞察从"黑盒输出"变成"可审查的推理过程"。产品团队不再需要盲目信任 AI，而是可以快速验证每个结论的可靠性。这极大地降低了组织采纳 AI 洞察的心理门槛。

### 6.3 类型安全 API 客户端层

**What**：前端通过自动生成的类型安全 API 客户端与后端通信，而不是手写 HTTP 请求。

**Why**：前后端的 API 协议是最容易出错的地方——字段名拼写错误、类型不匹配、枚举值缺失——这些 Bug 在运行时才暴露，排查成本极高。类型安全的 API 客户端在编译时就能捕获这些问题。

**How**：后端的 Pydantic v2 模型 → OpenAPI Schema → 前端 TypeScript 类型定义和 API 客户端代码。整条链路自动化，无需手动同步。统一响应格式 `{ "data": ..., "meta": { "request_id", "timestamp" } }` 确保所有 API 的错误处理逻辑一致。

**Benefit**：前后端协议变更时，类型检查在编译阶段就能发现不兼容——而不是上线后才在用户的浏览器里报错。

### 6.4 SSE 流式对话引擎

**What**：前端的 AI 分析对话采用 Server-Sent Events（SSE）实现流式输出，让用户看到 AI 的"思考过程"逐字显现。

**Why**：LLM 生成一段完整回复需要数秒到数十秒。如果采用传统的请求-响应模式，用户在等待期间看到的是一个空白屏幕和一个旋转的加载图标。SSE 流式输出让用户在第一个 token 生成后就开始看到内容，极大地改善了感知延迟。

**How**：SSE 连接从前端经由 API 网关透传到 LLM 网关，LLM 网关再透传到实际的 LLM Provider。整条链路都是流式的，第一个 token 的到达时间（Time to First Token）通常在 200-500 毫秒。

**Benefit**：用户体验从"等 8 秒看到完整结果"变成"200 毫秒后开始逐字看到回答"。在 AI 对话式分析的场景中，这不仅是体验优化，更是交互模式的升级——用户可以在 AI 生成过程中就开始思考和追问。

---

## 7. 能力间的协同效应

### 7.1 能力依赖矩阵

下表展示了五个能力群之间的依赖关系。行是"提供方"，列是"消费方"。

|  | 语义理解 | 数据接入 | 知识资产 | LLM 网关 | 用户体验 |
|--|---------|---------|---------|---------|---------|
| **语义理解** | - | - | SemanticUnit + Tag | - | 结构化数据 |
| **数据接入** | 标准化 Voice | - | - | - | - |
| **知识资产** | - | - | - | - | Concept + Signal + 检索结果 |
| **LLM 网关** | Chat + Embedding | - | 洞察发现引擎的 LLM 调用 | - | SSE 流式对话 |
| **用户体验** | - | - | 治理操作回写 | - | - |

这张矩阵揭示了两个关键事实：

1. **LLM 网关是最被依赖的能力**——四个能力群中有三个直接依赖它。这解释了为什么它的三级降级策略如此重要。
2. **用户体验层是唯一向知识资产体系"回写"的能力**——人类在 UI 中的治理操作（确认、命名、合并）会修改知识资产的状态。这形成了一个闭环：AI 发现 → 人类确认 → 系统学习 → AI 更准确。

### 7.2 端到端协同场景

让我们用一个完整的用户旅程来展示五个能力群如何协同工作。

**场景**：App 更新后用户集中抱怨"支付页面卡住"

**Day 0（15:00）——数据接入框架**

App Store 评论、Zendesk 工单、社交媒体提及同时涌入。数据接入框架的 Source Adapter 将来自三个渠道的数据统一转化为标准 Voice 模型，自动设置 `source_type`、`collected_at` 等元信息。

**Day 0（15:01）——语义理解引擎**

新 Voice 进入四阶段管线。Stage 1 将"付款的时候一直转圈，等了两分钟还没好，但你们的搜索功能还是很好用的"拆解为两个 SemanticUnit：(1) 支付页面卡顿 [情感:-0.8, 意图:complaint] (2) 搜索功能满意 [情感:+0.6, 意图:praise]。Stage 2 为(1)生成标签"支付卡顿""页面加载超时""结账体验差"。Stage 3 将两个片段向量化。Stage 4 发现(1)与过去 2 小时内 30 条其他片段高度相似。

**Day 0（15:01-15:30）——LLM 统一网关**

语义理解引擎在 30 分钟内处理了 87 条相关 Voice。LLM 网关的主模型（siliconflow/Qwen2.5-72B）在 15:15 出现短暂不可用，自动切换到降级模型（openrouter/Qwen2.5-72B），60 秒后主模型恢复，自动切回。整个切换过程对上游透明。

**Day 0（16:00）——知识资产体系**

洞察发现引擎的小时级快速扫描检测到异常：标签"支付卡顿"在过去 1 小时内从 0 次增长到 53 次，触发 Signal 产生。异常检测器同时发现今日反馈量偏离均值 2.8 个标准差，负面情感比例达到 47%。系统生成 P0 级 Signal："支付页面卡顿问题爆发"。

**Day 0（16:05）——用户体验层**

产品负责人收到 Slack 通知。点击链接进入概览层，看到 P0 洞察摘要。进入探索层，看到"支付卡顿"标签的时间线——15:00 前几乎为零，15:00 后直线上升。进入深钻层，阅读用户原文，发现绝大多数来自 iOS 17.2 用户。在 Concept 治理工作台中，将 Signal 确认为 Concept "iOS 17.2 支付页面卡顿"，指派给支付团队。

**Day 1（09:00）——闭环**

支付团队在 Prism 中查看 Concept 详情，利用 Agent 对话式分析工具进一步诊断：Agent 组合 `vector_search`、`get_neighbors`、`get_related_units` 发现问题与 Stripe SDK 3.2.0 版本更新相关。团队确认根因，发布修复版本。Concept 状态更新为 "resolved"，系统自动开始追踪"修复后情感是否回升"。

**这个场景的关键洞察**：五个能力群中任何一个的缺失都会导致流程断裂——没有数据接入框架，数据进不来；没有语义理解引擎，文本无法被结构化处理；没有 LLM 网关，AI 处理可能因 Provider 故障而中断；没有知识资产体系，异常不会被自动发现；没有用户体验层，人类无法参与治理和决策。**五个能力群不是"五个功能"，而是"一个有机体的五个器官"。**

---

## Key Takeaways

1. **语义理解引擎是 Prism 的"价值工厂"**。SemanticUnit 的六层信息结构、四阶段异步管线、涌现式标签双轨设计、三级降级守卫——这些不是过度设计，而是确保从非结构化文本到结构化语义知识的转化过程既高质量又高可靠。

2. **数据接入框架决定了"听觉范围"**。声明式 Source Adapter 让新数据源的接入成本趋近于零，确保组织不会因为工程瓶颈而错失关键渠道的客户声音。

3. **知识资产体系是 Prism 的"长期记忆"**。Signal 自动产生机制让组织从"被动看报表"变为"主动被通知"；Concept 人机共治流程让 AI 的发现能力和人类的判断能力各得其所；8 个原子查询工具让 Agent 拥有无限的分析策略组合空间。

4. **LLM 统一网关是全链路的"生命线"**。别名系统消除了 Provider 差异带来的复杂度，三级降级策略将 LLM 可用性从"单 Provider 的 SLA"提升到"多 Provider 联合的 SLA"。它是被依赖最多的底层能力，其可靠性直接决定了整个系统的上限。

5. **用户体验层让 AI 洞察"可信、可用、可行动"**。三层渐进式架构让不同角色各取所需，可解释的证据链让每个结论都经得起追问，SSE 流式对话让人机交互从"等结果"变为"看过程"。

6. **协同效应是真正的护城河**。单独来看，每个能力群都可以被竞争对手模仿。但五个能力群相互咬合形成的自增强飞轮——特别是"AI 发现 → 人类确认 → 系统学习 → AI 更准确"的闭环——是无法通过复制单个功能来复制的。**Prism 的价值不在于它有哪些能力，而在于这些能力如何协同放大彼此。**

7. **组织复利效应是长期价值的核心论据**。系统越用越聪明、知识资产越积越厚——这意味着 Prism 的投资回报率不是线性的，而是指数级的。越早开始积累，壁垒越高。

---

*本章深入剖析了 Prism 的五个核心能力群。下一章将展示 Prism 如何在真实业务场景中串联这些能力，从"发现问题"到"推动行动"形成完整闭环。*
