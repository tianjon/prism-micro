# 发展路线图

---

## 对齐说明（2026-02-20）

- 本路线图当前实现基线以 `docs/prd/02-prd-phase1.md` 为准。
- LLM 路由语义统一为 4 槽位（`fast/reasoning/embedding/rerank`），不再以别名系统作为当前阶段主路径。
- API 契约采用“新增目标路由 + 保留旧路由一个迭代周期”的兼容策略，见 `docs/prd/04-contract-alignment-migration.md`。

---

## TL;DR（高管速读版）

Prism 的路线图不是"功能清单的排期表"，而是一份**能力叠加的工程计划**——每个阶段独立可交付、可演示、可评审，后一阶段的启动以前一阶段的验收通过为前提。

六个阶段的核心逻辑可以用一句话概括：**先建地基（Phase 1），再通电力（Phase 2），然后搭骨架（Phase 2.5），接着长肌肉（Phase 3），然后练武功（Phase 4-5），最终开宗立派（Phase 6）。**

最值得关注的是 Phase 2.5——Agent 基础运行时。这是一个看似"多余"实则"救命"的阶段。常规思路是"先有数据再建分析工具"，但我们选择"先搭 Agent 骨架再灌数据"。原因很简单：骨架搭错了，肌肉长得越多，矫正的代价越大。Phase 2.5 的 Agent 运行时确保了后续每一个新能力上线后，都能立即被 Agent 编排使用——而不是"功能做好了，Agent 还没准备好"。

管理层最关心的三个事实：
1. **每个阶段都有可演示的成果**——不会出现"投入了半年但看不到东西"的局面
2. **每个阶段都有 Go/No-Go 评审点**——管理层始终保有决策主动权
3. **阶段之间的依赖是单向的**——Phase 3 的延期不会导致 Phase 2.5 的返工

---

## 1. 路线图设计原则

在展开六个阶段的详细内容之前，有必要先阐明四条贯穿全程的设计原则。这些原则不是事后总结的"最佳实践"，而是事前约定的"工程宪法"——每一个阶段的交付范围、技术选型、团队配置都必须通过这四条原则的校验。

### 1.1 每阶段独立可交付、可演示

这是路线图设计的第一铁律。每个阶段的交付物必须是一个可以在会议室里打开浏览器（或终端）、当场演示的可工作软件，而不是一份设计文档或一堆"跑通了单元测试"的代码。

为什么如此坚持？因为软件项目最大的风险不是技术失败，而是**长期不可见性导致的信任流失**。管理层不怕你犯错，怕的是你花了六个月但"还没到能看的时候"。每个阶段的可演示成果就是一份实物形式的进度报告——比任何 PPT 都有说服力。

### 1.2 基础设施从简

不在 Day 1 引入你"未来可能需要"的全部基础设施。Phase 1 只需要 PostgreSQL + Redis，不需要 Kafka、不需要 Elasticsearch、不需要 Kubernetes。每新增一个基础设施组件都意味着运维负担和认知负荷的增加——在 3-5 人的团队规模下，这些负担会直接挤压业务开发的带宽。

原则是：**当某个阶段的交付物明确需要某项基础设施时，才引入它——而不是"将来肯定要用，不如提前装好"。** 提前装好的东西，维护成本是即刻产生的，收益却是延迟兑现的。

### 1.3 API 先于 UI

所有能力先以 API 形式暴露，再构建 UI。这不是因为"后端比前端重要"，而是因为 API 是系统能力的**契约化表达**。一个没有 API 的功能，只有前端能调用；一个有 API 的功能，前端、CLI、Agent、外部系统都能调用。在 Agent-First 的架构下，API 是所有消费者的公共入口，UI 只是其中一个消费者。

具体来说：每个阶段先交付 API + 自动化测试，再交付 UI。如果时间紧张，可以延后 UI 的精细打磨，但不能延后 API 的设计和实现。

### 1.4 渐进式能力叠加

后一阶段的能力建立在前一阶段的基础之上，但不修改前一阶段已交付的核心接口。这确保了两件事：第一，已验收的功能不会因为新开发而回退；第二，团队可以并行推进——Agent 团队在做 Phase 2.5 的时候，不需要等 Phase 2 的 LLM 调用层"冻结"后才能开始。

这个原则的工程实现依赖于第六章（技术蓝图）中讨论的"依赖方向不可逆"约束。每个服务只依赖下层，不依赖上层和同层——新阶段引入的服务是"上层消费者"，而不是"修改下层实现"。

---

## 2. Phase 1：基础设施 + 模型配置（已完成）

### 目标

搭建微服务骨架，完成 LLM 模型资源的配置管理和连通性验证。这是整个系统的地基——地基不需要华丽，但必须坚固。

### 核心交付物

| 交付物 | 说明 |
|--------|------|
| **shared 共享库** | DB Session 管理、JWT 工具、认证中间件、通用响应模型——所有服务的"工具箱" |
| **user-service** | 用户注册/登录、JWT 签发/刷新——解决"谁能访问系统"的问题 |
| **llm-service 管理功能** | Provider CRUD、Model CRUD、Alias CRUD、连通性测试——解决"系统知道哪些模型可用"的问题 |
| **Web UI** | 登录页 + Provider/Model/Alias 配置管理页面——让非技术用户也能配置模型资源 |
| **基础设施** | Docker Compose（PostgreSQL 17 + pgvector + Redis 7）、uv workspace monorepo 结构 |

### 关键决策

| 决策 | 选择 | 理由 |
|------|------|------|
| 包管理方案 | uv workspace | Monorepo 场景下唯一能做到"统一 lockfile + path dependency"的方案 |
| 数据库隔离 | PostgreSQL Schema 隔离 | `auth`/`llm` 各用独立 schema，隔离度足够且运维零成本 |
| 前端框架 | React 19 + Vite + shadcn/ui | AI 辅助编码友好、组件源码可控、Tailwind 原子化 CSS |

### 验收标准

1. 用户可以注册账号并登录 Web UI
2. 用户可以添加一个 Provider（填入 API Key 和 Base URL）
3. 点击"测试连接"按钮，显示连接成功/失败及延迟
4. 用户可以为 Provider 添加模型，创建别名并关联到模型
5. 所有操作持久化到 PostgreSQL，刷新页面数据不丢失

### 团队配置

后端 x1 + 前端 x1 + DevOps x0.5（约 2.5 人），周期约 4 周。

---

## 3. Phase 2：LLM 调用能力

### 目标

将 llm-service 从"配置管理工具"升级为"可用的 LLM 网关"——系统不再只是"知道有哪些模型"，而是"能真正调用这些模型"。这是从"静态配置"到"动态能力"的质变。

### 核心交付物

| 交付物 | 说明 |
|--------|------|
| **Chat API** | `/api/llm/chat`，支持流式（SSE）和非流式响应，别名自动解析 |
| **Embedding API** | `/api/llm/embedding`，文本向量化，为 Phase 3 的语义检索打底 |
| **Rerank API** | `/api/llm/rerank`，结果重排序，提升检索精度 |
| **LiteLLM 集成** | 引入 LiteLLM 替代自建 Provider 适配器，覆盖 100+ Provider |
| **故障转移引擎** | 别名绑定降级链（primary → fallback），自动健康检查与切换 |
| **CLI 基础版** | `prism chat`、`prism embed`、`prism model list/test` |

### 关键决策

| 决策 | 选择 | 理由 |
|------|------|------|
| LLM 调用层 | LiteLLM | 覆盖 100+ Provider，避免自建 N 个适配器；社区活跃，持续维护 |
| 流式协议 | SSE（Server-Sent Events） | 与 OpenAI 兼容格式一致；浏览器原生支持；单向流天然匹配 LLM 输出场景 |
| 健康检查策略 | 被动检测 + 主动恢复 | 调用失败即标记不健康，60 秒恢复探测；状态存 Redis，多实例共享 |

### 验收标准

1. 通过别名调用 Chat API，获得流式和非流式响应
2. 通过别名调用 Embedding API，返回正确维度的向量
3. 手动关闭主模型的 Provider，系统自动切换到降级模型，调用方感知到 `degraded=true` 标记
4. CLI 可以完成基本的对话和模型列表查看
5. 降级恢复后，流量自动回切到主模型

### 团队配置

后端 x2 + 前端 x0.5（CLI + Web 简单适配），周期约 4-6 周。

---

## 4. Phase 2.5：Agent 基础运行时

> **这是整条路线图中最反直觉、也最关键的阶段。**

### 目标

交付 Agent 运行时的"骨架"——Skill 注册表、基础 Agent Loop、双身份认证、执行上下文管理。此阶段的 Agent 能力非常有限（只能调用 LLM 相关的 Skill），但"Agent 基础设施"已经完整就位。

### 为什么必须在 VOC 数据层之前

常规思路是"先有数据，再有分析工具"——先建好 VOC 数据管线（Phase 3），再让 Agent 来分析这些数据。这个直觉是错误的，原因有三：

**第一，骨架先于肌肉。** Agent 运行时是系统的骨架——Skill 注册表定义了"系统有哪些能力"，Agent Loop 定义了"如何组合这些能力"，执行上下文定义了"在什么约束下执行"。如果骨架没有提前就位，Phase 3 的 VOC 数据能力就会以"裸 API"的形式交付，后续再想把这些 API 包装成 Skill 塞进 Agent 框架，就是典型的"后期改造"——第五章（Agent-First 设计哲学）中详细论证过，这种改造的成本是初始设计的 5-10 倍。

**第二，提前验证架构假设。** Agent Loop 的 ReAct 循环、Skill 的声明式注册、双身份认证的 Principal 统一——这些都是架构级设计，需要尽早在真实环境中验证。在数据量小、复杂度低的时候发现和修复架构问题，比在系统已经"长满肌肉"后再动骨骼，代价小两个数量级。

**第三，团队并行开发。** Phase 2.5 的 Agent 基础设施和 Phase 3 的 VOC 数据管线有清晰的接口边界——Skill 契约。Agent 团队和数据团队可以各自推进：Agent 团队定义 Skill 契约，数据团队按照契约实现数据能力。当 Phase 3 完成时，新的 Skill 注册进注册表，Agent 立即可用——零集成成本。

用一个管理者更熟悉的类比：**Phase 2.5 就是在建毛坯房的时候就把水电管线预埋好。不预埋的代价不是"多花一点装修费"，而是"砸墙重来"。**

### 核心交付物

| 交付物 | 说明 |
|--------|------|
| **Skill 注册表** | 声明式工具定义（JSON Schema）、CRUD 管理 API、权限校验——Agent 的"工具目录" |
| **基础 Agent Loop** | ReAct 循环（推理 → 工具选择 → 执行 → 结果评估 → 继续/终止），固定迭代上限 |
| **双身份认证** | Human JWT + Agent API Key → 统一 Principal 身份对象；下游服务只认 Principal |
| **执行上下文** | 权限边界（Capability 白名单）、资源配额（迭代/token/时间/成本上限）、审计日志 |

### 关键决策

| 决策 | 选择 | 理由 |
|------|------|------|
| Agent 框架 | 自建轻量 Agent Loop | 当前需求明确，避免引入 LangChain/LangGraph 等重框架的学习成本和依赖风险；保留后续替换空间 |
| 身份模型 | 统一 Principal 抽象 | 人类和 Agent 殊途同归，下游服务零感知差异；这是 Type 1（不可逆）决策，必须在 Day 1 做对 |
| 数据存储 | `agent` Schema | 延续 Schema 隔离策略，与 `auth`/`llm` 平级，独立迁移 |

### 验收标准

1. Agent 可以通过 API Key 认证，系统识别其为 Agent Principal
2. Agent 可以查询 Skill 注册表，获取当前可用的 Skill 列表
3. Agent 可以执行一次完整的 ReAct 循环：推理 → 选择 `llm_chat` Skill → 调用 → 评估结果 → 终止
4. 系统为每次 Agent 执行生成完整的审计日志（谁、做了什么、花了多少 token、结果如何）
5. 当 Agent 超出资源配额（迭代上限或成本上限）时，系统优雅终止并返回部分结果

### 团队配置

后端 x2（Agent 运行时 + 认证改造）+ 前端 x0.5（管理界面），周期约 4-6 周。

### 战略意义

Phase 2.5 的价值不在于"Agent 能做多少事"——此阶段的 Agent 只能调用 LLM 做简单对话——而在于"Agent 基础设施是否可靠"。就像建大楼时先搭好钢结构：里面还没装修，但结构经得住考验。从这个阶段开始，Prism 就从一个"给人用的系统"变成了一个"人和 Agent 共同使用的系统"——这个身份转变是不可逆的，也是 Prism 区别于所有传统 VOC 工具的根本分水岭。

---

## 5. Phase 3：VOC 数据摄入 + 语义底座

> **这是 Prism 从"通用 LLM 网关"蜕变为"VOC 分析平台"的关键阶段。**

### 目标

建立 VOC 数据的摄入、语义拆解、向量化和检索能力。经过此阶段，系统能够接收客户反馈原始文本，将其转化为结构化的语义知识，并通过 8 个原子查询工具支撑 Agent 的分析任务。

### 核心交付物

| 交付物 | 说明 |
|--------|------|
| **四阶段 AI 管线** | Stage 1 语义拆解 → Stage 2 标签涌现 → Stage 3 向量化 → Stage 4 关系构建 |
| **涌现式标签系统** | 双轨设计——涌现标签（LLM 自由生成）+ 预设维度（intent/sentiment 枚举），标签标准化流水线 |
| **向量检索引擎** | 基于 pgvector 的 Embedding 存储和 ANN 近邻搜索，HNSW 索引 |
| **8 个原子查询工具** | vector_search / get_neighbors / random_sample / get_tags / get_units_by_tag / get_related_units / get_original_voice / get_tag_statistics |
| **数据接入框架** | 声明式 Source Adapter、批量导入接口（CSV/JSON）、Voice 标准化模型 |
| **LLM 输出守卫层** | 三级降级（L1 正常 → L2 修正 → L3 降级），确保管线鲁棒性 |

### 与 Agent 运行时的集成点

这是 Phase 2.5 提前交付 Agent 基础设施的回报兑现时刻。Phase 3 的 8 个原子查询工具作为 Skill 注册进 Phase 2.5 已经就位的 Skill 注册表，Agent 立即获得数据分析能力——零集成代码、零适配工作。

```
Phase 2.5 已就位的骨架           Phase 3 注入的肌肉
┌──────────────────┐            ┌──────────────────┐
│  Skill 注册表     │  ◄──注册── │  8 个原子查询 Skill │
│  Agent Loop      │            │  VOC 数据管线      │
│  执行上下文       │            │  向量检索引擎      │
└──────────────────┘            └──────────────────┘
```

如果没有 Phase 2.5，这里就需要一个额外的"集成阶段"来构建 Agent 框架并对接 VOC 数据能力——至少多出 3-4 周的集成和调试时间。

### 关键决策

| 决策 | 选择 | 理由 |
|------|------|------|
| 向量存储 | pgvector（复用 PostgreSQL） | 与业务数据同一事务边界，避免分布式事务；百万级数据量内性能足够 |
| 数据 Schema | 独立 `voc` Schema | 延续 Schema 隔离策略，与 `llm`/`auth`/`agent` 平级 |
| 工具设计哲学 | 原子化、不预设策略 | 8 个原子工具的自由组合 > N 个复合 API；Agent 可自主规划分析策略 |
| Embedding 模型 | BGE-large-zh-v1.5 | 中文语义理解最优，1024 维向量，通过 LLM 网关的别名系统调用 |

### 验收标准

1. 通过 CSV 导入 1000 条用户反馈，系统自动完成四阶段 AI 处理
2. 每条反馈被拆解为 1-N 个 SemanticUnit，每个 Unit 携带意图、情感、涌现标签、embedding
3. 通过 `vector_search` 搜索"支付卡顿"，返回语义相关（而非关键词匹配）的结果
4. Agent 可以组合原子 Skill 完成基础分析任务：如"找到所有关于支付功能的负面反馈"
5. 单条 Voice 的端到端处理时间 < 10 秒，千条批量处理 < 30 分钟
6. LLM 处理失败时，L3 降级策略生效——原始数据保留，标记待重处理

### 团队配置

后端 x2（数据管线 + 查询工具）+ AI 工程师 x1（Prompt 工程 + 守卫层）+ 前端 x1（数据浏览 UI），周期约 6-8 周。

---

## 6. Phase 4：语义检索 + 概念治理

### 目标

在 Phase 3 的语义底座之上，构建知识资产管理体系。系统从"被动存储和检索数据"升级为"主动发现异常信号并支持人机协同治理"。这是 Prism 从"数据工具"向"知识平台"跨越的阶段。

### 核心交付物

| 交付物 | 说明 |
|--------|------|
| **Concept Layer** | Signal → Concept 两阶段知识资产管理；Signal 由 AI 自动发现，Concept 由人类确认 |
| **人机共治工作台** | 五个治理操作：确认（Confirm）、命名（Rename）、合并（Merge）、静音（Mute）、追踪（Track） |
| **Signal 自动产生** | 五个并行分析器（趋势/异常/聚类/情感/涌现），三频率运行（小时/天/周） |
| **高级检索能力** | 混合检索（语义 + 结构化过滤）、时间范围查询、按 Concept 聚合分析 |
| **优先级评估器** | 五维度加权评分（严重程度、影响范围、趋势方向、情感强度、置信度）自动为 Signal 排序 |

### 关键决策

| 决策 | 选择 | 理由 |
|------|------|------|
| Signal 产生策略 | 多分析器并行 + 分频率调度 | 高频（小时级）捕获突发异常，低频（周级）发现渐进趋势；分频率降低计算成本 |
| 治理模型 | AI 提议 + 人类决策 | 解决"AI 擅长发现但不擅长判断价值"的根本矛盾；人机各取所长 |
| 审计设计 | 全操作审计轨迹 | 每个治理操作记录"谁、什么时候、为什么、影响了什么"，支持组织学习和回溯 |

### 验收标准

1. 系统在导入数据后 1 小时内自动产生至少一个 Signal（如"新涌现的高频标签"）
2. 产品经理可以在治理工作台中将 Signal 确认为 Concept，设置名称和描述
3. 可以将多个相似的 Signal 合并为一个 Concept
4. Concept 详情页展示关联的 SemanticUnit 数量、情感趋势、来源分布
5. 优先级评估器将 Signal 按 P0-P3 排序，P0/P1 触发通知

### 团队配置

后端 x2 + AI 工程师 x1 + 前端 x1 + 产品经理 x0.5，周期约 6-8 周。

---

## 7. Phase 5：Agent 高级交互 + 编排

### 目标

将 Agent 从"执行明确任务的工具使用者"升级为"自主规划复杂工作流的策略执行者"。从 Phase 2.5 的 Thin Agent 到 Phase 5 的 Full Agent，能力发生质的飞跃。

### 核心交付物

| 交付物 | 说明 |
|--------|------|
| **多 Agent 协作框架** | Orchestrator → Specialist 模式；编排者分解任务，专家各司其职，结果聚合输出 |
| **自定义 Skill 注册** | 用户可注册企业内部 Skill（对接 CRM、知识库、工单系统等），审核后进入注册表 |
| **工作流编排引擎** | DAG 定义、条件分支、并行执行、结果汇聚；支持"生成周报"等多步骤复合任务 |
| **5 种策略模式** | 探索式分析、深度追踪、对比分析、趋势分析、问题诊断——经过验证的最佳实践复合 Skill |
| **Agent 对话界面** | Web UI 中的完整 Agent 对话体验：SSE 流式输出、工具调用可视化、中间过程展示 |

### 关键决策

| 决策 | 选择 | 理由 |
|------|------|------|
| 多 Agent 架构 | Orchestrator → Specialist | 单 Agent 上下文窗口不足以承载复杂任务；专家分工降低单 Agent 的推理难度 |
| 策略模式定位 | "建议"而非"强制" | Agent 可选择策略模板，也可自由组合原子 Skill；避免策略僵化 |
| 自定义 Skill 管控 | 声明 + 验证 + 审核 + 发布 | 平衡开放性与安全性；审核环节确保 Skill 的权限需求和成本预估合理 |

### 验收标准

1. Orchestrator Agent 可以接收"生成本周产品洞察周报"任务，自动分解为子任务并分配给 Specialist
2. 趋势分析 Specialist 和问题诊断 Specialist 可以并行工作，结果由 Orchestrator 汇总
3. 用户可以注册一个自定义 Skill（如"查询 Jira 工单状态"），Agent 在下次任务中可以发现并使用它
4. Agent 对话界面展示完整的推理过程：每一轮选了什么工具、传了什么参数、得到了什么结果
5. 5 种策略模式的复合 Skill 可以在 Agent 任务中被正确识别和调用

### 团队配置

后端 x2 + AI 工程师 x1 + 前端 x1.5（Agent UI 复杂度上升），周期约 8-10 周。

---

## 8. Phase 6：洞察引擎 + 平台化

### 目标

系统从"人驱动 AI"反转为"AI 驱动人"——Agent 不再等待指令，而是主动巡检数据、发现异常、提出建议、通知相关人员。同时开放平台 API，让外部 Agent 和第三方系统接入 Prism 的能力体系。这是 Prism 愿景的终极形态。

### 核心交付物

| 交付物 | 说明 |
|--------|------|
| **自动化洞察发现** | Agent 按调度周期自动巡检，发现异常信号后主动生成洞察报告并推送通知 |
| **概念治理协助** | Agent 自动提出 Concept 候选、建议合并相似标签、推荐治理操作——人类一键确认 |
| **开放平台 API** | 外部 Agent/系统可以通过标准协议（API Key 认证 + Skill 契约）接入 Prism 的全部 Skill |
| **主动通知系统** | 多通道通知（Slack/飞书/邮件/Webhook），按 Signal 优先级和用户订阅规则过滤推送 |
| **全栈可观测性** | Prometheus + Grafana（应用指标）+ OpenTelemetry + Jaeger（分布式追踪）+ 告警 |

### 关键决策

| 决策 | 选择 | 理由 |
|------|------|------|
| 主动巡检调度 | 三频率（小时/天/周）+ 事件触发 | 覆盖突发异常和渐进趋势两种模式；事件触发处理"数据量突增"等即时场景 |
| 平台开放策略 | Skill 级别开放，非数据级别 | 外部 Agent 只能通过 Skill 契约访问能力，不能直接查询数据库；保障数据安全 |
| 通知策略 | 优先级过滤 + 用户订阅 | P0 通知全员、P1 通知相关人、P2/P3 仅写入系统——避免"狼来了"效应 |

### 验收标准

1. Agent 在无人触发的情况下，自动发现"新涌现的高增长问题"并生成洞察摘要
2. 产品负责人通过 Slack 收到 P0 级 Signal 通知，点击链接直接跳转到治理工作台
3. 外部系统通过 API Key + Skill 契约，成功调用 Prism 的 `vector_search` Skill
4. Agent 自动建议合并两个语义相似的 Concept，人类在工作台一键确认
5. Grafana 面板展示实时的系统指标：请求量、延迟分布、LLM token 消耗、Agent 任务成功率

### 团队配置

后端 x2 + AI 工程师 x1 + 前端 x1 + DevOps x1（可观测性基础设施），周期约 8-12 周。

---

## 9. 阶段依赖关系图

```
                         Prism 路线图依赖关系
                         =====================

Phase 1 ─────────► Phase 2 ─────────► Phase 2.5
基础设施              LLM 调用            Agent 运行时
模型配置              Chat/Embed/Rerank   Skill 注册表
                     故障转移             Agent Loop
                     CLI                 双身份认证
                         │                    │
                         │                    │
                         └────────┬───────────┘
                                  │
                                  ▼
                             Phase 3 ⭐
                             VOC 数据摄入
                             语义底座
                             四阶段 AI 管线
                             8 个原子 Skill
                                  │
                                  ▼
                             Phase 4
                             语义检索
                             概念治理
                             Signal 自动产生
                             人机共治工作台
                                  │
                                  ▼
                             Phase 5
                             Agent 高级交互
                             多 Agent 协作
                             工作流编排
                             自定义 Skill
                                  │
                                  ▼
                             Phase 6
                             洞察引擎
                             开放平台
                             主动通知
                             全栈可观测

依赖解读：
────────────────────────────────────────────────
Phase 1 → 2  : 有了模型配置，才能实现模型调用
Phase 2 → 2.5: 有了 LLM 调用，Agent 才有第一个可用 Skill
Phase 2 + 2.5 → 3: LLM 网关提供 AI 能力 + Agent 骨架接收新 Skill
Phase 3 → 4  : 有了语义数据和标签，才能做概念治理
Phase 4 → 5  : 有了知识资产体系，Agent 才有高价值数据可编排
Phase 5 → 6  : 有了高级 Agent 能力，才能实现自动化洞察
```

**关键观察**：Phase 3 是唯一同时依赖 Phase 2 和 Phase 2.5 的阶段——它既需要 LLM 网关提供 AI 处理能力（调用 Chat 和 Embedding API 完成四阶段管线），又需要 Agent 运行时的 Skill 注册表来安置它的 8 个原子查询工具。这验证了 Phase 2.5 提前交付的必要性：如果 Phase 2.5 不先于 Phase 3 完成，Phase 3 的交付物就无法被 Agent 即刻使用，而需要额外的集成阶段。

---

## Key Takeaways

1. **路线图是能力叠加图，不是功能排期表。** 六个阶段不是"先做 A 功能再做 B 功能"，而是"每个阶段让系统获得一种新能力，后续阶段在此基础上叠加更高阶能力"。这种叠加是严格有序的——你不能在没有地基的土地上盖楼，也不能在没有骨架的身体上长肌肉。

2. **Phase 2.5 是整条路线图的战略支点。** "骨架先于肌肉"不是技术偏好，而是工程经济学的理性选择。提前 4-6 周交付 Agent 基础设施，换来的是后续每个阶段省去 3-4 周的集成时间和不可估量的架构改造风险。这笔账怎么算都是划算的。

3. **每个阶段的可演示成果是项目信任的硬通货。** Phase 1 演示"配置一个模型并测试连通"，Phase 2 演示"通过别名调用 LLM 并看到故障转移"，Phase 2.5 演示"Agent 通过 API Key 认证并执行一次完整推理循环"，Phase 3 演示"导入用户反馈并用 Agent 搜索分析"——每个阶段都有一个"打开浏览器/终端、当场跑给你看"的 Demo。管理层的信心不是来自 PPT，而是来自可工作的软件。

4. **Go/No-Go 评审点是管理层的安全阀。** 在任何一个阶段结束时，管理层都可以基于当前交付物做出三种决策：继续投入（Go）、调整方向（Pivot）、止损退出（No-Go）。六阶段路线图将一个 12-18 个月的大投资切分为六个 4-10 周的小投资，每次决策的风险敞口被严格限制。

5. **阶段间的依赖是单向的、清晰的。** Phase 4 依赖 Phase 3，但 Phase 3 不依赖 Phase 4。这意味着 Phase 3 的延期不会导致 Phase 2.5 的返工，Phase 5 的需求变更不会影响 Phase 4 已交付的功能。单向依赖是系统可演化性的基石，也是路线图可管理性的保障。

6. **从"人驱动 AI"到"AI 驱动人"的反转发生在 Phase 6。** Phase 1-5 的 AI 都是"被动执行"——人类给指令，Agent 执行任务。Phase 6 的 Agent 开始"主动发现"——它巡检数据、发现异常、生成洞察、通知人类。这个反转是 Prism 愿景的最终兑现，也是系统长期价值的核心来源。但它只有在前五个阶段的能力全部就位后才有可能实现——每一个阶段都是这个终局的必要前提。

7. **路线图的终极目标不是"建完六个阶段"，而是"让组织获得不断增强的感知能力"。** Prism 不是一个建完就交付的项目，而是一个越用越聪明的平台。标签体系越来越精确、知识资产越来越丰富、Agent 策略越来越成熟——组织复利效应从 Phase 3 开始积累，到 Phase 6 形成飞轮。**越早开始积累，壁垒越高。**

---

*本章从设计原则到六阶段详细展开，呈现了 Prism 从基础设施到 AI 洞察引擎的完整演进路径。下一章（Ch08 风险分析与对策）将识别这条路径上的 12 个核心风险，以及每个风险的架构级缓解策略。*
