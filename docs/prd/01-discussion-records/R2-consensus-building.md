# R2 妥协构建记录

> 基于 R1 七场辩论的投票结果和交锋记录，对 7 个议题进行三区分析（绿/黄/红），构建从冲突到共识的桥梁。

---

## 投票结果回顾

| 议题 | 主题 | 正方 | 反方 | 投票结果 | 区域判定 |
|------|------|------|------|---------|---------|
| **a** | 第一阶段的边界在哪里？ | 苏明远（推到可感知价值） | 赵一凡（严格按技术阶段） | 3:2:2 | 黄区 |
| **b** | MVP 功能范围多大？ | 苏明远+陈思琪（数据摄入+涌现标签+语义搜索） | 赵一凡+周安（只做基础设施+LLM网关） | 5:0:2 | 绿区 |
| **c** | Agent-First 从第一天就要吗？ | 陈思琪（必须从第一天搭骨架） | 王磊（Agent 可渐进，先做核心数据流） | 1:4:2 | 绿区（反方胜） |
| **d** | 涌现标签是否必须进入第一阶段？ | 陈思琪（核心差异化，必须上线） | 周安（无质量保障不上线） | 6:0:1 | 绿区 |
| **e** | 前端投入多少？ | 苏明远（需要可交互UI） | 赵一凡（API First，前端最小化） | 5:1:1 | 绿区 |
| **f** | 目标用户是谁？第一阶段给谁用？ | 林晓薇（必须先找Design Partner） | 苏明远（先内部dogfooding） | 2:4:1 | 绿区（反方胜） |
| **g** | 第一阶段是否需要包含治理/采纳机制？ | 方若琳（必须包含最小治理闭环） | 王磊（先出产品再补机制） | 5:0:1 | 绿区 |

**总结**：7 个议题中，6 个进入绿区（5+ 人支持同一立场），1 个进入黄区（3:2:2，且双方在辩论中已有实质性靠拢）。无红区议题。

---

## 三区分析

### 绿区（共识区）：5+ 人支持同一立场 → 直接采纳

---

#### 议题 b：MVP 功能范围多大？
**R1 投票**：正方 5 : 反方 0 : 弃权 2
**共识内容**：MVP 必须包含数据摄入（CSV 导入）+ 涌现标签（Stage 1-3）+ 语义搜索（`vector_search`）+ LLM 守卫层 L1/L2 + 三元反馈按钮（有用/无用/错误）+ 三档置信度颜色编码 + "AI 生成"标注。`voc` Schema 从 Day 1 独立。
**附带条件**：
- 赵一凡要求 Phase 2 必须达到"API 冻结"状态后才能正式启动 Phase 3 MVP 开发（R1 辩论 b 第 3 轮交锋）
- 周安的三个安全条件全部被接受：置信度前端展示（高/中/低三档）、LLM 输出守卫层 L1+L2、最简人工审核通道（标记正确/错误）
- Stage 4（关系构建）不进入 MVP，列为 Won't Have
- 林晓薇建议的"对比基线验证"（涌现标签 vs 预设分类对比视图）作为 Should Have——时间允许则做
- 方若琳指出的"价值闭环缺失"——用户看到标签后无法采取行动——需在治理机制（议题 g）中部分回应
- 总工时约 33 人天，在 2 名后端 + 1 名 AI 工程师的 6 周产能（约 90 人天）内可控
**进入 PRD 状态**：Must Have

---

#### 议题 c：Agent-First 从第一天就要吗？
**R1 投票**：正方 1 : 反方 4 : 弃权 2（反方——渐进式 Agent 方案——胜出）
**共识内容**：Agent 骨架采用渐进式策略，而非完整的 Phase 2.5 一步到位。核心共识是"Type 1 决策做对，Type 2 决策先简后补"。
**附带条件**：
- **Type 1（不可逆）——必须做对**：Principal 抽象（Human JWT + Agent API Key → 统一 Principal 字典 `{"type": "human/agent", "id": "xxx"}`），约 3 人天。这是陈思琪和王磊在 R1 辩论第 1-2 轮交锋中达成的关键共识。
- **Type 2（可逆）——精简交付**：SkillRegistry 接口层（Protocol）+ YAML 实现约 2 人天；精简 Agent Loop（while 循环 + Function Calling + 硬编码迭代上限 max_iterations=10 + token 计数器）约 6.5 人天。合计约 11.5 人天（对比完整方案 33 人天）。
- **还债计划**：Phase 3 交付后 2 周内必须完成——数据库版 SkillRegistry 迁移（5-8 人天）+ Agent Loop 配置化升级（3-5 人天）。陈思琪保留"还债期被跳过则 block Phase 4"的否决权。
- 赵一凡（魔鬼代言人）建议在 Phase 3 交付前建立 Agent 行为评估基准（10 个标准化分析任务，通过率 > 80%），约 3-5 人天。
**进入 PRD 状态**：Must Have（精简版），附带强制还债计划

---

#### 议题 d：涌现标签是否必须进入第一阶段？
**R1 投票**：正方 6 : 反方 0 : 弃权 1
**共识内容**：涌现标签进入第一阶段，这是 Prism 与所有竞品的核心差异化。但涌现标签不能"裸奔上线"，必须同步交付三个质量保障条件。
**附带条件**：
- 置信度前端展示（高/中/低三档颜色编码），不展示具体数值，统一标注"AI 生成，仅供参考"——这是周安和陈思琪在 R1 第 1-2 轮交锋中达成的折中（避免未校准的 confidence 数值给用户虚假信心）
- LLM 输出守卫层 L1（格式校验）+ L2（语义一致性检查）同步交付
- 最简人工审核通道：三元反馈按钮（有用/无用/错误），"错误"标记可反馈到 Stage 2 Prompt 优化——这是周安在 R1 第 4 轮提出并获陈思琪认同的设计
- 方若琳的"对比实验"方案（涌现标签 vs 预设分类对比视图）作为 Should Have
- 陈思琪提出的种子数据冷启动策略（预先准备 1000 条公开 VOC 数据跑完管线）获周安有条件接受
- 涌现标签核心实现约 5 人天 + 质量保障约 9 人天 = 约 14 人天
**进入 PRD 状态**：Must Have（附质量保障三条件）

---

#### 议题 e：前端投入多少？
**R1 投票**：正方 5 : 反方 1 : 弃权 1
**共识内容**：Phase 3 必须包含前端投入，采纳王磊的"两批交付"策略。API First 原则不动摇，前端开发必须在 API 契约稳定后启动。
**附带条件**：
- **第一批（Phase 3 内，约 10 人天，Must Have）**：数据导入页 + 语义搜索页 + 标签列表页——粗糙但能用，满足 dogfooding 和管理层演示需求
- **第二批（Phase 3 后专项冲刺，约 10 人天，Should Have）**：反馈详情页 + 置信度精细交互 + 审核列表 + 搜索增强
- 赵一凡的硬性条件：前端严格基于 OpenAPI Schema 自动生成的 TypeScript 类型开发，不得因前端需求修改 API 契约（R1 辩论 e 第 4 轮交锋）
- 苏明远最终接受从 4 个页面缩减为 3 个页面（去掉独立的标签全景浏览页，标签列表集成在搜索页侧栏）
- 周安要求前端必须优先展示 AI 输出的置信度和溯源链——"从 Trust me 到 Check me"的核心体验
**进入 PRD 状态**：Must Have（第一批），Should Have（第二批）

---

#### 议题 f：目标用户是谁？第一阶段给谁用？
**R1 投票**：正方 2 : 反方 4 : 弃权 1（反方——先 dogfooding——胜出）
**共识内容**：第一阶段先内部 dogfooding，但设定 4 周退出窗口，到期后必须开始接触外部用户。
**附带条件**：
- 苏明远在 R1 辩论中明确接受林晓薇提出的"4 周退出窗口"——dogfooding 4 周后必须安排至少一次外部用户产品演示和反馈收集（R1 辩论 f 第 5-6 轮交锋）
- 赵一凡要求 API 从 Day 1 按外部用户标准设计——统一响应格式、规范错误信息、完整认证流程——这是隐藏在 dogfooding 决策中的 Type 1 决策
- 周安提出的"合成数据验证 + 延迟真实数据接入"方案获陈思琪赞同：Phase 3 前 3-4 周使用高质量合成数据跑通 AI 管线，后半段导入脱敏后的真实数据
- 林晓薇的概念验证访谈（5 个目标用户 x 30 分钟，3 天完成）可作为并行活动，不阻塞产品开发
- 方若琳强调 dogfooding 的价值不在于验证产品，而在于"建立紧迫感"——让团队亲身体验传统 VOC 的痛苦
**进入 PRD 状态**：Must Have（dogfooding + 4 周退出窗口）

---

#### 议题 g：第一阶段是否需要包含治理/采纳机制？
**R1 投票**：正方 5 : 反方 0 : 弃权 1（王磊在辩论中被说服转投正方）
**共识内容**：第一阶段包含最小反馈机制（thumbs-up/thumbs-down 按钮），排在所有 Must Have 之后、其他 Should Have 之前。
**附带条件**：
- 方若琳原始要求的 3 个组件（确认/拒绝按钮 + 统计仪表板 + 拒绝标签过滤）在辩论中逐步让步为最小版本：一个 thumbs-up/thumbs-down 按钮 + 后端 `tag_feedback` 表 + POST API，约 2.5 人天
- 王磊的两个条件：(1) 排在 Phase 3 所有 Must Have 之后；(2) 优先级高于其他 Should Have（Stage 4 关系构建、L3 降级策略等）——方若琳接受
- 林晓薇（魔鬼代言人）建议补充被动行为追踪（标签点击、搜索查询、页面停留时间），约 1 人天，可与主动反馈并行
- 完整的 Signal → Concept 治理（五个治理操作 + 审计轨迹）推迟到 Phase 4
- 赵一凡建议在 Phase 3 数据模型中为 `EmergentTag` 预留 `status`（active/merged/deprecated）和 `confidence` 等治理相关字段——低成本"管线预埋"
**进入 PRD 状态**：Should Have（优先级最高的 Should Have）

---

### 黄区（分歧区）：4:3 或有强力反对 → 条件性妥协

---

#### 议题 a：第一阶段的边界在哪里？
**R1 投票**：正方 3 : 反方 2 : 弃权 2
**核心分歧**：苏明远主张产品第一阶段的对外目标应定义为"到达可感知价值"（覆盖技术 Phase 3），赵一凡主张严格保持 Phase 2 → 2.5 → 3 三个独立阶段各自验收、不合并为一个整体。方若琳和林晓薇两位弃权者认为双方都未回答"第一阶段要验证什么假设"这个根本问题。

**妥协过程**：

> **苏明远**（产品策略师）："赵一凡，你在 R1 辩论的第 3 轮承认了 Phase 2.5 和 Phase 3 之间存在并行空间，双方在辩论的第 4-5 轮已经就'Type 1 做对、Type 2 精简'达成了实质共识。议题 c 的投票也确认了渐进式 Agent 方案。我的条件是：对外沟通层面，产品第一阶段的目标明确为'到达可感知价值'，时间线约 14-18 周。如果你同意这一点，我接受对内保持三阶段独立验收的工程纪律。"

> **赵一凡**（首席架构师）："我可以接受对外目标表述为'到达可感知价值'，但条件是：第一，Phase 2 结束时的 Go/No-Go 评审不能取消——LLM 网关是独立可用资产，管理层必须有权在此处决策；第二，Phase 2.5 的精简方案中，Principal 抽象必须在 Phase 3 数据流入前完成，不能推迟；第三，Phase 3 的 `voc` Schema 从 Day 1 独立于 `llm`，这是架构红线。"

> **方若琳**（企业创新变革顾问）："双方的工程计划我都不反对，但我要为这个'产品第一阶段'补上一个缺失的维度——假设验证里程碑。我在 R1 魔鬼代言人发言中提过：用假设验证来定义边界，而不是用技术 Phase。我的条件是，在 Phase 3 的交付验收标准中，必须增加一条：'至少 1 名非团队成员的目标用户确认涌现标签比传统分类更有价值'。这不是要求找到 Design Partner，只是要求在 Phase 3 结束前至少做一次外部信号校准——这和议题 f 的'4 周退出窗口'呼应。如果加上这一条，我从弃权转为支持。"

> **林晓薇**（用户研究官）："方若琳的补充正是我弃权的原因——双方都在讨论'做到哪个技术阶段'，没有人回答'做到哪个阶段能验证核心假设'。我接受 dogfooding 先行的方案（议题 f 已定），但要求 Phase 3 验收标准中新增两个假设验证指标：(1) 涌现标签在测试数据集上的标注一致性 > 70%（AI 质量基线）；(2) 至少收集 100 条用户对涌现标签的反馈数据（有用/无用/错误）。有了这两个数据，我们才能科学地评估 VP1 假设是否成立。"

> **苏明远**："方若琳和林晓薇的补充我都接受。总结一下：产品第一阶段的边界是'Phase 2 → 2.5 精简版 → 3 核心子集'，对外目标是'到达可感知价值'。保留 Phase 2 的独立评审点。Phase 3 验收标准增加假设验证指标。这个方案满足了赵一凡的工程纪律、方若琳的假设验证、林晓薇的数据要求和我的价值感知诉求。"

> **赵一凡**："措辞上再精确一下：'产品第一阶段分为三个工程里程碑（Phase 2 / 2.5 精简 / 3），每个里程碑独立验收。总体目标是在 Phase 3 结束时达到用户可感知价值。Phase 2 结束后保留 Go/No-Go 评审窗口。'——这个表述既保留了独立验收的工程纪律，也明确了总体价值目标。各位能接受吗？"

**最终妥协方案**：产品第一阶段覆盖技术 Phase 2 + Phase 2.5（精简版）+ Phase 3（核心子集），总体目标为"到达用户可感知价值"。保持三个工程里程碑独立验收，Phase 2 结束后保留 Go/No-Go 评审窗口。Phase 3 验收标准增加假设验证指标（标注一致性 > 70%、至少 100 条用户反馈数据、至少 1 名外部用户信号校准）。预估总工期约 14-18 周（Phase 2 剩余 + 精简 Phase 2.5 + Phase 3）。

**进入 PRD 状态**：Must Have（含分阶段验收和假设验证指标）

---

### 红区（僵持区）

**无。** 七个议题中没有出现核心立场不可调和的僵持局面。议题 a 是唯一进入黄区的议题，但正反双方在 R1 辩论的第 4-6 轮已经有实质性靠拢，R2 妥协构建中通过方若琳和林晓薇的假设验证补充条件实现了完全共识。

---

## 共识清单（R2 输出）

| # | 功能/决策 | 来源议题 | 共识类型 | 优先级 | 关键条件 | 工时估算 |
|---|----------|---------|---------|--------|---------|---------|
| 1 | 产品第一阶段目标：到达可感知价值 | a | 黄区妥协 | — | 三个工程里程碑独立验收，Phase 2 保留 Go/No-Go | 14-18 周总工期 |
| 2 | CSV 数据导入 + 四阶段 AI 管线（Stage 1-3） | b | 绿区 | Must Have | Phase 2 API 冻结后启动 | 15 人天 |
| 3 | 涌现标签系统（Stage 2 核心 + 基础标准化） | d | 绿区 | Must Have | 附三个质量保障条件 | 5 人天 |
| 4 | 语义搜索（`vector_search` API + pgvector） | b | 绿区 | Must Have | — | 6 人天 |
| 5 | LLM 输出守卫层 L1 + L2 | b, d | 绿区 | Must Have | L1 格式校验 + L2 语义一致性检查 | 3 人天 |
| 6 | 置信度三档展示 + "AI 生成"标注 | d | 绿区 | Must Have | 不展示具体数值，仅颜色编码 | 2 人天 |
| 7 | 精简版 Agent 基础设施（Principal 抽象 + YAML SkillRegistry + 精简 Agent Loop） | c | 绿区 | Must Have | Principal 抽象为 Type 1 决策必须做对 | 11.5 人天 |
| 8 | `voc` Schema 独立 | b | 绿区 | Must Have | 架构红线，不可协商 | 含在数据模型设计中 |
| 9 | 前端第一批（数据导入页 + 搜索页 + 标签列表页） | e | 绿区 | Must Have | API 契约稳定后启动，基于 OpenAPI Schema 类型开发 | 10 人天 |
| 10 | 内部 dogfooding + 4 周退出窗口 | f | 绿区 | Must Have | 4 周后必须安排外部用户接触 | 0（运营层面） |
| 11 | 最小反馈机制（thumbs-up/down 按钮） | g | 绿区 | Should Have #1 | 排在所有 Must Have 之后、其他 Should Have 之前 | 2.5 人天 |
| 12 | 前端第二批（详情页 + 置信度精细交互 + 审核列表） | e | 绿区 | Should Have #2 | Phase 3 后专项冲刺 | 10 人天 |
| 13 | 对比基线验证（涌现标签 vs 预设分类对比视图） | b, d | 绿区 | Should Have #3 | 方若琳和林晓薇强烈建议 | 3-5 人天 |
| 14 | 行为追踪埋点（标签点击、搜索查询、停留时间） | g | 绿区 | Should Have #4 | 林晓薇建议，与反馈按钮互补 | 1 人天 |
| 15 | Agent 行为评估基准（10 个标准化测试任务） | c | 绿区 | Should Have #5 | 赵一凡建议 | 3-5 人天 |
| 16 | Agent 精简版还债（SkillRegistry 迁移 DB + Loop 配置化） | c | 绿区 | Must Have（Phase 3 后） | 陈思琪保留否决权 | 8-13 人天 |
| 17 | Stage 4 关系构建 | b | 绿区 | Won't Have | 推迟到 Phase 3 后续完善 | — |
| 18 | 完整 Signal → Concept 治理工作台 | g | 绿区 | Won't Have | 推迟到 Phase 4 | — |
| 19 | Agent 对话界面（SSE 流式） | e | 绿区 | Won't Have | Phase 5 范畴 | — |
| 20 | 数据可视化图表（趋势线、热力图） | e | 绿区 | Won't Have | 推迟 | — |

**Must Have 工时合计**：约 53 人天（#2-#9），加上前端第一批 10 人天 = 63 人天。在 3-5 人团队的 6-8 周产能（90-200 人天）内有充足缓冲。

---

## R3 PRD 起草

### 价值组起草（苏明远 + 林晓薇）

#### 产品定位

Prism Phase 1 是一个**AI 驱动的 VOC（Voice of Customer）语义分析平台**，通过涌现式标签系统帮助产品团队从海量客户反馈中发现"不知道自己不知道的"未知问题，将检测延迟从周级压缩到天级。

#### 目标用户画像

**主要用户：一线产品负责人（产品经理/产品总监）**
- **工作职责**：负责某产品线的用户体验和功能迭代，需要定期分析客户反馈制定产品决策
- **当前痛点**：每周花 5-8 小时手动阅读客户反馈或扫描预设标签报表，30% 的反馈被归入"其他"类无法分析；新问题平均 4-6 周后才被发现（检测延迟）；发现问题后还需 2-3 周与团队对齐理解（对齐延迟）
- **对 Prism 的期望**：导入反馈数据后 5 分钟内看到 AI 自动发现的问题标签，特别是那些预设分类无法覆盖的长尾问题；能用自然语言搜索"支付卡顿"就找到所有语义相关的反馈

**次要用户（Phase 1 dogfooding 阶段）：Prism 开发团队自身**
- **角色**：既是开发者，也是第一批使用者
- **价值**：通过导入团队内部的需求反馈和 bug 报告来验证 AI 管线的技术质量，同时建立对传统 VOC 痛点的感性认知

#### 核心场景（User Stories）

**US-1：首次数据导入与涌现标签体验**

- **角色**：作为一个产品经理
- **目标**：我需要将 App Store 评论导入 Prism，让系统自动发现我预设分类无法覆盖的新问题
- **前置条件**：用户已注册并登录 Prism；拥有 CSV 格式的客户反馈文件（至少 100 条）；LLM Provider 已配置并测试连通
- **主流程**：
  1. 用户在数据导入页面上传 CSV 文件
  2. 系统展示导入进度（已解析/处理中/已完成）
  3. AI 管线自动执行 Stage 1（语义拆解）→ Stage 2（标签涌现）→ Stage 3（向量化）
  4. 处理完成后，用户在标签列表页看到按频率排序的涌现标签
  5. 每个标签旁展示置信度颜色编码（绿=高/黄=中/灰=低）和"AI 生成"标注
  6. 用户点击某个标签，查看关联的原始反馈列表
- **异常流程**：
  - CSV 格式不合规 → 系统提示具体错误行号和原因，未通过的行跳过、已通过的行正常处理
  - AI 管线处理某条反馈失败 → L3 降级策略生效，原始数据保留并标记"待重处理"，不阻塞其他条目
  - LLM Provider 不可用 → 故障转移引擎切换到降级模型，标记 `degraded=true`
- **验收标准**：
  - 1000 条反馈的端到端处理时间 < 30 分钟
  - 处理完成后至少产出 20 个不同的涌现标签
  - 每个标签附带置信度标注且 UI 正确展示三档颜色
  - 低置信度标签在列表中排在高置信度之后

**US-2：语义搜索与溯源验证**

- **角色**：作为一个产品经理
- **目标**：我需要用自然语言搜索某类问题，获得语义相关（而非关键词匹配）的结果，并能溯源到原始反馈
- **前置条件**：系统中已有经 AI 管线处理的反馈数据（至少完成 Stage 1-3）
- **主流程**：
  1. 用户在搜索页输入"支付卡顿"
  2. 系统调用 `vector_search` API，返回语义相关的 SemanticUnit 列表
  3. 结果包含"结账时转了好久的菊花""付款页面卡死重启才行"等语义相关但关键词不同的内容
  4. 用户点击某条结果，跳转到原始反馈全文，查看 AI 拆解详情（意图、情感、标签）
- **异常流程**：
  - 搜索无结果 → 系统提示"未找到语义相关内容"，建议换用同义词
  - 搜索结果中包含低置信度标注 → 结果旁展示"AI 生成，仅供参考"提示
- **验收标准**：
  - 搜索"支付卡顿"返回的 Top-5 结果中至少 3 条与支付体验语义相关
  - 搜索响应时间 < 2 秒
  - 每条结果可点击溯源到原始反馈全文

**US-3：标签质量反馈**

- **角色**：作为一个产品经理
- **目标**：我需要标记涌现标签的质量，帮助系统学习并改善标签准确性
- **前置条件**：标签列表页已展示涌现标签
- **主流程**：
  1. 用户浏览涌现标签列表
  2. 对有价值的标签点击 👍（有用）
  3. 对无关的标签点击 👎（无用）
  4. 对 AI 幻觉产生的错误标签点击 ❌（错误）
  5. 反馈数据记录到 `voc.tag_feedback` 表
- **异常流程**：
  - 用户修改之前的反馈 → 系统更新反馈记录
- **验收标准**：
  - 反馈操作响应时间 < 500ms
  - 反馈数据正确关联到 tag_id 和 user_id
  - 累计反馈数据可通过 API 查询统计（为后续标签质量分析提供基础）

**US-4：管理层演示场景**

- **角色**：作为产品负责人
- **目标**：我需要在 Go/No-Go 评审会上演示 Prism 的核心能力，让管理层理解投资价值
- **前置条件**：系统中有经 AI 管线处理的演示数据集（建议 1000+ 条公开 VOC 数据）
- **主流程**：
  1. 打开浏览器进入 Prism
  2. 展示标签列表页：指出涌现标签发现了预设分类无法覆盖的新问题（如"M3 芯片发热""深色模式对比度不足"）
  3. 展示语义搜索：输入"用户体验差"，返回语义相关而非关键词匹配的结果
  4. 展示置信度标注：指出系统对 AI 输出的透明度设计
  5. 展示反馈按钮：说明系统具备人机协同的质量改进机制
- **异常流程**：无特殊异常
- **验收标准**：
  - 完整演示流程可在 5 分钟内完成
  - 演示数据集中至少包含 3 个"令人惊喜"的涌现标签（传统预设分类无法发现的）
  - UI 在非技术受众面前可理解、可操作

**US-5：合成数据冷启动**

- **角色**：作为 AI 工程师
- **目标**：我需要用高质量合成数据初始化标签标准化表，避免真实用户看到冷启动阶段散乱的标签
- **前置条件**：LLM Provider 已配置；合成数据生成 Prompt 已就绪
- **主流程**：
  1. 使用 LLM 生成 1000-3000 条模拟 VOC 反馈（覆盖多种表达风格和主题）
  2. 将合成数据通过 CSV 导入管线
  3. AI 管线处理后积累初始标签标准化表和同义词映射
  4. 验证标签标准化效果（"加载慢""响应慢""卡顿"是否被合理聚合）
  5. 真实用户数据进入时，系统基于已积累的标签知识进行更高质量的标注
- **异常流程**：
  - 合成数据领域与真实业务不匹配 → 标签标准化表中特定领域条目被真实数据覆盖，不影响系统运行
- **验收标准**：
  - 合成数据处理完成后，系统中存在至少 50 个已标准化的标签
  - 同义标签合并率 > 30%（如"加载慢"和"响应慢"被合并或关联）

#### 成功标准（可量化 KPI）

| KPI | 目标值 | 衡量方式 | 时间节点 |
|-----|--------|---------|---------|
| AI 管线端到端处理可靠性 | > 95%（1000 条中失败 < 50 条） | 自动化测试 + 守卫层降级统计 | Phase 3 验收 |
| 涌现标签标注一致性 | > 70%（同一反馈重复处理产出的标签重叠率） | 自动化一致性测试 | Phase 3 验收 |
| 语义搜索 Top-5 命中率 | > 60% | 预定义 10 个测试查询的人工评审 | Phase 3 验收 |
| 用户反馈数据量（dogfooding） | > 100 条 thumbs-up/down/error | `tag_feedback` 表统计 | Phase 3 结束后 4 周 |
| 外部用户信号校准 | 至少 1 名非团队成员确认涌现标签有价值 | 产品演示 + 反馈收集 | Phase 3 结束后 4 周 |

---

### 技术组起草（赵一凡 + 王磊）

#### 架构约束

**依赖方向（不可逆）**：
```
apps/web → (HTTP) → llm-service, voc-service → (import) → shared → PostgreSQL, Redis
```

**Schema 隔离（不可协商）**：
- `auth`——用户认证数据（Phase 1 已就位）
- `llm`——LLM Provider/Model/Alias 配置（Phase 1 已就位）
- `agent`——Agent 身份、Skill 注册、执行日志（Phase 2.5 精简版引入）
- `voc`——Voice、SemanticUnit、EmergentTag、TagFeedback（Phase 3 引入）

**API 契约约束**：
- 统一响应格式：`{ "data": ..., "meta": { "request_id", "timestamp" } }`
- 统一错误格式：`{ "error": { "code", "message" } }`
- 所有 API 先于 UI 交付，前端严格消费 OpenAPI Schema 生成的 TypeScript 类型
- API 契约一旦冻结不允许 breaking change（新增字段可以，删除/重命名不行）

#### 数据模型

**核心实体（`voc` Schema）**：

```
Voice（原始反馈）
├── id: UUID (PK)
├── source: String (CSV / API / ...)
├── raw_text: Text
├── created_at: Timestamp
├── processed_status: Enum (pending / processing / completed / failed)
└── metadata: JSONB

SemanticUnit（语义单元，1 条 Voice → 1-N 个 Unit）
├── id: UUID (PK)
├── voice_id: UUID (FK → Voice)
├── text: Text (拆解后的语义片段)
├── summary: String
├── intent: String (意图)
├── sentiment: Enum (positive / negative / neutral / mixed)
├── confidence: Float
├── embedding: vector(1024) (pgvector, BGE-large-zh-v1.5)
└── created_at: Timestamp

EmergentTag（涌现标签）
├── id: UUID (PK)
├── name: String (标准化后的标签名)
├── raw_name: String (LLM 原始输出)
├── usage_count: Integer
├── status: Enum (active / merged / deprecated) [预留治理字段]
├── confidence: Float [预留治理字段]
└── created_at: Timestamp

UnitTagAssociation（Unit-Tag 关联）
├── unit_id: UUID (FK → SemanticUnit)
├── tag_id: UUID (FK → EmergentTag)
├── relevance: Float (相关度评分)
└── is_primary: Boolean

TagFeedback（标签反馈）
├── id: UUID (PK)
├── tag_id: UUID (FK → EmergentTag)
├── user_id: UUID (FK → auth.User)
├── feedback_type: Enum (useful / useless / error)
├── created_at: Timestamp
└── updated_at: Timestamp
```

**Agent 相关实体（`agent` Schema）**：

```
Principal（统一身份，精简版）
→ 通过中间件注入 request context: {"type": "human" | "agent", "id": "xxx"}

SkillRegistry（精简版，Phase 2.5 用 YAML 配置，Phase 3 后迁移 DB）
├── name: String
├── description: String
├── input_schema: JSON Schema
├── output_schema: JSON Schema
├── required_capabilities: List[String]
└── cost_metadata: JSON

AgentExecutionLog（审计日志）
├── id: UUID (PK)
├── principal_id: String
├── principal_type: Enum (human / agent)
├── skill_name: String
├── input_params: JSONB
├── output_result: JSONB
├── token_usage: Integer
├── duration_ms: Integer
├── status: Enum (success / failed / terminated)
└── created_at: Timestamp
```

#### API 契约

**核心 API 端点（Phase 3 新增）**：

| 端点 | 方法 | 说明 | 优先级 |
|------|------|------|--------|
| `/api/voc/import` | POST | CSV 批量导入 Voice | Must Have |
| `/api/voc/import/{id}/status` | GET | 查询导入任务状态 | Must Have |
| `/api/voc/search` | POST | 语义搜索（vector_search） | Must Have |
| `/api/voc/tags` | GET | 获取涌现标签列表（含使用次数排序） | Must Have |
| `/api/voc/tags/{id}/units` | GET | 获取标签关联的 SemanticUnit 列表 | Must Have |
| `/api/voc/units/{id}` | GET | 获取 SemanticUnit 详情（含原始 Voice） | Must Have |
| `/api/voc/tags/{id}/feedback` | POST | 提交标签反馈（useful/useless/error） | Should Have #1 |
| `/api/voc/voices/{id}` | GET | 获取原始 Voice 全文 | Must Have |

**Agent 相关端点（Phase 2.5 精简版）**：

| 端点 | 方法 | 说明 | 优先级 |
|------|------|------|--------|
| `/api/agent/skills` | GET | 获取可用 Skill 列表 | Must Have |
| `/api/agent/execute` | POST | 执行 Agent 任务（ReAct 循环） | Must Have |
| `/api/agent/executions/{id}` | GET | 查询 Agent 执行日志 | Must Have |

#### 排期与里程碑

以下排期基于当前团队规模（~2.5 人，Phase 3 扩展至 5 人），从 Phase 2 完成时间点开始计算。

| 里程碑 | 时间 | 交付物 | 团队 | Go/No-Go 条件 |
|--------|------|--------|------|--------------|
| **M1: Phase 2 完成** | W0（基线） | LLM 网关（Chat/Embed API + 故障转移 + CLI） | 后端x2 + 前端x0.5 | Chat API 可用 + 降级演示通过 |
| **M2: Phase 2.5 精简版完成** | W0 + 3 周 | Principal 抽象 + YAML SkillRegistry + 精简 Agent Loop | 后端x2 | Agent 完成一次 ReAct 循环 + 审计日志生成 |
| **M3: Phase 3 数据底座** | W0 + 7 周 | CSV 导入 + Stage 1 语义拆解 + Stage 2 标签涌现 + 基础标准化 | 后端x2 + AI x1 | 导入 1000 条数据，产出涌现标签 |
| **M4: Phase 3 语义搜索** | W0 + 9 周 | Stage 3 向量化 + vector_search API + 守卫层 L1/L2 | 后端x2 + AI x1 | 搜索"支付卡顿"返回语义相关结果 |
| **M5: Phase 3 前端 + 集成** | W0 + 11 周 | 数据导入页 + 搜索页 + 标签列表页 + 联调测试 | 前端x1 + 全员联调 | 完整端到端流程可演示 |
| **M6: Dogfooding 启动** | W0 + 12 周 | 内部团队开始使用 Prism 分析真实数据 | 全员 | — |
| **M7: 假设验证检查点** | W0 + 16 周 | 收集 100+ 条标签反馈 + 至少 1 次外部用户演示 | PM x0.5 | 标注一致性 > 70%，外部信号积极 |
| **M8: Agent 还债** | W0 + 13-14 周 | SkillRegistry 迁移 DB + Agent Loop 配置化 | 后端x1 | SkillRegistry 支持 CRUD API |

**工时汇总**：

| 工作包 | 人天 | 负责人 |
|--------|------|--------|
| Phase 2.5 精简版（Principal + YAML Registry + 精简 Loop） | 11.5 | 后端x2 |
| CSV 导入 + Stage 1 语义拆解 | 7 | 后端x1 + AI x1 |
| Stage 2 标签涌现 + 标准化 | 5 | AI x1 |
| Stage 3 向量化 + pgvector | 3 | 后端x1 |
| vector_search API | 3 | 后端x1 |
| LLM 守卫层 L1 + L2 | 3 | AI x1 |
| 置信度展示 + "AI 生成"标注 | 2 | 前端x1 |
| 前端第一批（3 页面） | 10 | 前端x1 |
| 合成数据冷启动 | 3 | AI x1 |
| 联调测试 + Bug 修复 | 10 | 全员 |
| **Must Have 小计** | **57.5** | — |
| 反馈按钮（Should Have #1） | 2.5 | 前端x0.5 + 后端x0.5 |
| Agent 评估基准 | 3-5 | AI x1 |
| Agent 还债（Phase 3 后） | 8-13 | 后端x1 |
| 前端第二批（Phase 3 后冲刺） | 10 | 前端x1 |

---

### 约束组起草（陈思琪 + 周安）

#### AI 管线设计约束

**Phase 1 必须实现的范围（四阶段管线中的前三阶段）**：

| 阶段 | 输入 | 输出 | LLM 依赖 | 关键约束 |
|------|------|------|---------|---------|
| Stage 1: 语义拆解 | Voice 原始文本 | 1-N 个 SemanticUnit（text, summary, intent, sentiment, confidence） | Chat API | Prompt 必须输出结构化 JSON；confidence 字段必须包含 |
| Stage 2: 标签涌现 | SemanticUnit | 3-7 个涌现标签（name, relevance, is_primary） | Chat API | 标签必须经过 `normalize_tag_name` 标准化；`get_or_create_tag` 幂等创建 |
| Stage 3: 向量化 | SemanticUnit text | 1024 维 embedding 向量 | Embedding API（BGE-large-zh-v1.5） | 存入 pgvector；HNSW 索引参数需基准测试调优 |
| ~~Stage 4: 关系构建~~ | ~~SemanticUnit pairs~~ | ~~显式关系网络~~ | ~~Chat API~~ | ~~Won't Have，推迟~~ |

**标签标准化流水线（Phase 1 范围）**：
1. 文本清洗（`normalize_tag_name`）：小写化、去除首尾空格、统一标点
2. 幂等创建（`get_or_create_tag`）：防止同名标签重复
3. **不在 Phase 1 范围**：向量相似度自动合并（依赖标签 embedding 积累）、同义词映射 UI

#### 安全要求

**置信度展示底线（周安的不可谈判条件）**：
- 所有涌现标签在 UI 上统一标注"AI 生成，仅供参考"
- 置信度三档展示（绿=高相关/黄=中相关/灰=低相关），基于 Stage 2 的 `relevance` 分数阈值映射
- 不展示具体 confidence 数值（避免未校准分数给用户虚假信心）

**LLM 输出守卫层**：
- **L1（格式校验）**：验证 LLM 输出是否为有效 JSON、是否包含必需字段、字段类型是否正确。失败 → 重试 1 次 → 仍失败则进入 L2。
- **L2（语义一致性检查）**：验证生成的标签与原文是否语义相关（可通过简化的交叉验证实现）。低于阈值的标签标记为低置信度。
- **L3 降级策略**（Won't Have 的精简替代）：处理失败的 Voice 保留原始数据，标记 `processed_status = failed`，不阻塞其他条目。

**审计日志（Day 1 硬性要求）**：
- Agent 每次执行生成完整审计日志：principal_id, skill_name, input, output, token_usage, status
- 所有数据导入操作记录：谁、什么时间、导入了多少条、处理结果

**数据安全（dogfooding 阶段）**：
- 内部 dogfooding 数据如包含外部用户 PII，须脱敏后导入
- 合成数据阶段不涉及真实用户数据，安全风险最低
- API 按外部用户标准设计（完整认证、规范错误响应），为后续对外开放预留安全基线

#### 非功能需求

| 维度 | 要求 | 验证方式 |
|------|------|---------|
| **性能** | 单条 Voice 端到端处理 < 10 秒；千条批量 < 30 分钟；语义搜索 P95 < 2 秒 | 基准测试 |
| **可靠性** | AI 管线处理成功率 > 95%；守卫层确保失败数据不丢失 | 自动化测试 + 监控 |
| **可扩展性** | pgvector 在 10 万向量内 P95 延迟 < 100ms | Phase 3 基准测试（技术验证节点） |
| **安全性** | 所有 API 需认证（JWT/API Key）；审计日志不可篡改 | 安全审查 |
| **可观测性** | Phase 3 基础日志（结构化日志 + 错误追踪）；完整可观测性（Prometheus + Grafana）推迟到 Phase 6 | 日志审查 |

#### 风险清单

| # | 风险 | 概率 | 影响 | 缓解措施 | 责任人 |
|---|------|------|------|---------|--------|
| 1 | **涌现标签在小数据量下效果不显著** | 高 | 高——动摇 VP1 核心假设 | 合成数据冷启动（1000-3000 条种子数据）；设定标注一致性 > 70% 的验证基线；方若琳的对比实验方案作为 Should Have | 陈思琪 |
| 2 | **LLM 幻觉产生错误标签被当作事实** | 中 | 高——信任崩塌 | 置信度三档展示 + "AI 生成"标注 + 三元反馈按钮（有用/无用/错误）+ L1/L2 守卫层 | 周安 |
| 3 | **Phase 3 工期超出预期** | 中 | 中——延迟到达价值拐点 | Stage 4 已列为 Won't Have；前端分两批交付；Must Have 工时 57.5 人天在 90+ 人天产能内有缓冲 | 王磊 |
| 4 | **精简版 Agent 还债被跳过** | 中 | 高——Phase 4 无法启动 | 陈思琪保留否决权；还债期排入 M8 里程碑强制执行 | 陈思琪 |
| 5 | **Dogfooding 反馈不具代表性** | 高 | 中——产品方向偏差 | 4 周退出窗口强制接触外部用户；林晓薇的概念验证访谈可并行；行为追踪埋点补充主观反馈的不足 | 林晓薇 |

---

### 方若琳交叉审查

#### 对价值组的审查意见

**问题 1：价值闭环在"标签展示"处断裂。**

苏明远和林晓薇定义的 5 个 User Stories 覆盖了"数据进去 → AI 处理 → 洞察产出"，但在"用户行动 → 行动结果反馈回系统"环节存在明显缺口。US-3 的反馈按钮只解决了"用户对标签质量的评价"，但没有回答一个更关键的问题：**用户看到涌现标签后做什么？** "M3 芯片发热问题"这个标签很好——然后呢？用户需要在 Prism 内部创建一个追踪任务吗？需要导出为报告发给工程团队吗？需要分享给同事？

**改进建议**：在 Should Have 中增加一个极简的"标签导出"功能——用户可以将某个标签及其关联的反馈原文导出为 CSV 或 Markdown，拿到 Jira/飞书等外部工具中使用。这不需要复杂的集成，只需要一个"导出"按钮。工时估算 1-2 人天，但它补上了"洞察 → 行动"的最小闭环。如果连这都没有，涌现标签就只是"看看而已"，无法转化为组织行动。

**问题 2：US-4（管理层演示）缺少"So What"回答。**

当前的演示流程是"看标签 → 做搜索 → 看置信度 → 看反馈按钮"。管理层会问一个 So What 问题："这比 Excel 关键词筛选强在哪里？"单纯的演示无法回答这个问题——需要一个明确的对比锚点。建议在演示数据集中预埋一组"传统关键词匹配结果 vs 涌现标签结果"的对比案例，让管理层亲眼看到差异。这呼应了议题 b 中林晓薇提出的"对比基线验证"方案。

#### 对技术组的审查意见

**问题 1：架构是否预留了治理机制接口？**

赵一凡在 `EmergentTag` 上预留了 `status`（active/merged/deprecated）和 `confidence` 字段，这是好的"管线预埋"。但我注意到数据模型中缺少一个关键字段：**`parent_tag_id`**（用于 Phase 4 的标签合并操作——合并后的标签需要指向父标签）。如果 Phase 4 开始时发现需要这个字段，就要做数据迁移。建议在 Phase 3 的 `EmergentTag` 表中预留 `parent_tag_id: UUID (nullable, FK → self)`。新增一个 nullable 字段的成本接近于零，但省去了未来的 ALTER TABLE。

**问题 2：排期中 M6（Dogfooding 启动）和 M7（假设验证检查点）之间的 4 周没有明确的产品运营活动。**

Dogfooding 不是"把系统开着让人随便用"——需要有计划的引导。建议在 M6 和 M7 之间安排：第 1 周全员导入数据并使用；第 2 周收集内部反馈讨论 AI 管线质量；第 3 周安排外部用户演示；第 4 周汇总反馈数据准备 M7 评审。否则 4 周可能悄无声息地过去，到 M7 才发现反馈数据量不够。

#### 对约束组的审查意见

**问题 1：AI 管线的输出如何进入组织决策流程？**

陈思琪和周安的约束设计聚焦于"AI 管线的技术质量保障"——守卫层、置信度、审计日志都是正确的。但缺少一个组织维度的设计：**涌现标签产出后，谁负责"看"？看了之后"做什么"？做了之后"系统知道吗"？**

Phase 1 的 dogfooding 阶段，"谁看"的答案是"团队全员"，但这是临时方案。建议在 Phase 3 的文档中明确定义一个"标签审阅者"角色——即使只有一个人，也需要明确"这个人每天/每周花 15 分钟看一遍新涌现的标签，做 thumbs-up/down 反馈"。没有这个组织承诺，反馈按钮就是摆设。

**问题 2：风险 #1（小数据量下涌现标签效果不显著）的缓解措施不够激进。**

"合成数据冷启动"解决的是标签标准化表的初始化，不解决"涌现标签对用户的价值感知"问题。建议增加一个更直接的缓解措施：**Phase 3 验收时，用真实 VOC 数据（至少 500 条，可从公开 App Store 评论获取）运行 AI 管线，然后让 3 名非团队成员评审涌现标签的质量。** 如果 3 人中有 2 人认为涌现标签"比随机标签有意义"，则 VP1 假设初步成立。如果 2 人以上认为"看不出和关键词提取有什么区别"，则需要在进入 Phase 4 之前调整标签策略（可能需要优化 Prompt 或引入 few-shot examples）。这个验证的成本极低（1 天准备 + 半天评审），但能在 Phase 3 结束时给团队一个明确的信号。

---

*本文档为 R2 妥协构建记录，下一步将进入 R4 终审投票阶段，对以上共识清单进行五维评分和最终定稿。*
