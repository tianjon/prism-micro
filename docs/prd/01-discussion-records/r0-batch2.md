# R0 独立立场宣言 — 第二批（赵一凡、林晓薇）

> 本文档记录赵一凡（首席架构师）和林晓薇（用户研究官）对 7 大议题的独立立场。两位专家在互不知晓对方观点的前提下独立撰写，允许同一议题出现分歧。

---

## 赵一凡 · 首席架构师 —— "不可妥协的地基工匠"

---

### 赵一凡 · a 第一阶段的边界在哪里？

**立场**：反对（反对将产品第一阶段边界推到技术 Phase 3）
**一句话观点**：产品第一阶段应严格对齐技术 Phase 1-2.5，Phase 3 作为独立里程碑验收。
**关键论据**：
1. 路线图的六阶段设计不是功能排期表，而是**能力叠加图**——每阶段的依赖关系是严格单向的（Phase 1 → 2 → 2.5 → 3）。试图将产品第一阶段推到 Phase 3，等于在盖楼时同时打地基、搭钢结构和装修，看起来省了时间，实际上每一层的质量验证都被跳过了。这就像在飞行中同时更换发动机和起落架——任何一个出问题你连紧急着陆的机会都没有。路线图设计原则第 1.1 条明确要求"每阶段独立可交付、可演示"，这不是官僚主义，而是"长期不可见性导致信任流失"的工程对策。
2. Phase 2.5（Agent 基础运行时）的战略定位决定了它不能被压缩或跳过。路线图第 4 节明确论证了"骨架先于肌肉"的必要性——Skill 注册表、Agent Loop、双身份认证是 Type 1 决策（不可逆），如果在 Phase 3 才补这些骨架，后期改造成本是初始设计的 5-10 倍。我画一张依赖图就能说清楚：Phase 3 的 8 个原子查询工具需要注册进 Phase 2.5 的 Skill 注册表，如果注册表没有在 Phase 3 之前就位并验证，那 Phase 3 交付物要么是"裸 API"要么需要额外 3-4 周集成阶段。
3. Go/No-Go 评审点是管理层的安全阀（资源与 ROI 文档 5.1 节）。如果将 Phase 1-3 合并为一个"产品第一阶段"，管理层在 112 万投入完成之前没有任何有意义的评审窗口。而按技术路线图走，Phase 2 结束时（累计约 29 万）已经交付了可独立使用的 LLM 网关，Phase 2.5 结束时（累计约 51 万）已经交付了 Agent 基础设施——每一步都有"已获得的可用资产"。这是将 200 万的一次性赌注切分为多个 30 万以内的分期决策。
**最大风险**：如果严格按技术路线图走，Phase 1-2.5 对终端用户来说都是"零可感知价值"的纯基础设施阶段。在此期间团队可能面临来自管理层或利益相关者的信心压力——"花了 50 万但用户还什么都看不到"。如果管理层耐心不足，项目可能在到达 Phase 3 价值拐点之前被叫停。

---

### 赵一凡 · b MVP 功能范围多大？

**立场**：有条件支持（支持 MVP 包含数据摄入和语义搜索，但必须以 Phase 2.5 架构就绪为前提）
**一句话观点**：MVP 是 Phase 3 的验收标准，但骨架（Phase 2.5）不能为了赶 MVP 而偷工减料。
**关键论据**：
1. 从架构依赖关系看，MVP 的最小有意义边界确实是 Phase 3 的核心交付物——四阶段 AI 管线、8 个原子查询工具、向量检索引擎。路线图依赖关系图（第 9 节）清晰表明 Phase 3 是"Prism 从通用 LLM 网关蜕变为 VOC 分析平台的关键阶段"。但这个 MVP 不能绕过 Phase 2.5，否则就像在没有钢结构的地基上直接浇筑楼板——看起来"有东西了"，但承重能力为零。我的类比是：你可以毛坯交付，但水电管线必须预埋好。
2. MVP 范围内必须包含双身份认证的 Principal 统一设计（Phase 2.5 核心交付物）。这是一个 Type 1 决策——人类 JWT 和 Agent API Key 如何统一为 Principal 身份对象，下游服务只认 Principal。如果在 MVP 阶段跳过这个设计，直接让用户通过 JWT 调用 VOC API，后续引入 Agent 时就需要重写整个认证链路。我在一个过去的项目中花了 6 个月重写认证体系，那段经历让我对"先做后改"的成本有刻骨铭心的认知。
3. Schema 隔离（auth / llm / agent / voc 四个独立 Schema）是不可协商的架构约束。MVP 功能范围无论多大多小，数据模型必须从 Day 1 就按正确的 Schema 边界组织。Phase 1 交付定义中已经确立了 auth/llm 的 Schema 隔离，Phase 2.5 引入 agent Schema，Phase 3 引入 voc Schema。如果为了加速 MVP 而将 voc 数据混入 llm Schema，未来的迁移成本不是"花两天改一下"，而是"停服迁移数据 + 修改所有查询 + 回归测试全部接口"。
**最大风险**：如果我坚持 Phase 2.5 全部完成后才开始 Phase 3 的 MVP 开发，总计需要 12-20 周（Phase 2 剩余 + Phase 2.5 + Phase 3）。在 4.5 人团队规模下这几乎是半年时间，MVP 可能因为"太慢"而失去内部支持和外部市场窗口。

---

### 赵一凡 · c Agent-First 从第一天就要吗？

**立场**：支持
**一句话观点**：Agent 骨架是钢结构，必须在装修之前就位——这是 Phase 2.5 存在的全部理由。
**关键论据**：
1. 路线图第 4 节用了整整一节论证"为什么 Agent 运行时必须在 VOC 数据层之前"，给出了三个理由：骨架先于肌肉、提前验证架构假设、团队并行开发。这不是技术偏好，而是工程经济学的理性选择。我的依赖图可以精确说明：如果 Phase 3 的 8 个原子查询工具在交付时没有 Skill 注册表可以注册，它们就只是"裸 API"，后续要将裸 API 包装成 Skill 塞进 Agent 框架，是典型的"后期改造"，成本是初始设计的 5-10 倍。提前 4-6 周交付 Agent 基础设施，换来的是后续每个阶段省去 3-4 周的集成时间。
2. 双身份认证（Human JWT + Agent API Key → 统一 Principal）是 Type 1 决策。路线图关键决策表明确标注"这是 Type 1（不可逆）决策，必须在 Day 1 做对"。Type 1 决策的定义是：一旦做出就很难回退，回退成本极高。如果我们先不做 Agent 认证，等 Phase 3 之后再补，所有已建成的 API 端点都需要被改造以识别 Agent Principal——这就像在飞行中更换发动机，而且是在乘客已经上了飞机之后。
3. Phase 2.5 的 Agent 运行时让 Skill 契约成为 Phase 2.5 和 Phase 3 之间的清晰接口边界，使得 Agent 团队和数据团队可以并行开发。在 4.5 人的团队中，并行开发能力是生死攸关的——如果所有人都在同一条串行链路上排队，14-20 周的 Phase 2.5-3 工期可能膨胀到 24-30 周。
**最大风险**：Phase 2.5 的 Agent 运行时在完成时只能调用 LLM 做简单对话——对用户来说"Agent 能做的事太少了"。如果 Phase 3 因为任何原因延期或被砍，那 Phase 2.5 的投入（约 22 万）就变成了一个"为未来准备但当下无用"的沉没成本。这会给"过度工程"的批评者提供实弹。

---

### 赵一凡 · d 涌现标签是否必须进入第一阶段？

**立场**：有条件支持（支持涌现标签进入 Phase 3，但必须附带 LLM 输出守卫层和标准化流水线）
**一句话观点**：涌现标签是 Phase 3 的核心交付物，但必须带着三级降级和标准化一起上线。
**关键论据**：
1. 从架构视角看，涌现标签是四阶段 AI 管线中 Stage 2（标签涌现）的产出物，而四阶段管线是 Phase 3 的核心交付物。路线图验收标准明确要求"每条反馈被拆解为 1-N 个 SemanticUnit，每个 Unit 携带意图、情感、涌现标签、embedding"。如果把涌现标签从 Phase 3 中抽掉，Stage 2 就变成空壳，整条管线断裂——这就像从心脏搭桥手术中移除搭桥环节，剩下的切开和缝合毫无意义。
2. 但涌现标签绝不能"裸奔上线"。核心能力文档第 2.3 节描述的双轨设计（涌现标签 + 预设维度）和三道标准化工序（文本清洗 → 同义词映射 → 向量相似度合并）是涌现标签可用性的前提。如果只做 Stage 2 的 LLM 调用而不做标准化，"加载慢""卡顿""响应慢""转圈""菊花转"就会变成五个不同标签——这不是涌现，是混乱。依赖方向是：涌现标签依赖标准化流水线，标准化流水线依赖 Stage 3 的向量化（因为需要向量相似度合并），所以 Stage 2 和 Stage 3 必须一起交付。
3. LLM 输出守卫层（三级降级：L1 正常 → L2 修正 → L3 降级）是涌现标签的安全网。核心能力文档第 2.4 节明确指出"在生产环境中，LLM 输出的可靠性直接决定了数据质量的下限"。涌现标签的质量取决于 LLM 的表现，而 LLM 是概率性系统。没有守卫层，一次 LLM 抽风（格式错误、幻觉标签）就可能污染知识库。L3 降级策略的哲学是"宁可粗糙也不丢失"——这是架构层面的数据安全保障。
**最大风险**：将涌现标签 + 标准化 + 守卫层作为捆绑包交付，会显著增加 Phase 3 的工作量和复杂度。核心能力文档估算四阶段管线的 Phase 3 工期为 6-8 周（含 20% 缓冲），如果标准化和守卫层的实现比预期复杂，可能导致 Phase 3 延期 2-4 周，推迟整个项目到达可感知价值的时间。

---

### 赵一凡 · e 前端投入多少？

**立场**：有条件支持（支持最小化前端投入，API First 原则不可动摇）
**一句话观点**：所有能力先以 API 暴露，UI 是 API 的消费者之一——前端可以薄，但 API 必须厚。
**关键论据**：
1. 路线图设计原则第 1.3 条"API 先于 UI"是架构宪法级的约束。原文明确指出："API 是系统能力的契约化表达。一个没有 API 的功能，只有前端能调用；一个有 API 的功能，前端、CLI、Agent、外部系统都能调用。在 Agent-First 的架构下，API 是所有消费者的公共入口，UI 只是其中一个消费者。"如果前端投入过大，团队注意力会从 API 设计转向 UI 打磨——这就像为还没有水管的房子精心挑选水龙头的样式。
2. 从依赖关系看，前端依赖后端 API，而不是反过来。Phase 1 已经交付了基础 Web UI（登录页 + 模型管理页面），Phase 2 的 CLI 基础版也在开发中。Phase 3 需要的前端能力是数据浏览 UI（路线图 Phase 3 团队配置明确列出"前端 x1（数据浏览 UI）"），但这个 UI 的前提是 8 个原子查询工具的 API 已经就位。我的建议是：先交付 API + 自动化测试，如果时间允许再做 UI 精细打磨。
3. 类型安全 API 客户端层（核心能力文档第 6.3 节）的存在让前端开发效率更高：Pydantic v2 模型 → OpenAPI Schema → TypeScript 类型定义和 API 客户端代码，整条链路自动化。这意味着一旦 API 设计完成，前端的开发成本被结构性地降低了。把精力花在 API 设计的正确性上，比花在 UI 的美观度上，对系统的长期价值贡献更大。
**最大风险**：前端投入过少可能导致 MVP 阶段的产品"不可感知"。没有可交互的 UI，管理层和潜在的 Design Partner 都无法体验产品价值。API 再漂亮，如果只能通过 curl 或 Postman 演示，说服力会大打折扣。可能会出现"工程师觉得完美，但非技术受众完全看不懂"的尴尬局面。

---

### 赵一凡 · f 目标用户是谁？第一阶段给谁用？

**立场**：有条件支持（支持先内部 dogfooding，但必须从 Day 1 预留外部接入的 API 契约）
**一句话观点**：第一用户是团队自己，但 API 契约必须从一开始就按外部用户标准设计。
**关键论据**：
1. 这是一个 Type 2 决策（可逆的）——先 dogfooding 还是先找 Design Partner，这个决定可以随时调整，不影响架构。但有一个 Type 1 决策藏在里面：API 契约的设计标准。如果 API 是按"内部特供"的标准设计的——错误信息不规范、认证流程简化、响应格式随意——后续对外开放时就需要重写契约。Phase 1 交付定义中已确立的统一响应格式 `{ "data": ..., "meta": { "request_id", "timestamp" } }` 就是一个正确的 Type 1 决策示范。
2. 从资源约束看（09-resource-roi.md），Phase 2.5-3 阶段团队是 3-5 人规模。在这个规模下同时做产品开发和外部用户运营是不现实的——外部 Design Partner 意味着需求沟通、Bug 响应、部署支持，这些"非代码"工作会挤压工程带宽。内部 dogfooding 的优势是：反馈循环极短（走两步路就能找到"用户"）、容忍度高（内部人员理解产品处于 Alpha 阶段）、零运营成本。
3. 但"先内部"不等于"只内部"。技术架构必须从 Day 1 就按多租户、标准 API、完整认证的标准设计——这些都是 Type 1 决策。路线图中的双身份认证（Human JWT + Agent API Key → 统一 Principal）和 Schema 隔离策略（auth / llm / agent / voc）确保了系统从一开始就具备接纳外部用户的架构基础，而不需要在"从内部到外部"转换时做架构改造。
**最大风险**：内部 dogfooding 的最大风险是"自己觉得好用但外部用户完全不认可"。团队成员对系统的理解深度、容错意愿、使用习惯都与真实目标用户（一线产品负责人）有本质差异。如果在内部 dogfooding 阶段投入过多时间优化"内部体验"，可能在面对真实用户时发现方向性偏差。

---

### 赵一凡 · g 第一阶段是否需要包含治理/采纳机制？

**立场**：有条件支持（支持预留治理接口，但治理 UI 和完整流程推迟到 Phase 4）
**一句话观点**：治理机制的 API 接口在 Phase 3 预埋，完整治理工作台在 Phase 4 交付。
**关键论据**：
1. 路线图的阶段划分已经给出了明确答案：Signal → Concept 治理机制是 Phase 4 的核心交付物（"语义检索 + 概念治理"），包括五个治理操作（确认、命名、合并、静音、追踪）和人机共治工作台。将完整治理功能提前到 Phase 3，等于在还没有足够数据支撑 Signal 自动产生的情况下就建治理工具——这就像在还没有矿石的时候就建冶炼厂，空转设备的维护成本是纯浪费。
2. 但"预埋接口"是一个值得做的低成本高回报动作。在 Phase 3 的数据模型中为 EmergentTag 预留 `status`（active / merged / deprecated）、`confidence` 等治理相关字段，在 API 设计中预留 `PATCH /tags/{id}` 端点的接口定义（即使暂不实现完整逻辑）——这些都是不超过 1-2 天工作量的"管线预埋"。类比：你不需要在毛坯阶段装好水龙头，但必须把水管口留好，否则将来装水龙头时要砸墙。
3. 核心能力文档 4.2 节描述的 Concept 人机共治流程依赖五个并行分析器（趋势/异常/聚类/情感/涌现检测器）的 Signal 自动产生。这些分析器需要足够的数据量才能产生有意义的 Signal——在 Phase 3 初期数据量很小的情况下，治理机制缺少被治理的对象。这是一个严格的数据依赖关系：有数据 → 有 Signal → 才有治理的必要。
**最大风险**：如果治理机制完全推迟到 Phase 4，Phase 3 期间涌现出的标签会处于"无人治理"状态。标签数量会快速膨胀，同义标签会大量堆积（核心能力文档提到"加载慢""卡顿""响应慢"可能生成为不同标签），等到 Phase 4 开始治理时，面对的可能是一个已经"野蛮生长"了 6-8 周的混乱标签库。清理存量的成本可能远高于从一开始就做基本治理的成本。

---
---

## 林晓薇 · 用户研究官 —— "冷血的数据现实主义者"

---

### 林晓薇 · a 第一阶段的边界在哪里？

**立场**：有条件支持（支持推到可感知价值，但前提是明确"为谁创造价值"和"验证什么假设"）
**一句话观点**：第一阶段的边界应该由"要验证的核心假设"决定，而非技术路线图的分期。
**关键论据**：
1. 现有的技术路线图（07-roadmap.md）是一份工程能力叠加图，但它回避了一个产品层面的根本问题：**我们在为谁建这个东西？** 00-expert-team.md 第 1 节团队使命中明确提出"什么功能让用户 30 秒内感受到价值"，但到目前为止，这个问题仍然没有基于用户数据的回答。我们说的"用户"——到底是谁？是内部产品经理？外部 VOC 分析师？企业 CX 负责人？不同角色对"价值"的感知完全不同。第一阶段的边界如果不锚定在一个具体的用户角色和可验证的假设上，就只是"我们觉得做到这里差不多了"。
2. 01-market-problem.md 描述的三重延迟（检测延迟 4-6 周、对齐延迟 2-3 周、行动延迟 6-8 周）是一个有力的痛点叙事，但它的数据来源是"据我们对 12 家中大型企业 VOC 系统的调研"——样本量和方法论没有披露。12 家企业是哪些行业？调研方式是问卷还是深访？"4-6 周"是中位数还是平均值？如果我们要基于这个痛点定义产品边界，至少应该对自己的目标用户群做一次快速验证：他们真的面临这个问题吗？程度有多严重？他们目前的解决方案是什么？满意度如何？
3. 我的建议是：第一阶段的边界应该能让我们验证**一个核心假设**——"涌现式标签在真实 VOC 数据上比预设分类更能发现未知问题"。这个假设是 VP1 的核心主张，也是 Prism 的差异化根基。为了验证这个假设，MVP 需要做到：(a) 能导入真实的用户反馈数据（哪怕只是 CSV），(b) 能跑完 Stage 1-2 产生涌现标签，(c) 能与预设分类的结果做对比展示。不需要完整的 Agent 运行时，不需要向量检索，不需要治理机制——这些都是假设验证之后的事。
**最大风险**：如果按"最小假设验证"定义边界，可能导致交付物过于简陋——一个只能导入 CSV 和看标签的原型，可能无法给管理层足够的信心继续投入。缺乏足够的"完成感"可能反而削弱团队士气和外部信任。

---

### 林晓薇 · b MVP 功能范围多大？

**立场**：反对（反对将数据摄入 + 涌现标签 + 语义搜索全部塞入 MVP）
**一句话观点**：MVP 范围应由"要验证什么假设"驱动，而非由"技术上能做什么"驱动。
**关键论据**：
1. 当前讨论中的 MVP 功能清单（数据摄入 + 涌现标签 + 语义搜索 + Agent 分析）实质上是把 Phase 3 的全部交付物重新贴了一个"MVP"标签。这不是 MVP 思维，而是"Complete V1"思维。Eric Ries 定义的 MVP 是"能够启动学习循环的最小产品"——关键词是"学习"，不是"功能完整"。我们需要问：**从这个 MVP 中，我们能学到什么？** 如果答案是"用户是否觉得涌现标签有用"，那 MVP 只需要涌现标签的展示和收集用户反馈的通道，不需要语义搜索和 Agent。
2. 09-resource-roi.md 给出了硬约束：Phase 2.5-3 合计需要 3-5 人干 10-14 周，累计投入约 61 万。在这个约束下，如果 MVP 范围定得太大，要么时间延期（验证循环被推迟），要么质量妥协（每个功能都做了 60% 但没有一个做到位）。用户研究的铁律是：**用户不会因为你有 10 个半成品功能而满意，但会因为 1 个做到位的功能而惊喜。** 我宁可看到一个涌现标签做到极致的 MVP，也不愿看到一个"什么都有但什么都差口气"的 V1。
3. 02-vision-proposition.md 列出了六大价值主张（VP1-VP6），但这六条主张目前全部都是**未经验证的假设**。"涌现标签覆盖率从 30% 提升到 85%"——这个数据来自哪里？是 benchmark 测试还是真实用户场景的验证？"其他类占比从 30% 趋近于 0%"——在什么规模的数据上？什么类型的反馈？MVP 的核心任务不是"展示我们能做什么"，而是"验证用户是否需要我们能做的"。功能范围越小，验证循环越快；验证循环越快，我们越早知道方向对不对。
**最大风险**：如果 MVP 范围被我压得太小（比如只有涌现标签展示而没有语义搜索），可能导致用户无法体验到"端到端的价值闭环"——导入数据后只看到一堆标签但无法基于标签做任何事情。这种"半截子体验"可能让用户做出"这东西没用"的错误判断，反而给了产品负面验证信号。

---

### 林晓薇 · c Agent-First 从第一天就要吗？

**立场**：反对（反对第一天就投入 Agent 基础设施）
**一句话观点**：在不知道用户是否需要 Agent 之前，花 22 万建 Agent 骨架是一场昂贵的信仰行为。
**关键论据**：
1. "Agent-First"是 Prism 设计文档中反复出现的核心理念，但我需要指出：**这是一个技术假设，不是一个经过用户验证的需求。** 02-vision-proposition.md 的 VP3 描述了"Agent-Human 价值共创"的美好愿景，但所有论据来自理论框架（S-D Logic、服务主导逻辑）而非用户数据。我们有任何证据表明目标用户想要一个 AI Agent 来帮他们分析 VOC 数据吗？还是说他们更想要一个更好的搜索框和更智能的标签？在没有这个答案之前，Phase 2.5 的 4-6 周 / 约 22 万投入本质上是在押注一个未验证的假设。
2. 从需求层次分析（我习惯用 Kano 模型来区分）：Agent 交互是一个**期望需求**甚至**魅力需求**——有了会加分，但缺少不会让用户拒绝使用产品。而涌现标签、语义搜索是**基本需求**——如果 Prism 连"帮我找到相关反馈"这件事都做不好，Agent 再炫酷也没人用。MVP 阶段的资源应该集中在基本需求上，而非魅力需求。路线图中 Phase 2.5 的验收标准是"Agent 完成一次 ReAct 循环"——这对技术团队有意义，但对用户来说约等于零价值。
3. 09-resource-roi.md 中 Phase 2.5 的团队配置是"后端 x2 + 前端 x0.5"，周期 4-6 周。这些资源如果投入 Phase 3（VOC 数据摄入），可以更早地让用户接触到核心价值——导入数据、看到涌现标签、体验语义搜索。用户研究的基本原则是：**越早把产品放到用户手里，学到的东西越多。** 我宁可用 Phase 2.5 的资源让用户提前 4 周体验到核心功能，也不愿花这些资源建一个目前"只能调用 LLM 做简单对话"的 Agent 骨架。
**最大风险**：如果跳过 Phase 2.5 直接做 Phase 3，后续引入 Agent 时确实可能面临更高的集成成本（技术文档估算为 5-10 倍）。这意味着如果市场验证后确认 Agent 是核心需求，我们会为"当初没提前建骨架"付出显著的技术代价。这个风险是真实的，我不否认。

---

### 林晓薇 · d 涌现标签是否必须进入第一阶段？

**立场**：有条件支持（支持涌现标签进入第一阶段，但必须同时建立验证机制来证明其价值）
**一句话观点**：涌现标签可以进入第一阶段，但必须同时回答"比预设分类好多少"这个问题。
**关键论据**：
1. 涌现标签是 VP1 的核心载体，也是 Prism 宣称的核心差异化。但"涌现标签比预设分类好"目前还是一个**未经验证的假设**。02-vision-proposition.md 中给出的对比表（预设分类覆盖率 30% vs 涌现式 85%+）的数据来源未注明——这是 benchmark 测试数据还是理论推导？是在英文数据上的表现还是中文数据上的表现？是在什么类型的 VOC 数据上测试的？如果涌现标签进入第一阶段，**必须同时设计一个 A/B 对比验证方案**：同一批数据，分别用涌现标签和预设分类处理，让目标用户判断哪个结果更有价值。
2. 01-market-problem.md 中描述的"其他类占比膨胀到 30%"是涌现标签的核心 use case——如果涌现标签确实能把"其他"类别拆解为有意义的语义标签，这对用户来说是一个"打动人心的瞬间"。但这个效果在小数据量下可能不显著。00-expert-team.md 中陈思琪的弱点描述也提到"涌现标签的效果在小数据量下可能不显著"。第一阶段的数据量如果只有几百条内部 dogfooding 数据，涌现标签可能看起来和简单的关键词提取差不多。验证方案需要确保有**足够的数据量**（至少 1000 条真实 VOC 数据）。
3. 我的最小验证路径建议：在 Phase 3 交付涌现标签功能后，立即进行一次为期 1-2 周的快速验证。找 3-5 个真实的产品经理或 VOC 分析师，给他们看同一批数据的两种标注结果（涌现 vs 预设），收集定量评分（哪组标签更完整？哪组更有助于发现未知问题？）和定性反馈。这个验证的成本极低（约 1 人周），但能回答一个价值 61 万（Phase 2.5-3 投入）的问题："我们押注的核心差异化是否真的成立？"
**最大风险**：如果验证结果表明涌现标签在当前数据量和模型能力下**并不明显优于**预设分类（这完全有可能——LLM 在小样本、特定领域数据上的表现可能不及预期），团队可能面临核心叙事动摇的信心危机。这时候需要诚实面对数据，而不是为了维护叙事而否认结果。

---

### 林晓薇 · e 前端投入多少？

**立场**：有条件支持（支持适度前端投入，但必须服务于用户验证而非展示需求）
**一句话观点**：前端投入的唯一正当理由是"能让目标用户完成验证任务"，而非"让演示更好看"。
**关键论据**：
1. 前端投入需要区分两种目的：**演示用途**和**验证用途**。演示用途是"在会议室里让管理层说 wow"——这需要精美的 UI、流畅的动画、完整的交互流程。验证用途是"让目标用户在真实场景中完成一次核心任务"——这只需要能完成任务的最低可用 UI，甚至可以丑但不能不能用。两者的投入量级差 3-5 倍。我主张第一阶段的前端投入应该服务于验证而非演示。
2. 验证所需的最小前端包括：(a) 数据导入界面（CSV 上传），(b) 涌现标签浏览界面（标签列表 + 关联的原始反馈），(c) 语义搜索界面（输入框 + 结果列表 + 溯源链接）。核心能力文档第 6.1 节描述的三层渐进式信息架构（概览 → 探索 → 深钻）是完整产品的 UI 设计，但 MVP 阶段只需要"探索层"的最简版本——让用户能浏览标签、搜索反馈、点击溯源到原文。这大约是 1 个前端工程师 2-3 周的工作量。
3. 但我要强调：**完全没有 UI 的产品是无法进行用户验证的。** 我无法要求目标用户（产品经理、VOC 分析师）通过 curl 命令来评估涌现标签的价值。API First 是正确的技术原则，但"API 是产品"是一个面向开发者的说法，不适用于 Prism 的目标用户。至少需要一个可点击的 Web 界面，让非技术用户能够独立完成"导入数据 → 浏览标签 → 搜索反馈 → 查看原文"的完整流程。
**最大风险**：如果前端投入仅限于"最小可用"，产品的第一印象可能对目标用户的判断产生负面偏差——一个丑陋的界面可能让用户低估了底层能力的价值。用户研究中有一个已知的偏差：**用户对产品的能力评价会受到视觉呈现质量的显著影响**（审美效应/Aesthetic-Usability Effect）。"好用但丑"的原型可能得到比它应得的更低的评价。

---

### 林晓薇 · f 目标用户是谁？第一阶段给谁用？

**立场**：支持（支持必须先找 Design Partner 而非仅靠内部 dogfooding）
**一句话观点**：内部 dogfooding 不等于市场验证——团队成员不是目标用户，他们的反馈会系统性误导产品方向。
**关键论据**：
1. 这是我的核心立场，因为它涉及产品方向的根本性风险。00-expert-team.md 中"当前项目状态速览"显示团队约 2.5 人，都是技术背景。这意味着 dogfooding 的"用户"是一群对系统内部实现了如指掌、对 Bug 极度宽容、使用习惯与真实用户截然不同的人。他们会告诉你"API 响应时间可以优化""这个 JSON 格式不太方便"，但不会告诉你"我根本不理解什么是涌现标签""我不知道为什么要用这个而不是 Excel"。**用户研究最大的陷阱就是用不具代表性的样本做决策。**
2. 01-market-problem.md 描述了 Prism 的目标用户场景——被三重延迟（检测/对齐/行动延迟）困扰的一线产品负责人。但团队中没有人正在承受这些痛苦。你不能通过"想象自己是产品经理"来验证产品对产品经理是否有价值——这就像让大厨自己评价菜品味道，他的味觉已经被厨房的油烟钝化了。至少需要 1-2 个**真实面临 VOC 痛点的外部用户或团队**参与早期验证。
3. 我的最小验证路径：不需要等到产品完成才找 Design Partner。现在就可以进行"概念验证访谈"——带着涌现标签的 mock 示例（哪怕是手动生成的）、与预设分类的对比表、三重延迟的痛点描述，找 5 个潜在目标用户做 30 分钟访谈。验证三个核心假设：(a) 他们是否认同三重延迟是真实痛点？(b) 看到涌现标签 vs 预设分类的对比后，他们是否认为前者更有价值？(c) 他们愿意投入多少时间/精力来试用这样的工具？这个验证 3 天就能完成，零开发成本。
**最大风险**：过早引入外部 Design Partner 可能带来需求噪音——外部用户的个性化需求可能把产品方向带偏，特别是在产品核心架构还未稳定的阶段。此外，找到合适的 Design Partner 本身需要时间和关系网络，如果团队缺乏相关行业人脉，这个过程可能耗时 2-4 周且不一定成功。

---

### 林晓薇 · g 第一阶段是否需要包含治理/采纳机制？

**立场**：有条件支持（支持包含最小反馈收集机制，但反对在第一阶段建完整治理流程）
**一句话观点**：治理流程是 Phase 4 的事，但收集"用户觉得哪些标签有用"的反馈按钮应该 Day 1 就有。
**关键论据**：
1. 方若琳关于"价值闭环"的观点在理论上是正确的——没有反馈通道的功能确实是"一次性烟花"。但我的问题是：**4.5 人的团队有余力建"治理流程"吗？** 09-resource-roi.md 显示 Phase 3 的团队配置是"后端 x2 + AI x1 + 前端 x1 + PM x0.5"，这些人要在 6-8 周内交付四阶段 AI 管线、8 个原子查询工具、数据接入框架和 LLM 输出守卫层。在这个工作量面前，完整的治理机制（Signal 自动产生 + 五个治理操作 + 审计轨迹）是不现实的。
2. 但有一个极低成本的替代方案可以实现"最小反馈收集"：在涌现标签展示界面上添加一个简单的 **thumbs-up/thumbs-down** 按钮，让用户标记"这个标签有用"或"这个标签无用"。数据存入一张简单的 `tag_feedback` 表。这不是治理——没有合并、没有命名、没有状态流转——但它解决了两个关键问题：(a) 为后续的标签质量评估提供真实数据，(b) 让用户感到自己的判断被系统接收了（这是采纳的心理学基础）。开发成本约 2-3 天。
3. 从用户研究角度看，第一阶段最重要的治理数据不是"Signal 如何升级为 Concept"这样的组织流程，而是**"用户认为哪些涌现标签有价值、哪些是噪音"** 这样的原始反馈。这个数据对验证 VP1（涌现式标签 vs 预设分类）的核心假设至关重要。如果 80% 的涌现标签被用户标记为"无用"，那我们在 VP1 上的整个叙事就需要重新审视。这个验证数据的价值远高于一个完整但没人用的治理工作台。
**最大风险**：如果治理机制仅限于 thumbs-up/thumbs-down，用户可能觉得自己的反馈"石沉大海"——标记了"无用"但系统没有任何可见的响应。这种"反馈无响应"的体验会快速消磨用户的参与意愿，最终导致反馈按钮被忽略，收集到的数据量不足以支撑有意义的分析。

---

*本文档为 R0 阶段独立立场宣言（第二批：赵一凡、林晓薇），后续将在 R1 对抗辩论阶段进行交叉质证。*
