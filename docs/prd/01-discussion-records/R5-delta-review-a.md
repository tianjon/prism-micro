# R5 Delta 评审 A：数据摄入重构

> 本文档是 R5 Delta 评审的 Agent A 辩论记录，聚焦用户修正 #1-#4 对数据摄入架构的影响。Delta 评审是在 PRD v1.0 定稿后，针对用户反馈中的重大方向性修正进行的增量评审流程。

**触发原因**：用户（系统最终用户代表，来自汽车行业 [Prism/Avatr] 和消费品行业 [Prism Coffee]）在 PRD v1.0 评审后提出 6 项修正意见，其中 4 项涉及数据摄入架构重构，属于 Agent A 的评审范围。

**评审日期**：PRD v1.0 后增量评审
**涉及修正**：#1（不固定 Schema）、#2（Voice 存储结构确认）、#3（Phase 1 爬虫需求）、#4（LLM 自动转化 + 增量模式）

---

## 1. 变更影响分析

### 1.1 修正 #1：数据输入格式/Schema 总是不固定的

**修正内容**：用户明确指出，CSV、Excel、爬虫数据的字段名和结构都不同，不存在统一的输入 Schema。

**受影响的 PRD 章节**：

| 章节 | 影响程度 | 影响说明 |
|------|---------|---------|
| US-1（首次数据导入） | **重大** | 原 US-1 假设 CSV 必须包含 `text` 列，这与"Schema 不固定"直接矛盾。需要引入 LLM 自动字段映射替代硬编码字段名 |
| 2.1 前置条件 | **重大** | "CSV 格式的客户反馈文件（至少 100 条）"的表述暗示固定格式，需重写 |
| 2.1 异常流程 | **重大** | "缺少 `text` 列"的错误处理逻辑需要改为"LLM 无法识别内容字段"的处理 |
| 03-ingestion-pipeline.md Stage 0（新增） | **新增** | 需要在四阶段管线前新增 Stage 0：Schema 识别与自动映射 |
| 02-data-architecture.md Voice 模型 | **轻微** | Voice 模型本身字段不需改动（修正 #2 已确认），但需新增 `SchemaMapping` 和 `IngestionJob` 模型 |

**核心问题**：PRD v1.0 的 US-1 将 CSV 结构视为一个可预期的、简单的映射问题（"必须包含 `text` 列"），但真实业务场景中，每个数据源的字段名千差万别——Prism的懂车帝爬虫数据可能有 `评论内容`、`用户名`、`车型`，而 Prism 的微博数据可能是 `博文正文`、`发布时间`、`互动量`。这意味着系统必须具备 LLM 辅助的动态 Schema 理解能力。

### 1.2 修正 #2：Voice 存储结构相对固定

**修正内容**：用户确认 Voice 的数据模型不需要大改。

**受影响的 PRD 章节**：

| 章节 | 影响程度 | 影响说明 |
|------|---------|---------|
| 02-data-architecture.md Voice 模型 | **确认** | 现有设计（id, tenant_id, content, title, source_type, source_metadata 等）被用户验证为合理 |
| 02-data-architecture.md 整体架构 | **无影响** | Voice → SemanticUnit → EmergentTag 的三层数据结构保持不变 |

**核心问题**：这是一个好消息——说明原有的 Voice 数据模型设计是合理的。修正 #2 与修正 #1 结合起来理解：**输入端混乱（Schema 不固定），但输出端稳定（Voice 结构固定）**。这意味着系统需要的是一个"适配器层"（Adapter Layer），负责将多种不固定输入映射到固定的 Voice 结构。

### 1.3 修正 #3：Phase 1 必须含特定爬虫

**修正内容**：Phase 1 必须包含用户上传 + 懂车帝爬虫 + 微博爬虫；Phase 2 才做可配置周期性采集。

**受影响的 PRD 章节**：

| 章节 | 影响程度 | 影响说明 |
|------|---------|---------|
| US-1 | **扩展** | 数据来源从单一 CSV 扩展为 CSV/Excel + 爬虫 |
| US-2（语义搜索） | **轻微** | 搜索对象新增爬虫采集的数据，但搜索功能本身无变化 |
| 功能清单 | **新增** | 需新增"懂车帝爬虫"和"微博爬虫"两个功能条目 |
| 排期估算 | **重大** | 爬虫开发需要额外工时（每个爬虫预估 5-8 人天），总工期可能延长 2-3 周 |
| 技术架构 | **重大** | 爬虫需要与 Agent/Skill 引擎集成，涉及 dev-browser 等浏览器控制工具的架构设计 |
| `SourceType` 枚举 | **扩展** | 需新增 `CRAWLER_DCDPI`（懂车帝）和 `CRAWLER_WEIBO`（微博）等来源类型，或使用现有 `SOCIAL` / `REVIEW` 配合 `source_metadata` 区分 |

**核心问题**：PRD v1.0 完全没有涉及爬虫采集。用户将其定义为 Phase 1 Must Have，理由是Prism需要懂车帝数据（汽车评论）、Prism 需要微博数据（消费者口碑）。这是一个功能边界的重大扩展，必须认真评估工时和架构影响。

### 1.4 修正 #4：LLM 自动转化 + 增量模式

**修正内容**：Raw Data → Voice 转化必须由 LLM 自动完成，减少手工确认；必须支持增量模式。

**受影响的 PRD 章节**：

| 章节 | 影响程度 | 影响说明 |
|------|---------|---------|
| US-1 主流程第 3 步 | **重大** | 原设计"用户确认字段映射后点击开始导入"暗示人工确认环节，用户要求减少此环节 |
| 03-ingestion-pipeline.md | **重大** | 需新增 Stage 0 自动映射环节，并将人工确认改为可选的异常处理 |
| 02-data-architecture.md | **新增** | 需新增增量控制相关字段：content_hash、batch_id、dedup_status |
| US-1 验收标准 | **新增** | 需新增增量处理相关验收标准：重复数据自动跳过、增量导入不影响已有数据 |

**核心问题**：原 US-1 设计中的"用户确认字段映射"步骤虽然安全，但在实际操作中是一个高摩擦的环节。如果用户每天有数百条新的爬虫数据需要导入，手工确认映射会成为严重的采纳瓶颈。用户的诉求是"扔数据进去就能用"，而不是"每次都要确认一遍 Schema"。

---

## 2. 专家辩论记录

### 议题 A1：不固定 Schema 的 LLM 自动映射策略

**核心矛盾**：LLM 映射的准确率 vs 人工确认的效率
**主辩双方**：陈思琪（正方：LLM 自动映射可行）vs 周安（反方：需要人工安全网）

---

#### 第一轮：正方开题

**陈思琪**（AI/ML 工程师）：

各位，让我先明确一个前提——我们面对的不是一个传统的 ETL 问题，而是一个**语义理解问题**。用户给我们的 CSV 可能列名叫 `评论内容` 或 `comment` 或 `反馈文本`，但 LLM 完全有能力理解这些字段的语义，并将其正确映射到 Voice 模型的 `content`、`collected_at`、`source_type` 等字段。

技术方案是这样的：

1. **采样策略**：读取文件前 10 行，连同列名一起发给 LLM
2. **Prompt 工程**：给出 Voice 模型的目标字段定义和示例，要求 LLM 输出列名到字段的映射关系
3. **结构化输出**：使用 JSON Schema 约束 LLM 输出格式，确保映射结果可直接程序化处理
4. **置信度**：LLM 对每个映射附带置信度分数

根据我的经验和测试，这类任务的映射准确率可以达到 **90% 以上**——因为这不是一个需要创造力的任务，而是一个模式匹配任务。CSV/Excel 列名虽然不固定，但语义空间是有限的：`评论内容`、`comment`、`content`、`正文`、`text` 这些变体，LLM 全部能正确识别为 `content` 字段。

更重要的是，Voice 模型中真正关键的映射只有 2-3 个字段（content 是必须的，collected_at 和 source_type 是建议的），其余字段可以存入 `source_metadata` JSONB 字段。映射任务本身的复杂度远低于我们后续的语义拆解和标签涌现。

**结论**：LLM 自动映射不仅可行，而且是唯一能规模化的方案。如果每次导入都需要人工映射，系统就不可能支持定时爬虫自动入库的场景。

---

#### 第一轮：反方开题

**周安**（安全与合规顾问）：

我先做钢人论证——陈思琪说的没错，对于"列名语义理解"这类有限空间的任务，LLM 的准确率确实可以做到 90% 以上。我不质疑技术可行性。

但我质疑的是**那 10% 的错误会带来什么后果**。

设想这个场景：某份 CSV 有一列叫 `回复时间`，LLM 可能把它映射为 `collected_at`（用户发表时间），而实际上它是客服响应时间。这个错误会导致所有时间维度的分析出现系统性偏差——用户看到"本月投诉集中在周三"，实际上不是用户在周三投诉，而是客服在周三集中处理积压。

再设想：某份数据有 `评分` 列（1-5 星），LLM 可能将其映射为 `quality_score`（Voice 质量分）而非存入 `source_metadata`。这种语义接近但含义不同的字段，正是 LLM 最容易犯错的地方。

**我的诉求不是要求全量人工确认**——那确实不可行。我的诉求是：

1. **首次映射时展示预览**：LLM 完成映射后，向用户展示"我认为您的数据结构是这样的"，用户一键确认或修正
2. **映射模板缓存**：同一数据源的映射只需确认一次，后续复用
3. **低置信度字段告警**：置信度 < 0.8 的映射高亮标记，建议用户核实
4. **抽样验证**：自动抽取 3-5 条数据，展示映射结果预览

这些不是"人工确认每一行"，而是"人工确认映射规则一次，之后自动执行"。成本很低，但能避免系统性数据污染。

---

#### 第二轮：自由交锋

**陈思琪**：周安的方案我基本同意，但我要强调一个关键区分——**首次映射确认** vs **每次导入确认**。对于用户上传 CSV/Excel 的场景，首次展示映射预览是合理的。但对于爬虫数据，爬虫脚本本身就定义了数据结构，根本不需要 LLM 映射——爬虫输出的就是已知结构的数据。所以真正需要 LLM 映射的只是"用户手动上传未知格式文件"这一个场景。

**周安**：同意。爬虫数据的结构是开发时确定的，不需要运行时映射。但我要追问：如果未来用户上传的数据格式变了（比如Prism换了一个内部系统导出的 CSV），映射模板还能用吗？

**陈思琪**：这正是 LLM 映射的价值所在——它不是基于硬编码规则的映射，而是基于语义理解的映射。即使列名从 `评论内容` 变成 `用户反馈文本`，LLM 照样能正确映射。映射模板是加速手段，不是唯一路径。

**赵一凡**（首席架构师）：我介入一下。技术上，我认为需要定义一个清晰的 `SchemaMapping` 数据模型：

```python
class SchemaMapping:
    id: str
    tenant_id: str
    name: str                    # 映射名称（如"懂车帝评论数据"）
    source_format: str           # csv / excel / json
    column_mappings: dict        # {"原始列名": "voice 字段名"}
    created_by: str              # "llm" / "user" / "llm+user_confirmed"
    confidence: float            # LLM 映射的整体置信度
    sample_data: list            # 采样数据（用于展示预览）
    usage_count: int             # 复用次数
    created_at: datetime
    updated_at: datetime
```

这个模型解决了几个问题：（1）映射结果可持久化复用；（2）记录映射来源是纯 LLM 还是用户确认过的；（3）为未来的映射质量分析提供数据基础。

**王磊**（全栈工程师）：我给一个工时估算。LLM 自动映射 + 预览确认 + 模板缓存，前后端加起来大概 **5-7 人天**。拆分一下：
- LLM 映射 Prompt + 解析逻辑：2 天
- SchemaMapping 数据模型 + CRUD：1 天
- 前端映射预览 + 确认交互：2-3 天
- 测试 + Edge case：1 天

这个投入是合理的，比"每次让用户手动选列"的方案开发成本差不多，但用户体验好一个数量级。

---

#### 魔鬼代言人发言

**林晓薇**（用户研究官）：

你们讨论了很多技术方案，但我想提出第三种可能——**我们是否在过度工程化一个可能不存在的问题？**

用户说"Schema 不固定"，但我们有没有搞清楚到底有多少种 Schema？Prism用懂车帝数据（一种格式）+ 自己的 CRM 导出（可能一种格式）；Prism 用微博数据（一种格式）+ 门店反馈表（可能一种格式）。也就是说，Phase 1 真正需要处理的数据格式可能就 4-5 种。

对于 4-5 种已知格式，**硬编码适配器** 可能比 LLM 映射更可靠、更快、成本更低。每种格式写一个解析器，总共也就 2-3 人天。LLM 映射是一个通用化方案，但通用化在 MVP 阶段真的需要吗？

当然，我不是说 LLM 映射没有价值——Phase 2 做可配置采集时它会很有用。但 Phase 1 的优先级应该是"让已知用户的已知数据跑通"，而不是"为未知用户的未知格式做通用方案"。

我的建议：Phase 1 用硬编码适配器处理已知格式 + LLM 映射作为 fallback 处理未知格式。这样既快又安全。

---

#### 专家投票

| 专家 | 投票 | 理由 |
|------|------|------|
| 苏明远 | **支持正方（LLM 映射）** | LLM 自动映射 + 首次确认的体验远优于硬编码适配器。用户不应该关心数据格式，"扔进来就能用"才是产品价值 |
| 赵一凡 | **支持正方** | 但必须配合 SchemaMapping 持久化模型。LLM 映射是 Type 2 决策（可逆），先做起来，不好再换 |
| 陈思琪 | **支持正方** | LLM 映射的技术可行性已充分论证，5-7 人天的投入完全可控 |
| 林晓薇 | **有条件支持正方** | 同意 LLM 映射方案，但要求 Phase 1 先为已知的 4-5 种格式准备预置模板，LLM 映射作为 fallback |
| 周安 | **有条件支持正方** | 同意，但首次映射预览 + 置信度告警 + 映射模板缓存是硬性要求，不可省略 |
| 王磊 | **支持正方** | 5-7 人天可接受。先做 CSV/Excel 的 LLM 映射，爬虫数据用硬编码解析器 |
| 方若琳 | **支持正方** | LLM 自动映射降低了用户的认知成本和操作摩擦，有利于组织采纳 |

**投票结果**：7:0 支持 LLM 自动映射方案（其中 2 票为有条件支持）

**共识决议**：
1. 用户上传 CSV/Excel 采用 LLM 自动映射 + 首次确认预览
2. 爬虫数据采用硬编码解析器（结构在开发时已知）
3. 新增 SchemaMapping 数据模型，支持映射模板复用
4. 低置信度映射（< 0.8）高亮提示用户
5. 为已知用户（Prism、Prism）预置数据格式模板

---

### 议题 A2：爬虫作为 Skill 进入 Phase 1

**核心矛盾**：爬虫是否属于 MVP 范围 vs 用户明确需求
**主辩双方**：苏明远 + 林晓薇（正方：爬虫必须进入 Phase 1）vs 赵一凡（反方：架构耦合风险）

---

#### 第一轮：正方开题

**苏明远**（产品策略师）：

我用一个反问开始——**如果 Prism Phase 1 只支持 CSV 上传，Prism和 Prism 会用它吗？**

让我描述一下没有爬虫的用户体验：
1. 用户打开懂车帝，手动翻页、复制评论、粘贴到 Excel
2. 整理成 CSV 格式
3. 上传到 Prism
4. 等待 AI 处理
5. 第二天重复以上步骤

这不叫"30 秒感受到价值"，这叫"30 分钟手工搬运数据"。用户会用两次然后放弃。

Prism明确需要懂车帝数据——因为那里有车主的真实用车反馈，是产品改进的核心数据源。Prism 需要微博数据——因为那里有消费者对新品的即时口碑。这两个需求不是假设，而是**真实用户的明确诉求**。

更关键的是——我们终于有了真实用户。R1 辩论中林晓薇一直追问"我们有用户吗？"，现在答案是"有了"。Prism和 Prism 就是我们的 Design Partner。既然有了真实用户，就应该响应他们的真实需求。

**林晓薇**（用户研究官）：

我补充苏明远的论点。在之前的讨论中，我一直强调"没有用户验证的功能清单就是一份 wish list"。但现在情况变了——Prism和 Prism 是真实的潜在用户，他们提出的需求具有以下特征：

1. **具体到数据源**：不是"我们需要爬虫"，而是"我们需要懂车帝和微博的数据"
2. **有明确的业务场景**：Prism监控车主口碑，Prism 追踪消费者对新品的反应
3. **高频使用**：这不是一次性需求，而是每天/每周都需要的数据输入

从用户研究角度，这是 **Must Have** 级别的需求——不是因为爬虫技术上有多重要，而是因为没有自动化数据采集，产品的核心价值循环就跑不起来。

---

#### 第一轮：反方开题

**赵一凡**（首席架构师）：

钢人论证：苏明远和林晓薇说的对——真实用户的真实需求当然应该优先响应，爬虫是让数据采集自动化的关键。我不反对爬虫进入 Phase 1。

我关心的是**爬虫如何进入系统的架构设计**。用户的补充上下文提到爬虫架构是"Python 脚本，基于 dev-browser 等浏览器控制工具，包装业务领域逻辑，需被 agent/skill 引擎调用"。这里面有几个架构问题必须现在回答：

1. **爬虫与 Agent/Skill 引擎的耦合**：爬虫被设计为 Skill，需要 Agent 运行时来调度。但 R4 投票中 Agent 基础设施只通过了"精简版"（#7，加权分 3.57），精简到什么程度能支撑爬虫调度？

2. **浏览器控制依赖**：dev-browser 等工具需要 Chromium 运行时环境，这意味着爬虫不能跑在常规的 Docker 容器里，需要特殊的运行环境配置。

3. **错误处理与重试**：爬虫天然不稳定——页面改版、反爬机制、网络超时。爬虫的错误处理与 AI 管线的错误处理是两套完全不同的逻辑。

4. **数据格式约定**：爬虫脚本输出什么格式？JSON？CSV？每个爬虫的输出 Schema 是否需要标准化？

我的立场是：**爬虫可以进入 Phase 1，但必须作为独立模块，不与 Agent/Skill 引擎深度耦合**。Phase 1 的爬虫就是两个独立的 Python 脚本，通过 CLI 触发，输出标准化 JSON，然后走正常的摄入管线。Agent/Skill 集成是 Phase 2 的事。

---

#### 第二轮：自由交锋

**王磊**（全栈工程师）：赵一凡的方案很务实。让我给个工时估算：

| 组件 | 工时 | 说明 |
|------|------|------|
| 懂车帝爬虫脚本 | 5-6 人天 | 含反爬处理、分页、数据解析 |
| 微博爬虫脚本 | 5-7 人天 | 微博反爬更复杂，可能需要登录态 |
| 爬虫输出标准化 | 1-2 人天 | 定义标准输出 JSON Schema，对接摄入管线 |
| CLI 触发命令 | 1 人天 | `prism crawl dongchedi --keyword "Prism"` |
| 测试 + 调试 | 2-3 人天 | 爬虫本身不稳定，需要大量调试 |
| **总计** | **14-19 人天** | 约 3-4 周（1 人全职） |

这个工时不可忽视——它相当于 Phase 1 原计划（14-18 周 * 2.5 人）中一个人整整一个月的工作量。如果加上爬虫，Phase 1 总工期可能延长 **2-3 周**，或者需要并行开发分担。

**苏明远**：3-4 周换来两个真实用户的核心需求满足，这个 ROI 是值得的。没有爬虫，Prism和 Prism 可能在试用一周后流失。

**赵一凡**：关于架构，我强调一下 Phase 1 爬虫的边界：

```
Phase 1 爬虫架构（最简版）：
┌──────────────┐     ┌──────────────┐     ┌──────────────┐
│ CLI 命令      │────▶│ 爬虫脚本      │────▶│ 标准 JSON     │
│ prism crawl  │     │ (独立 Python) │     │ 输出文件      │
└──────────────┘     └──────────────┘     └──────────────┘
                                                  │
                                                  ▼
                                          ┌──────────────┐
                                          │ 摄入管线      │
                                          │ (正常 Voice   │
                                          │  创建流程)    │
                                          └──────────────┘

Phase 2 爬虫架构（完整版）：
┌──────────────┐     ┌──────────────┐     ┌──────────────┐
│ Agent/Skill  │────▶│ 爬虫 Skill    │────▶│ 自动入库      │
│ 调度引擎      │     │ (被调度执行)   │     │ (增量 + 去重) │
└──────────────┘     └──────────────┘     └──────────────┘
        │
        ▼
┌──────────────┐
│ 定时触发器    │
│ (周期性采集)  │
└──────────────┘
```

Phase 1 只做上半部分。这是 Type 2 决策，后续可以无痛升级到 Phase 2 架构。

**陈思琪**：我同意赵一凡的分层方案。但我要补充一点——爬虫脚本的输出需要包含足够的元数据，让后续的 LLM 处理更精准。比如懂车帝数据应该包含车型、年款、评分等结构化字段，这些信息对标签涌现的质量有直接影响。

**方若琳**（企业创新变革顾问）：从组织采纳角度，我支持爬虫进入 Phase 1，但我要提醒一个被忽视的问题：**爬虫的合规风险**。懂车帝和微博的 robots.txt 是否允许爬取？数据的使用是否符合平台的用户协议？Prism作为一个大型车企，如果被发现违规爬取数据，这个后果不是 Prism 能承担的。

**周安**：方若琳说到了关键问题。爬虫合规是一个必须在 Day 1 就解决的问题。我建议：
1. 在爬虫文档中明确标注合规风险
2. 爬虫默认使用合理的请求频率（< 1 req/s）
3. 尊重 robots.txt
4. 数据仅用于客户自身的分析，不做二次分发

---

#### 魔鬼代言人发言

**陈思琪**（AI/ML 工程师，本议题魔鬼代言人）：

你们都在讨论"爬虫怎么做"，但我要提出第三种可能——**Phase 1 不做爬虫，而是做"数据粘贴导入"**。

用户的核心需求是"懂车帝和微博的数据进入系统"，但"进入系统"的方式不一定是爬虫。一个更低成本的替代方案是：

1. 用户在懂车帝页面使用浏览器插件，一键选中评论区，复制粘贴到 Prism 的"文本导入"框
2. 或者用户使用第三方爬虫工具（如八爪鱼、Web Scraper）自行采集，导出 CSV 后上传

这种方案不需要我们开发爬虫，省下 14-19 人天。风险是用户体验差——需要手动操作。

但我自己并不真的推荐这个方案。原因是：用户已经明确说了"需被 agent/skill 引擎调用"，这说明他们期望的是自动化采集，而不是手动搬运。如果我们交付一个需要手动复制粘贴的方案，用户会认为我们没理解他们的需求。

所以我只是作为魔鬼代言人提出这种可能性，让大家明确：**我们选择做爬虫不是因为技术上必须，而是因为用户体验和信任建设上必须**。

---

#### 专家投票

| 专家 | 投票 | 理由 |
|------|------|------|
| 苏明远 | **支持正方（爬虫进入 Phase 1）** | 真实用户的真实需求，这是产品存在的基础 |
| 赵一凡 | **有条件支持正方** | 同意进入 Phase 1，但必须是独立脚本 + CLI 触发的最简架构，不与 Agent/Skill 深度耦合 |
| 陈思琪 | **支持正方** | 爬虫数据是 AI 管线的"食粮"，没有数据源多样性，涌现标签的价值无法充分展现 |
| 林晓薇 | **支持正方** | Prism和 Prism 是真实 Design Partner，他们的需求就是我们的验证目标 |
| 周安 | **有条件支持正方** | 同意，但合规要求（请求频率、robots.txt、数据使用范围）是硬性约束 |
| 王磊 | **支持正方** | 14-19 人天的投入可控，建议一个人专职做爬虫，与主线并行 |
| 方若琳 | **有条件支持正方** | 同意，但必须在交付文档中明确合规责任归属（用户企业自行承担爬虫合规风险） |

**投票结果**：7:0 支持爬虫进入 Phase 1（其中 3 票为有条件支持）

**共识决议**：
1. Phase 1 实现懂车帝 + 微博两个爬虫，作为独立 Python 脚本
2. 通过 CLI 命令触发（`prism crawl dongchedi`、`prism crawl weibo`）
3. 输出标准化 JSON，通过正常摄入管线入库
4. 不与 Agent/Skill 引擎耦合——Phase 2 再做集成
5. 遵守合规约束：合理请求频率、尊重 robots.txt、数据使用范围限定
6. 预估额外工时：14-19 人天（约 3-4 周，1 人全职）

---

### 议题 A3：增量模式的设计

**核心矛盾**：增量去重的技术复杂度 vs 必要性
**主辩双方**：赵一凡（正方：增量模式需要系统设计）vs 王磊（反方：最小增量即可）

---

#### 第一轮：正方开题

**赵一凡**（首席架构师）：

增量模式不是一个可选特性，而是一个**数据完整性的基本要求**。让我解释为什么。

场景一：用户今天上传了 1000 条 CSV，明天又加了 200 条新的和 800 条重复的，再次上传 1000 条。如果没有增量去重，系统会有 800 条重复数据，导致：
- 标签统计失真（重复数据会人为放大某些标签的频率）
- 搜索结果冗余
- LLM 处理成本翻倍

场景二：懂车帝爬虫每天跑一次，抓取最近 7 天的评论。第 2 天到第 7 天的数据与前一天重叠。如果没有增量去重，7 天后系统中每条评论平均有 7 份副本。

增量模式的核心组件：

1. **Content Hash 去重**：对 Voice 的 `content` 字段计算 SHA-256 hash，存入 `content_hash` 字段。写入前查重。
2. **幂等处理**：已处理完成的 Voice 不重新进入 AI 管线。通过 `status = completed` 判断。
3. **Source ID 去重**：对于有外部 ID 的数据（如微博 ID、懂车帝评论 ID），通过 `source_id` 字段去重。
4. **Batch 管理**：每次导入作为一个 `IngestionBatch`，记录批次元数据（来源、总数、新增数、跳过数、失败数）。

数据模型需要扩展：

```python
class Voice:
    # ... 现有字段 ...
    content_hash: str              # SHA-256(content)，用于内容去重
    batch_id: Optional[str]        # 所属导入批次

class IngestionBatch:
    id: str
    tenant_id: str
    source: str                    # "csv_upload" / "crawler_dongchedi" / "crawler_weibo"
    file_name: Optional[str]       # 上传文件名
    total_count: int               # 总记录数
    new_count: int                 # 新增数
    duplicate_count: int           # 重复跳过数
    failed_count: int              # 失败数
    status: str                    # pending / processing / completed / failed
    started_at: datetime
    completed_at: Optional[datetime]
    created_by: str                # 操作人
```

这是地基级的设计，不做好后面会出大问题。

---

#### 第一轮：反方开题

**王磊**（全栈工程师）：

钢人论证：赵一凡说的重复数据问题完全真实，增量去重是必要的。我不反对增量模式本身。

我反对的是"过度设计增量模式"。赵一凡方案里的 `IngestionBatch` 数据模型、Source ID 去重、批次管理——这些是完整版增量系统的设计。Phase 1 需要的只是**最小增量**：

```python
# 最小增量 = 两行代码
content_hash = hashlib.sha256(voice.content.encode()).hexdigest()
if await voice_repo.exists_by_hash(tenant_id, content_hash):
    return "skipped"  # 跳过已存在的
```

加上一个数据库唯一索引：

```sql
CREATE UNIQUE INDEX idx_voices_content_hash ON voices(tenant_id, content_hash);
```

就这样。整体工时 **0.5 人天**。

`IngestionBatch` 是好东西，但它是 Phase 2 的事。Phase 1 的用户不需要看到"本次导入新增 200 条，跳过 800 条"这种统计信息——他们只需要知道"数据导进去了，没有重复"。

Source ID 去重也是 Phase 2 的事——Phase 1 的爬虫脚本可以在脚本内部做 Source ID 去重（在请求爬取前先检查本地已抓取的 ID 列表），不需要在数据库层面支持。

**我的原则是：先做能解决 80% 问题的 20% 工作，剩下的 80% 工作在 Phase 2 做。**

---

#### 第二轮：自由交锋

**赵一凡**：王磊的最小方案能解决 content 完全相同的去重，但处理不了以下场景：

1. **内容微变**：同一条评论被抓了两次，但第二次多了一个空格或少了一个标点——hash 不同，被当作新数据。
2. **不同来源的同一内容**：一条评论同时出现在懂车帝和微博（用户交叉发布），hash 可能相同但 source 不同——到底算不算重复？

**王磊**：第一个问题，Phase 1 的答案是"接受这种程度的不完美"。内容微变的去重需要模糊匹配（simhash、minhash），这是一个独立的技术课题，投入产出比在 MVP 阶段不合理。第二个问题，跨来源去重确实是 content hash 就能解决的——hash 相同就是重复，不管来源是什么。

**陈思琪**：我站王磊这边。从 AI 管线角度，即使有少量重复数据（比如 5% 的微变体），对标签涌现的影响可以忽略不计——因为涌现标签是统计性的，少量重复不会显著改变标签分布。真正有害的是大规模重复（比如同一批数据被导入两次），而 content hash 恰好能解决这种情况。

**赵一凡**：好吧，我接受最小增量方案。但我有一个非协商条件——`IngestionBatch` 模型必须在 Phase 1 就定义（即使字段精简），因为它是后续增量管理的地基。如果 Phase 1 连批次概念都没有，Phase 2 要加批次管理就需要数据迁移。

**王磊**：可以接受精简版 `IngestionBatch`——只保留 id、tenant_id、source、total_count、new_count、duplicate_count、status、created_at。其余字段 Phase 2 再加。工时增加 **0.5-1 人天**。

---

#### 魔鬼代言人发言

**周安**（安全与合规顾问）：

你们讨论了去重，但漏掉了一个重要问题——**增量模式下的数据溯源**。

如果用户上传了一批数据，其中 800 条被标记为重复跳过，用户怎么知道这些"重复"真的是重复？万一是 hash 碰撞（虽然概率极低但理论上可能），用户的数据就被静默丢弃了。

我的建议是：
1. 导入完成后向用户展示"新增 X 条、跳过 Y 条重复、失败 Z 条"的摘要
2. 被跳过的数据不是丢弃，而是标记 `skip_reason = duplicate`，保留可追溯
3. 用户可以点击查看被跳过的数据列表

第 1 点其实就是 `IngestionBatch` 的展示层。赵一凡坚持 Phase 1 就要 `IngestionBatch`，从审计角度看是对的。

---

#### 专家投票

| 专家 | 投票 | 理由 |
|------|------|------|
| 苏明远 | **支持反方（最小增量）** | Phase 1 先解决 80% 的问题，用户不关心去重的技术细节 |
| 赵一凡 | **有条件支持反方** | 接受最小增量实现，但精简版 IngestionBatch 模型必须同步落地 |
| 陈思琪 | **支持反方** | content hash 去重对 AI 管线来说已经足够 |
| 林晓薇 | **支持反方** | 同意先简后繁，但导入摘要（新增/跳过/失败数）对用户体验很重要 |
| 周安 | **有条件支持反方** | 同意最小实现，但被跳过的数据必须可追溯，不能静默丢弃 |
| 王磊 | **支持反方** | 1-1.5 人天搞定，不拖进度 |
| 方若琳 | **支持反方** | 增量模式降低了用户的重复劳动，对采纳有利 |

**投票结果**：7:0 支持最小增量方案（其中 2 票为有条件支持）

**共识决议**：
1. Phase 1 增量去重 = content hash（SHA-256）+ 唯一索引
2. 同步落地精简版 `IngestionBatch` 模型（id, tenant_id, source, total/new/dup/fail count, status, created_at）
3. 导入完成后展示摘要（新增/跳过/失败数）
4. 被跳过的数据记录 skip 原因，不静默丢弃
5. 模糊去重（simhash）、跨来源 Source ID 去重推迟到 Phase 2
6. 预估工时：1-1.5 人天

---

### 议题 A4：LLM 自动转化 vs 手工确认

**核心矛盾**：自动化程度 vs 数据质量
**主辩双方**：方若琳 + 苏明远（正方：最大化自动化）vs 周安（反方：需要安全网）

---

#### 第一轮：正方开题

**方若琳**（企业创新变革顾问）：

让我用 Kotter 的变革模型来分析这个问题。组织采纳一个新工具的最大阻力不是"工具不好用"，而是"工具增加了我的工作量"。

如果 Raw Data → Voice 的转化过程需要用户手工确认：
- 每天爬虫抓取 200 条新数据
- 用户需要花 30 分钟审核映射结果
- 这 30 分钟没有产出新价值，纯粹是"喂数据"的苦力活

两周后会发生什么？用户会说"我没时间每天花半小时喂数据给 Prism"，然后停止使用。

这不是假设——这是我在企业数字化转型中见过无数次的模式。**任何在价值产出前增加用户工作量的环节，都是采纳杀手**。

用户的诉求非常明确：LLM 必须自动完成 Raw → Voice 转化。这意味着：

1. CSV/Excel 上传后，LLM 自动识别 Schema、自动映射、自动入库
2. 爬虫数据抓取后，直接入库（爬虫输出格式是开发时确定的）
3. 用户只在异常情况下介入（比如 LLM 完全无法理解某个文件的结构）

**正常路径应该是零手工确认**。

**苏明远**（产品策略师）：

方若琳说到了点子上。让我补充产品视角——

Prism 的产品叙事是"AI 自动发现未知问题"。如果连"把数据喂进去"这一步都需要大量手工操作，用户会质疑"这到底有多 AI？"

竞品对比：如果 Qualtrics 也需要用户手动映射每个字段，用户至少有个借口——"这是传统工具，不意外"。但 Prism 定位为 AI 驱动的平台，如果数据导入体验和传统工具一样笨重，用户会更失望——因为期望值更高。

我的一句话总结：**数据摄入的自动化程度决定了用户对 Prism "AI 能力"的第一印象。**

---

#### 第一轮：反方开题

**周安**（安全与合规顾问）：

钢人论证：方若琳和苏明远说的完全对——手工确认是采纳杀手，LLM 自动化是用户体验的关键。我不反对自动化的大方向。

但我必须指出一个被忽略的风险：**完全自动化 = 用户对数据质量完全失去掌控感**。

设想这个链条：
1. 爬虫自动抓取 200 条微博数据
2. LLM 自动映射字段
3. AI 管线自动拆解 + 标签涌现
4. 用户打开 Prism，看到一堆标签

用户在整个过程中没有任何参与。如果某天爬虫抓错了页面（比如抓到了广告内容而非用户评论），LLM 照样会"映射"、"拆解"、"打标签"——产出的结果看起来完全正常，但基于的是错误数据。用户不会意识到任何问题，直到他基于这些数据做了一个错误决策。

**这就是我说的"一次 LLM 幻觉被当事实传递 = 灾难"的变种——这次不是 LLM 幻觉，而是垃圾输入被 AI 美化成了看似有价值的输出。**

我的方案不是"每次手工确认"，而是**分层自动化 + 置信度阈值**：

| 场景 | 自动化程度 | 用户参与 |
|------|----------|---------|
| 已有映射模板的数据源 | 完全自动 | 无需参与 |
| LLM 映射置信度 >= 0.9 | 自动 + 异步通知 | 用户收到"已自动处理 200 条"通知，可选审查 |
| LLM 映射置信度 0.7-0.9 | 自动 + 标记 | 数据正常入库但标记 `confidence=medium`，在 UI 中区别展示 |
| LLM 映射置信度 < 0.7 | 暂停 + 等待确认 | 系统暂停处理，通知用户"无法确定数据结构，请协助确认" |

这个方案保留了 95%+ 场景的完全自动化（因为多数数据会落在高置信度区间），只在极端情况下才要求用户介入。

---

#### 第二轮：自由交锋

**方若琳**：周安的方案我大体接受，但我要推回一个细节——置信度 0.7-0.9 区间的数据入库后标记 `confidence=medium`，在 UI 中区别展示。这个"区别展示"如果做得太重（比如加一个大大的警告框），用户反而会被干扰。

建议的折中：中等置信度数据正常展示，但在 Voice 详情页的来源信息中标注"自动映射（置信度：中）"——只有用户主动查看时才能看到。这样不干扰正常使用，但保留了可追溯性。

**周安**：可以接受。但我坚持一点——低置信度（< 0.7）必须暂停等待确认，这个不能松动。因为 < 0.7 意味着 LLM 对"这列数据到底是什么"基本没把握，强行入库大概率会出错。

**陈思琪**：从技术角度，我需要澄清一个概念混淆。这里讨论的"LLM 自动转化"实际上涉及两个不同的层次：

1. **Schema 映射的自动化**：LLM 自动识别字段→Voice 映射。这是议题 A1 已经解决的问题。
2. **AI 管线处理的自动化**：Voice 创建后自动进入 Stage 1-3 管线。这在 PRD v1.0 中就是自动的，从来不需要手工确认。

用户说"减少手工确认"，我理解主要针对的是第 1 层——Schema 映射。第 2 层本来就是自动的。所以，只要 Schema 映射的自动化做好了（议题 A1 的结论），用户的诉求就基本满足了。

**王磊**：陈思琪说得对。其实我们把议题 A1 和 A4 合在一起看，解决方案已经很清晰了：

1. 首次上传新格式文件 → LLM 自动映射 + 用户一键确认（A1 结论）
2. 后续上传同格式文件 → 复用映射模板，完全自动
3. 爬虫数据 → 完全自动（格式在开发时确定）
4. LLM 映射低置信度 → 暂停等待确认
5. Voice 创建后 → AI 管线全自动

这样一来，"手工确认"只发生在"首次上传全新格式"这一个场景，而且只是"看一眼映射预览然后点确认"的 5 秒钟操作。

**林晓薇**：我想从用户心理角度补充一点。"零手工确认"听起来很好，但可能会引发另一个问题——**用户不信任感**。如果用户完全不参与数据处理过程，他可能会想"Prism 到底把我的数据怎么了？"。首次映射确认其实是一个**建立信任**的机会——"嘿，这是我理解你数据的方式，你看看对不对？"

所以，我的观点与陈思琪一致——首次确认不是负担，而是信任建设。但后续复用必须完全自动化。

---

#### 魔鬼代言人发言

**赵一凡**（首席架构师）：

你们都同意"首次确认 + 后续自动"的方案，看起来很和谐。但我要提出一个第三种可能——**什么都不做，因为这不是 Phase 1 的问题**。

Phase 1 总共只有两类数据源：用户上传（CSV/Excel）和两个特定爬虫。爬虫数据格式是确定的，CSV/Excel 在议题 A1 中已经有 LLM 映射 + 首次确认的方案。所以"自动化程度"这个议题在 Phase 1 的语境下是一个伪问题——因为 Phase 1 根本不存在"高频重复手工确认"的场景。

真正需要讨论自动化程度的是 Phase 2——当我们支持可配置的周期性采集、用户自定义数据源时，自动化才成为关键问题。

我说这些不是反对自动化——我只是提醒大家，不要为了一个 Phase 2 的问题在 Phase 1 投入过多精力。**先做能跑通的最简版本，Phase 2 再优化体验。**

---

#### 专家投票

| 专家 | 投票 | 理由 |
|------|------|------|
| 苏明远 | **支持正方（最大化自动化）** | 自动化是产品定位的核心，不能在体验上打折扣 |
| 赵一凡 | **有条件支持正方** | 同意大方向，但 Phase 1 只需实现"首次确认 + 模板复用"即可，不需要复杂的置信度分层 |
| 陈思琪 | **支持正方** | 用户诉求已被议题 A1 的方案覆盖，AI 管线本身就是全自动的 |
| 林晓薇 | **有条件支持正方** | 同意自动化，但首次确认保留为"信任建设"环节 |
| 周安 | **有条件支持正方** | 同意多数场景自动化，但低置信度暂停机制不可省略 |
| 王磊 | **支持正方** | 方案在 A1 已经落地，不需要额外工时 |
| 方若琳 | **支持正方** | 低摩擦是组织采纳的前提 |

**投票结果**：7:0 支持自动化方案（其中 3 票为有条件支持）

**共识决议**：
1. Phase 1 的 Raw → Voice 转化整体设计为**默认自动化**
2. 用户上传新格式文件时保留首次映射确认（5 秒操作），后续复用模板全自动
3. 爬虫数据完全自动入库
4. 低置信度映射（< 0.7）暂停等待用户确认
5. AI 管线（Stage 1-3）保持全自动，无需用户参与
6. 不额外增加工时——已被议题 A1 的方案覆盖

---

## 3. 具体修改建议

### 3.1 PRD `02-prd-phase1.md` 修改清单

| # | 章节 | 修改类型 | 具体修改 |
|---|------|---------|---------|
| 1 | 1.1 一句话定位 | **扩展** | 增加"支持多源数据自动采集"的表述 |
| 2 | 2.1 US-1 | **重写** | 将"CSV 导入"重写为"多格式数据上传 + LLM 自动映射"（见第 4 节） |
| 3 | 2.1 US-1 前置条件 | **修改** | 删除"CSV 格式的客户反馈文件"的固定格式假设，改为"CSV 或 Excel 格式的数据文件（字段名不限）" |
| 4 | 2.1 US-1 主流程第 3 步 | **修改** | "用户确认字段映射"改为"LLM 自动映射 + 用户一键确认预览（首次）" |
| 5 | 2.1 US-1 异常流程 | **修改** | "缺少 `text` 列"改为"LLM 无法识别内容字段（置信度 < 0.7）" |
| 6 | 2.1 US-1 验收标准 | **新增** | AC6：重复数据自动跳过，导入摘要展示新增/跳过/失败数 |
| 7 | US-2（新增） | **新增** | 新增爬虫数据采集 User Story（见第 4 节） |
| 8 | 功能清单 Must Have | **新增** | 新增"懂车帝爬虫"和"微博爬虫"两个条目 |
| 9 | 功能清单 Must Have | **新增** | 新增"LLM Schema 自动映射"条目 |
| 10 | 功能清单 Must Have | **新增** | 新增"增量去重（content hash）"条目 |
| 11 | 排期与里程碑 | **修改** | 总工期增加 3-4 周（爬虫开发）+ 1 周（Schema 映射 + 增量模式） |
| 12 | 技术架构约束 | **新增** | 新增 SchemaMapping、IngestionBatch 数据模型 |
| 13 | 风险与缓解 | **新增** | 新增爬虫合规风险、LLM 映射错误风险 |

### 3.2 设计文档修改清单

| # | 文档 | 修改类型 | 具体修改 |
|---|------|---------|---------|
| 1 | `02-data-architecture.md` | **新增模型** | 新增 SchemaMapping 和 IngestionBatch 数据模型定义 |
| 2 | `02-data-architecture.md` Voice 模型 | **新增字段** | 新增 `content_hash`（VARCHAR, NOT NULL）和 `batch_id`（UUID, NULLABLE）字段 |
| 3 | `02-data-architecture.md` Voice 表 | **新增索引** | 新增 `UNIQUE INDEX idx_voices_content_hash ON voices(tenant_id, content_hash)` |
| 4 | `03-ingestion-pipeline.md` | **新增阶段** | 在 Stage 1 前新增 Stage 0：Schema 识别与自动映射 |
| 5 | `03-ingestion-pipeline.md` | **新增** | 新增增量处理逻辑（content hash 查重 → skip/process） |
| 6 | 新增文档 | **新增** | `04-crawler-design.md`——爬虫系统设计（懂车帝/微博） |

### 3.3 `SourceType` 枚举扩展建议

现有 `SourceType` 包含 `SOCIAL`（社交媒体）和 `REVIEW`（应用商店评论），建议扩展方式：

- 微博数据：使用现有 `SOCIAL` 类型，通过 `source_metadata.platform = "weibo"` 区分
- 懂车帝数据：使用现有 `REVIEW` 类型，通过 `source_metadata.platform = "dongchedi"` 区分

理由：不增加枚举值可以保持 SourceType 的通用性。具体平台信息存储在 JSONB 字段中，更灵活且易于扩展。

---

## 4. 新增/修改的 User Story 草案

### US-1（重写）：多格式数据上传与 LLM 自动映射

- **角色**：作为一个产品经理
- **目标**：我需要将任意格式的客户反馈数据（CSV/Excel）上传到 Prism，系统自动理解数据结构并完成处理，无需我手动指定字段对应关系
- **前置条件**：
  - 用户已注册并登录 Prism
  - 拥有 CSV 或 Excel 格式的数据文件（字段名不限，但至少有一列包含文本内容）
  - LLM Provider 已配置并测试连通
- **主流程**：
  1. 用户在数据导入页面点击"上传文件"按钮
  2. 选择本地 CSV 或 Excel 文件
  3. 系统读取文件前 10 行，调用 LLM 自动识别字段含义，生成 Schema 映射建议
  4. **首次上传新格式**：系统展示映射预览面板——左侧为原始列名，右侧为 Voice 字段名，置信度 < 0.8 的映射项高亮标注。用户可修正映射后点击"确认并开始导入"。系统保存映射模板以供后续复用
  5. **复用已有模板**：系统检测到文件结构与已有映射模板匹配，自动应用模板，跳过确认步骤直接导入
  6. 系统执行增量导入：通过 content hash 去重，跳过已存在的数据
  7. 系统展示导入进度条（已解析 / 去重跳过 / 处理中 / 已完成 / 失败），每 5 秒刷新
  8. AI 管线自动执行 Stage 1（语义拆解）→ Stage 2（标签涌现 + 标准化）→ Stage 3（向量化）
  9. 处理完成后，页面展示导入摘要（新增 X 条、跳过 Y 条重复、失败 Z 条）
  10. 用户点击"查看结果"跳转到标签列表页
- **异常流程**：
  - LLM 无法识别内容字段（置信度 < 0.7）→ 系统暂停导入，提示用户"无法自动识别数据结构，请手动指定内容列"
  - 文件编码错误 → 系统提示"文件编码不支持，请使用 UTF-8 或 GBK 编码"
  - 全部数据为重复 → 系统提示"所有数据已存在，无需重复导入"
  - AI 管线处理某条反馈失败 → 原始数据保留并标记 `status = failed`，不阻塞其他条目
  - LLM Provider 不可用 → 故障转移引擎切换到降级模型，处理结果标记 `degraded=true`
- **验收标准**：
  - AC1：上传一个列名为 `评论内容`、`发布时间`、`用户名` 的 CSV，LLM 能正确映射到 `content`、`collected_at`、`author_id`
  - AC2：相同文件重复上传时，第二次导入重复数据被跳过
  - AC3：导入完成后展示准确的新增/跳过/失败摘要
  - AC4：1000 条反馈的端到端处理时间 < 30 分钟
  - AC5：处理完成后至少产出 20 个不同的涌现标签
  - AC6：每个标签附带置信度标注且 UI 正确展示三档颜色
  - AC7：映射模板保存后，下次上传同格式文件可自动匹配并跳过确认步骤

### US-2（新增）：懂车帝/微博爬虫数据自动采集

- **角色**：作为一个品牌运营经理
- **目标**：我需要一键触发懂车帝或微博的数据采集，系统自动抓取指定关键词/品牌的用户评论，LLM 自动转化为 Voice 并完成分析
- **前置条件**：
  - 用户已注册并登录 Prism
  - Prism CLI 已安装并配置
  - LLM Provider 已配置并测试连通
  - 网络环境可访问懂车帝/微博
- **主流程**：
  1. 用户通过 CLI 触发爬虫采集：
     - `prism crawl dongchedi --keyword "Prism" --pages 5`
     - `prism crawl weibo --keyword "Prism Coffee" --days 7`
  2. 爬虫脚本自动执行：访问目标网站、解析页面结构、提取评论数据
  3. 爬虫输出标准化 JSON 文件，包含 content、author、published_at、source_url 等字段
  4. 系统自动将 JSON 数据导入摄入管线：
     - 通过 content hash 去重，跳过已存在的数据
     - 创建 Voice 记录（source_type = social/review，source_metadata 包含平台信息）
     - AI 管线自动执行 Stage 1-3
  5. CLI 输出采集摘要：总抓取 X 条、新增 Y 条、跳过 Z 条重复、失败 W 条
  6. 用户打开 Web UI，查看新采集数据产生的涌现标签
- **异常流程**：
  - 目标网站不可达 → CLI 输出错误提示，建议检查网络或稍后重试
  - 反爬机制触发 → 爬虫自动降低请求频率并重试，超过重试次数后报错退出
  - 爬虫抓取的内容为空或无效 → 跳过无效数据，记录到日志
  - 部分数据 AI 管线处理失败 → 原始数据保留，标记 `status = failed`
- **验收标准**：
  - AC1：`prism crawl dongchedi --keyword "Prism"` 能成功抓取至少 50 条评论
  - AC2：`prism crawl weibo --keyword "Prism Coffee"` 能成功抓取至少 30 条微博
  - AC3：重复执行同一爬虫命令时，已抓取的数据不会重复入库
  - AC4：爬虫数据自动进入 AI 管线处理，无需用户额外操作
  - AC5：请求频率不超过 1 次/秒，尊重目标网站的 robots.txt
  - AC6：爬虫采集的数据在 Web UI 中与手动上传的数据无差异地展示

### US-2 原版（语义搜索）→ 重编号为 US-3

原 US-2（语义搜索与溯源验证）保持内容不变，编号调整为 US-3。后续 US 编号顺延。

---

## 5. 排期影响评估

### 5.1 原排期基线

| 里程碑 | 时间 | 交付内容 |
|-------|------|---------|
| Phase 2 完成 | 基线 T0 | LLM 网关、Agent 基础设施精简版 |
| Phase 2.5 精简版 | T0 + 6-8 周 | VOC 数据模型、AI 管线 Stage 1-3 |
| Phase 3 核心子集 | T0 + 14-18 周 | 语义搜索、前端 3 页面、dogfooding |

### 5.2 增量影响评估

| 新增项 | 工时估算 | 并行可能性 | 说明 |
|-------|---------|----------|------|
| LLM Schema 自动映射 | 5-7 人天 | 可与 AI 管线并行 | 含 Prompt 开发、SchemaMapping 模型、前端映射预览 |
| 增量去重 + IngestionBatch | 1-1.5 人天 | 可与数据模型开发合并 | content hash + 唯一索引 + 精简批次模型 |
| 懂车帝爬虫 | 5-6 人天 | **独立并行** | 需 1 人专职，含反爬处理 |
| 微博爬虫 | 5-7 人天 | **独立并行** | 微博反爬更复杂，含登录态处理 |
| 爬虫 CLI 集成 | 1 人天 | 可与爬虫开发合并 | Typer CLI 命令定义 |
| 爬虫输出标准化 | 1-2 人天 | 可与爬虫开发合并 | 标准 JSON Schema + 摄入管线对接 |
| **总计** | **18.5-24.5 人天** | | 约 4-5 周（1 人全职） |

### 5.3 修正后排期

**关键假设**：爬虫开发可由 1 人独立并行执行，不阻塞主线开发。

| 里程碑 | 原排期 | 修正后排期 | 变化 |
|-------|--------|----------|------|
| Phase 2 完成 | T0 | T0 | 无变化 |
| Phase 2.5 精简版 | T0 + 6-8 周 | T0 + 7-9 周 | +1 周（Schema 映射 + 增量模式） |
| 爬虫交付 | - | T0 + 8-12 周 | 新增里程碑（与 Phase 2.5/3 并行） |
| Phase 3 核心子集 | T0 + 14-18 周 | T0 + 15-20 周 | +1-2 周（集成测试 + 爬虫联调） |

**总工期影响**：延长 **1-2 周**（假设爬虫独立并行），最坏情况延长 **3-4 周**（如果爬虫开发人力与主线共享）。

### 5.4 风险与缓解

| 风险 | 概率 | 影响 | 缓解措施 |
|------|------|------|---------|
| 爬虫开发耗时超预期（反爬机制复杂） | 中 | 高 | 设置 3 周上限，超时则降级为手动数据导入 |
| LLM 映射准确率不达标 | 低 | 中 | 预置已知格式的映射模板作为 fallback |
| 懂车帝/微博页面改版导致爬虫失效 | 中 | 中 | 爬虫模块化设计，页面解析逻辑可独立更新 |
| 爬虫合规风险 | 低 | 高 | 文档明确合规责任归属，遵守 robots.txt，控制请求频率 |
| 增量去重的 content hash 碰撞 | 极低 | 低 | SHA-256 碰撞概率可忽略不计 |

---

## 附录：辩论统计

### 投票汇总

| 议题 | 正方 | 反方 | 弃权 | 决议 |
|------|------|------|------|------|
| A1：LLM 自动映射策略 | 7（含 2 有条件） | 0 | 0 | LLM 映射 + 首次确认 + 模板缓存 |
| A2：爬虫进入 Phase 1 | 7（含 3 有条件） | 0 | 0 | 两个爬虫作为独立脚本进入 Phase 1 |
| A3：增量模式设计 | 0 | 7（含 2 有条件） | 0 | 最小增量（content hash）+ 精简 IngestionBatch |
| A4：LLM 自动转化程度 | 7（含 3 有条件） | 0 | 0 | 默认自动化 + 低置信度暂停 |

### 条件性要求汇总

以下是有条件支持中附带的硬性要求，在实现时不可省略：

| # | 条件 | 提出者 | 关联议题 |
|---|------|--------|---------|
| 1 | SchemaMapping 数据模型必须持久化 | 赵一凡 | A1 |
| 2 | 低置信度映射（< 0.8）必须高亮提示 | 周安 | A1 |
| 3 | 映射模板缓存支持复用 | 周安 | A1 |
| 4 | 为已知用户预置数据格式模板 | 林晓薇 | A1 |
| 5 | 爬虫必须作为独立模块，不与 Agent/Skill 深度耦合 | 赵一凡 | A2 |
| 6 | 爬虫合规约束（请求频率、robots.txt） | 周安 | A2 |
| 7 | 合规责任归属在文档中明确 | 方若琳 | A2 |
| 8 | 精简版 IngestionBatch 模型必须 Phase 1 落地 | 赵一凡 | A3 |
| 9 | 被跳过的数据可追溯，不静默丢弃 | 周安 | A3 |
| 10 | 低置信度映射（< 0.7）必须暂停等待确认 | 周安 | A4 |
| 11 | 首次映射确认保留为信任建设环节 | 林晓薇 | A4 |

---

*文档版本*：v1.0
*生成日期*：R5 Delta 评审周期
*涉及修正*：用户修正 #1, #2, #3, #4
*评审范围*：Agent A（数据摄入重构）
